<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>7&nbsp; Neural Networks – Machine Learning in Industrial Image Processing</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../nn/cnn.html" rel="next">
<link href="../nn/index.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark-8ea72dc5fed832574809a9c94082fbbb.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-d3d4d1eae387a6e9deb6a52c96ceddf1.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark-bf224785ad4c3f9b7bbdd05ed05d0153.min.css" rel="prefetch" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../nn/index.html">Neural Networks and Deep Learning</a></li><li class="breadcrumb-item"><a href="../nn/nn.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Neural Networks</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Machine Learning in Industrial Image Processing</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/kandolfp/MECH-M-DUAL-2-MLB/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../clustering/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Clustering and Classification</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../clustering/unsupervised.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Unsupervised learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../clustering/supervised.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Supervised learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../clustering/semisupervised.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Semi-Supervised learning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../data/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data management and data engineering</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../data/model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Model persistence</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../data/code.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Code persistence</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../data/data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Data persistence</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../nn/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Neural Networks and Deep Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../nn/nn.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../nn/cnn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Convolutional Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../nn/autoencoder.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Autoencoders</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Summary</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendices/explanations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">More detailed explanations</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendices/keras.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Our first Neural Network in <code>tensorflow.keras</code></span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#the-trainable-parameters-of-a-neural-network" id="toc-the-trainable-parameters-of-a-neural-network" class="nav-link active" data-scroll-target="#the-trainable-parameters-of-a-neural-network"><span class="header-section-number">7.1</span> The trainable parameters of a Neural Network</a></li>
  <li><a href="#a-neural-network-with-pytorch" id="toc-a-neural-network-with-pytorch" class="nav-link" data-scroll-target="#a-neural-network-with-pytorch"><span class="header-section-number">7.2</span> A Neural Network with <code>pytorch</code></a></li>
  <li><a href="#how-to-save-a-pytorch-model" id="toc-how-to-save-a-pytorch-model" class="nav-link" data-scroll-target="#how-to-save-a-pytorch-model"><span class="header-section-number">7.3</span> How to save a <code>pytorch</code> model</a></li>
  <li><a href="#backward-propagation-of-error---backpropagation" id="toc-backward-propagation-of-error---backpropagation" class="nav-link" data-scroll-target="#backward-propagation-of-error---backpropagation"><span class="header-section-number">7.4</span> Backward Propagation of Error - Backpropagation</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/kandolfp/MECH-M-DUAL-2-MLB/edit/main/nn/nn.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/kandolfp/MECH-M-DUAL-2-MLB/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../nn/index.html">Neural Networks and Deep Learning</a></li><li class="breadcrumb-item"><a href="../nn/nn.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Neural Networks</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-nn-nn" class="quarto-section-identifier"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Neural Networks</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Now that we constructed one of the simplest NNs possible (if we can even call it a NN), we build on this and extend our model. The first step is to introduce some (non-linear) activation functions or transfer functions <span class="math display">\[
y = f(A, b, x).
\]</span></p>
<p>Some common functions are:</p>
<ol type="1">
<li><p><strong>linear</strong> <span class="math display">\[ f(x) = x. \]</span></p></li>
<li><p><strong>binary step</strong> <span class="math display">\[ f(x) =
     \begin{cases}
         0 &amp; \text{for}\quad x \leq 0,\\
         1 &amp; \text{for}\quad x &gt; 0.\\
     \end{cases}
\]</span></p></li>
<li><p><strong>logistic (soft step)</strong> or <strong>sigmoid</strong> <span class="math display">\[ f(x) = \frac{1}{1 + \exp (-x)}. \]</span></p></li>
<li><p><strong>tanh</strong> <span class="math display">\[ f(x) = \tanh (x). \]</span></p></li>
<li><p><strong>rectified linear unit</strong> (ReLU) <span class="math display">\[ \begin{cases}
         0 &amp; \text{for}\quad x \leq 0,\\
         x &amp; \text{for}\quad x &gt; 0.\\
     \end{cases}
\]</span></p></li>
</ol>
<p>We can visualize them and their derivatives (we need them later).</p>
<div class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Show the code for the figure</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>config InlineBackend.figure_formats <span class="op">=</span> [<span class="st">"svg"</span>]</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.differentiate</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">1025</span>, endpoint<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>linear <span class="op">=</span> <span class="kw">lambda</span> x: x</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>binary <span class="op">=</span> <span class="kw">lambda</span> x: np.heaviside(x, <span class="dv">1</span>)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>logistic <span class="op">=</span> <span class="kw">lambda</span> x: <span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>x))</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>tanh <span class="op">=</span> <span class="kw">lambda</span> x: np.tanh(x)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>relu <span class="op">=</span> <span class="kw">lambda</span> x: np.maximum(<span class="dv">0</span>, x)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>plt.figure()</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>plt.plot(x, linear(x), <span class="st">"-"</span>, label<span class="op">=</span><span class="st">"Linear"</span>)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>plt.plot(x, binary(x), <span class="st">":"</span>, label<span class="op">=</span><span class="st">"Binary"</span>)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>plt.plot(x, logistic(x),<span class="st">"--"</span>,  label<span class="op">=</span><span class="st">"Logistic"</span>)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>plt.plot(x, tanh(x), <span class="st">"-."</span>, label<span class="op">=</span><span class="st">"tanh"</span>)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>plt.plot(x, relu(x), <span class="st">"-."</span>, label<span class="op">=</span><span class="st">"ReLU"</span>,</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>         marker<span class="op">=</span><span class="st">"o"</span>, markevery<span class="op">=</span><span class="dv">100</span>, markersize<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>plt.xlim([<span class="op">-</span><span class="dv">4</span>, <span class="dv">4</span>])</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>plt.ylim([<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>])</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>plt.gca().set_aspect(<span class="dv">8</span> <span class="op">/</span> (<span class="dv">4</span> <span class="op">*</span> <span class="dv">3</span>))</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>plt.figure()</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>plt.plot(x, scipy.differentiate.derivative(linear, x).df, <span class="st">"-"</span>, label<span class="op">=</span><span class="st">"Linear"</span>)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>plt.plot(x, scipy.differentiate.derivative(binary, x).df, <span class="st">":"</span>, label<span class="op">=</span><span class="st">"Binary"</span>)</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>plt.plot(x, scipy.differentiate.derivative(logistic, x).df,<span class="st">"--"</span>,  label<span class="op">=</span><span class="st">"Logistic"</span>)</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>plt.plot(x, scipy.differentiate.derivative(tanh, x).df, <span class="st">"-."</span>, label<span class="op">=</span><span class="st">"tanh"</span>)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>plt.plot(x, scipy.differentiate.derivative(relu, x).df, <span class="st">"-."</span>, label<span class="op">=</span><span class="st">"ReLU"</span>,</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>         marker<span class="op">=</span><span class="st">"o"</span>, markevery<span class="op">=</span><span class="dv">100</span>, markersize<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>plt.xlim([<span class="op">-</span><span class="dv">4</span>, <span class="dv">4</span>])</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>plt.ylim([<span class="op">-</span><span class="fl">0.1</span>, <span class="fl">1.1</span>])</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>plt.gca().set_aspect(<span class="dv">8</span> <span class="op">/</span> (<span class="fl">1.2</span> <span class="op">*</span> <span class="dv">3</span>))</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="fig-nn-singlelayer" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="1">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-nn-singlelayer-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-display">
<div id="fig-nn-singlelayer-1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-nn-singlelayer-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="nn_files/figure-html/fig-nn-singlelayer-output-1.svg" class="lightbox" data-gallery="fig-nn-singlelayer" title="Figure&nbsp;7.1&nbsp;(a): Activation functions."><img src="nn_files/figure-html/fig-nn-singlelayer-output-1.svg" class="img-fluid figure-img" data-ref-parent="fig-nn-singlelayer"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-nn-singlelayer-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Activation functions.
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div id="fig-nn-singlelayer-2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-nn-singlelayer-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="nn_files/figure-html/fig-nn-singlelayer-output-2.svg" class="lightbox" data-gallery="fig-nn-singlelayer" title="Figure&nbsp;7.1&nbsp;(b): Numerical derivates of the activation functions."><img src="nn_files/figure-html/fig-nn-singlelayer-output-2.svg" class="img-fluid figure-img" data-ref-parent="fig-nn-singlelayer"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-nn-singlelayer-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Numerical derivates of the activation functions.
</figcaption>
</figure>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-nn-singlelayer-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.1: Different activation functions and their derivatives.
</figcaption>
</figure>
</div>
</div>
<section id="the-trainable-parameters-of-a-neural-network" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="the-trainable-parameters-of-a-neural-network"><span class="header-section-number">7.1</span> The trainable parameters of a Neural Network</h2>
<p>Before we build our first NN in the next section, we need to get a better understanding on the dimensions and available parameters for our optimization involved in training a NN. As discussed, these parameters are the matrices combining the weights and the biases. Of course they are related to the neurons.</p>
<div id="fig-nn-nn-get_dim" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-nn-nn-get_dim-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="../_assets/nn/generic_nn_get_dim.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Figure&nbsp;7.2: Generic linear NN with weights and biases."><img src="../_assets/nn/generic_nn_get_dim.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-nn-nn-get_dim-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.2: Generic linear NN with weights and biases.
</figcaption>
</figure>
</div>
<div class="callout callout-style-simple callout-caution no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exr-nn-nn-params" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 7.1 (Compute the parameters of the Neural Network)</strong></span> For the NN display in <a href="#fig-nn-nn-get_dim" class="quarto-xref">Figure&nbsp;<span>7.2</span></a> answer the following questions:</p>
<ol type="1">
<li>What are the shapes of the matrices <span class="math inline">\(A_1, A_2, A_3, A_4\)</span>?</li>
<li>Which of these matrices are sparse (have multiple zeros)?</li>
<li>What are the shapes of the biases <span class="math inline">\(b_1, b_2, b_3, b_4\)</span>?</li>
<li>Write down the (expanded) formula for the output <span class="math inline">\(y\)</span> with respect to the input <span class="math inline">\(x\)</span> resulting from the composition of the different layers for <span class="math inline">\(f(x) = x\)</span> in each layer (as seen in <a href="#fig-nn-nn-get_dim" class="quarto-xref">Figure&nbsp;<span>7.2</span></a>).</li>
<li>Is this formulation a good option to compute <span class="math inline">\(y\)</span> from <span class="math inline">\(x\)</span> (provide some reasoning)?</li>
</ol>
</div>
</div>
</div>
</div>
<p>In <a href="#fig-nn-nn-get_dim" class="quarto-xref">Figure&nbsp;<span>7.2</span></a> we also used the formulation of <em>hidden layers</em> for all the layers <em>inside</em> the NN. This is a common formulation reflecting the nature of the NN. Their <em>activations</em> (transfer from their specific input to output <span class="math inline">\(f_j(A_j, b_j, x^{(j-1)})\)</span>) are not exposed to the user and can’t be observed by the user directly.</p>
<p>Now let us build our first NN.</p>
</section>
<section id="a-neural-network-with-pytorch" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="a-neural-network-with-pytorch"><span class="header-section-number">7.2</span> A Neural Network with <code>pytorch</code></h2>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>There are multiple frameworks available for NNs in <code>Python</code>. We will focus on <a href="https://pytorch.org/"><code>pytorch</code></a> for these notes.</p>
<p>Nevertheless, see <a href="../appendices/keras.html" class="quarto-xref"><span>Appendix B</span></a> for an implementation of the <em>same</em> NN with an alternative framework.</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>There are a couple of steps required and some foreshadow later decisions. We tried to make the split to provide better understanding and an easy way to follow the material.</p>
</div>
</div>
<p>Let us start with the input and how to prepare our data for for the model to-be. Before we load everything into the <code>pytorch</code> specific structures, we split our data into a training and test set. This time it is important that we rescale scale our image to <span class="math inline">\([0, 1]\)</span>, otherwise the optimization algorithms perform poorly. We scale by <span class="math inline">\(255\)</span>, our theoretical maximum in a generic image.</p>
<div id="045c7118" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="annotated-cell-2"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-2-1"><a href="#annotated-cell-2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="annotated-cell-2-2"><a href="#annotated-cell-2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy</span>
<span id="annotated-cell-2-3"><a href="#annotated-cell-2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="annotated-cell-2-4"><a href="#annotated-cell-2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> io</span>
<span id="annotated-cell-2-5"><a href="#annotated-cell-2-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="annotated-cell-2-6"><a href="#annotated-cell-2-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="annotated-cell-2-7"><a href="#annotated-cell-2-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> TensorDataset</span>
<span id="annotated-cell-2-8"><a href="#annotated-cell-2-8" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>config InlineBackend.figure_formats <span class="op">=</span> [<span class="st">"svg"</span>]</span>
<span id="annotated-cell-2-9"><a href="#annotated-cell-2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize everything for reproducibility</span></span>
<span id="annotated-cell-2-10"><a href="#annotated-cell-2-10" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">6020</span>)</span>
<span id="annotated-cell-2-11"><a href="#annotated-cell-2-11" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">6020</span>)</span>
<span id="annotated-cell-2-12"><a href="#annotated-cell-2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-2-13"><a href="#annotated-cell-2-13" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> requests.get(</span>
<span id="annotated-cell-2-14"><a href="#annotated-cell-2-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">"https://github.com/dynamicslab/databook_python/"</span></span>
<span id="annotated-cell-2-15"><a href="#annotated-cell-2-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">"raw/refs/heads/master/DATA/catData_w.mat"</span>)</span>
<span id="annotated-cell-2-16"><a href="#annotated-cell-2-16" aria-hidden="true" tabindex="-1"></a>cats_w <span class="op">=</span> scipy.io.loadmat(io.BytesIO(response.content))[<span class="st">"cat_wave"</span>]</span>
<span id="annotated-cell-2-17"><a href="#annotated-cell-2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-2-18"><a href="#annotated-cell-2-18" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> requests.get(</span>
<span id="annotated-cell-2-19"><a href="#annotated-cell-2-19" aria-hidden="true" tabindex="-1"></a>    <span class="st">"https://github.com/dynamicslab/databook_python/"</span></span>
<span id="annotated-cell-2-20"><a href="#annotated-cell-2-20" aria-hidden="true" tabindex="-1"></a>    <span class="st">"raw/refs/heads/master/DATA/dogData_w.mat"</span>)</span>
<span id="annotated-cell-2-21"><a href="#annotated-cell-2-21" aria-hidden="true" tabindex="-1"></a>dogs_w <span class="op">=</span> scipy.io.loadmat(io.BytesIO(response.content))[<span class="st">"dog_wave"</span>]</span>
<span id="annotated-cell-2-22"><a href="#annotated-cell-2-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-2-23"><a href="#annotated-cell-2-23" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> <span class="dv">40</span></span>
<span id="annotated-cell-2-24"><a href="#annotated-cell-2-24" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> np.concatenate((dogs_w[:, :s], cats_w[:, :s]), axis<span class="op">=</span><span class="dv">1</span>).T <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="annotated-cell-2-25"><a href="#annotated-cell-2-25" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> np.repeat(np.array([<span class="dv">0</span>, <span class="dv">1</span>]), s)</span>
<span id="annotated-cell-2-26"><a href="#annotated-cell-2-26" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> np.concatenate((dogs_w[:, s:], cats_w[:, s:]), axis<span class="op">=</span><span class="dv">1</span>).T <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="annotated-cell-2-27"><a href="#annotated-cell-2-27" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> np.repeat(np.array([<span class="dv">0</span>, <span class="dv">1</span>]), <span class="dv">80</span> <span class="op">-</span> s)</span>
<span id="annotated-cell-2-28"><a href="#annotated-cell-2-28" aria-hidden="true" tabindex="-1"></a></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-2" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-2-29" class="code-annotation-target"><a href="#annotated-cell-2-29" aria-hidden="true" tabindex="-1"></a>X_train_tensor <span class="op">=</span> torch.tensor(X_train, dtype<span class="op">=</span>torch.float32)</span>
<span id="annotated-cell-2-30"><a href="#annotated-cell-2-30" aria-hidden="true" tabindex="-1"></a>y_train_tensor <span class="op">=</span> torch.tensor(y_train, dtype<span class="op">=</span>torch.uint8)</span>
<span id="annotated-cell-2-31"><a href="#annotated-cell-2-31" aria-hidden="true" tabindex="-1"></a>X_test_tensor <span class="op">=</span> torch.tensor(X_test, dtype<span class="op">=</span>torch.float32)</span>
<span id="annotated-cell-2-32"><a href="#annotated-cell-2-32" aria-hidden="true" tabindex="-1"></a>y_test_tensor <span class="op">=</span> torch.tensor(y_test, dtype<span class="op">=</span>torch.uint8)</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-2" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-2-33" class="code-annotation-target"><a href="#annotated-cell-2-33" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> TensorDataset(X_train_tensor, y_train_tensor)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-2" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-2" data-code-lines="29,30,31,32" data-code-annotation="1">We need to convert the training data to <em>PyTorch tensors</em> unfortionalty, this might result in larger data if we are not careful, <code>uint8</code> works for the loss computation we aim for (see later).</span>
</dd>
<dt data-target-cell="annotated-cell-2" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-2" data-code-lines="33" data-code-annotation="2">Combine <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> such that it can easily be used for a <code>DataLoader</code>.</span>
</dd>
</dl>
</div>
</div>
<p>The easiest way to provide data for training is to use the mentioned <code>DataLoader</code> class. As we have only a very limited number of training data, we split our available data into a training and validation. We do so new and random in each epoch (optimization step). To provide a better overview, we use a dedicated function for this procedure. This function will be called during each optimization step in our training.</p>
<div id="3130e9d9" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, random_split</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_dataset(dataset: TensorDataset, val_split: <span class="bu">float</span>, batch_size: <span class="bu">int</span>):</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    val_size <span class="op">=</span> <span class="bu">int</span>(val_split <span class="op">*</span> <span class="bu">len</span>(dataset))</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    train_size <span class="op">=</span> <span class="bu">len</span>(dataset) <span class="op">-</span> val_size</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    train_ds, val_ds <span class="op">=</span> random_split(dataset, [train_size, val_size])</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a dataset</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    train <span class="op">=</span> DataLoader(train_ds, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    val <span class="op">=</span> DataLoader(val_ds, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> train, val</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now that we have taken care of our input, we need to discuss the output of our model. Instead of having a single neuron that is zero or one, we will have two neurons, i.e.&nbsp;<span class="math inline">\(y\in\mathbb{R^2}\)</span> using a so called <em>one-hot encoding</em> for our two classes. <span class="math display">\[
y = \left[\begin{array}{c}1 \\ 0\end{array}\right] = \text{dog},
\quad\text{and}\quad
y = \left[\begin{array}{c}0 \\ 1\end{array}\right] = \text{cat}.
\]</span></p>
<p>The idea is, that the model will provide us with the probability, that an image shows a dog on <span class="math inline">\(y_1\)</span> or a cat on <span class="math inline">\(y_2\)</span> (the sum of both will be <span class="math inline">\(1\)</span>).</p>
<p>Next, we define our activation function in the first layer by the non-linear function <span class="math inline">\(f_1 = \tanh\)</span>. The idea is to use a more <em>complicated</em> function the reflect the nature of our images. The rest remains unchanged, with the weights aggregated to matrix <span class="math inline">\(A_1\)</span> and the bias to the vector <span class="math inline">\(b_1\)</span>. In a the next layer we have a linear transform to provide some more freedom and than use the <code>softmax</code> function <span class="math inline">\(\sigma\)</span> (see <a href="../appendices/explanations.html#sec-appendix-softmax" class="quarto-xref"><span>Section A.3</span></a> for a more detailed explanation and example) to translate the result into a probability <span class="math display">\[
\sigma: \mathbb{R^n} \to (0, 1)^n, \quad \sigma(x)_i = \frac{\exp(x_i)}{\sum_j{\exp(x_j)}}.
\]</span></p>
<p>We visualized the resulting network in <a href="#fig-nn-cvd-nl" class="quarto-xref">Figure&nbsp;<span>7.3</span></a>.</p>
<div id="fig-nn-cvd-nl" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-nn-cvd-nl-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="../_assets/nn/cats_vs_dogs_nonlinear.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Figure&nbsp;7.3: A two layer structure for the cats vs.&nbsp;dogs classification with a non-linear model."><img src="../_assets/nn/cats_vs_dogs_nonlinear.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-nn-cvd-nl-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.3: A two layer structure for the cats vs.&nbsp;dogs classification with a non-linear model.
</figcaption>
</figure>
</div>
<p>The following couple of code sections translate <a href="#fig-nn-cvd-nl" class="quarto-xref">Figure&nbsp;<span>7.3</span></a> into a <code>pytorch</code> model. The main idea is that we create a model class that inherits from <code>torch.nn.Module</code> and than perform our training on this class, benefiting from the inherited capabilities.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>As we will see in <a href="#exr-nn-nn-dvc-backprop" class="quarto-xref">Exercise&nbsp;<span>7.9</span></a>, <code>softmax</code> and our loss function can be combined in a numerical stable way. Therefore, it is often advised not to include <code>softmax</code> during training but for inference.</p>
<p>For the following code snippet, we keep it in as a comment to show where it would be included.</p>
</div>
</div>
<div id="c0eaf7d0" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="annotated-cell-4"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-4-1"><a href="#annotated-cell-4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="annotated-cell-4-2"><a href="#annotated-cell-4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-4-3"><a href="#annotated-cell-4-3" aria-hidden="true" tabindex="-1"></a></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-4" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-4-4" class="code-annotation-target"><a href="#annotated-cell-4-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MyFirstNN(torch.nn.Module):</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-4" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-4-5" class="code-annotation-target"><a href="#annotated-cell-4-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_params):</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-4" data-target-annotation="3" onclick="event.preventDefault();">3</a><span id="annotated-cell-4-6" class="code-annotation-target"><a href="#annotated-cell-4-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(MyFirstNN, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-4" data-target-annotation="4" onclick="event.preventDefault();">4</a><span id="annotated-cell-4-7" class="code-annotation-target"><a href="#annotated-cell-4-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> torch.nn.Sequential(</span>
<span id="annotated-cell-4-8"><a href="#annotated-cell-4-8" aria-hidden="true" tabindex="-1"></a>            torch.nn.Linear(input_params, <span class="dv">2</span>),           </span>
<span id="annotated-cell-4-9"><a href="#annotated-cell-4-9" aria-hidden="true" tabindex="-1"></a>            torch.nn.Tanh(),                            </span>
<span id="annotated-cell-4-10"><a href="#annotated-cell-4-10" aria-hidden="true" tabindex="-1"></a>            torch.nn.Linear(<span class="dv">2</span>, <span class="dv">2</span>),                      </span>
<span id="annotated-cell-4-11"><a href="#annotated-cell-4-11" aria-hidden="true" tabindex="-1"></a>            <span class="co">#torch.nn.Softmax(dim=1),                    </span></span>
<span id="annotated-cell-4-12"><a href="#annotated-cell-4-12" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="annotated-cell-4-13"><a href="#annotated-cell-4-13" aria-hidden="true" tabindex="-1"></a></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-4" data-target-annotation="5" onclick="event.preventDefault();">5</a><span id="annotated-cell-4-14" class="code-annotation-target"><a href="#annotated-cell-4-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="annotated-cell-4-15"><a href="#annotated-cell-4-15" aria-hidden="true" tabindex="-1"></a>        y <span class="op">=</span> <span class="va">self</span>.model(x)</span>
<span id="annotated-cell-4-16"><a href="#annotated-cell-4-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> y</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-4" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-4" data-code-lines="4,17" data-code-annotation="1">Create a class inheriting from <code>torch.nn.Module</code>.</span>
</dd>
<dt data-target-cell="annotated-cell-4" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-4" data-code-lines="5,13" data-code-annotation="2">The layers of the NN are defined in the initialization of the class.</span>
</dd>
<dt data-target-cell="annotated-cell-4" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-4" data-code-lines="6" data-code-annotation="3">Do not forget to initialize the super class.</span>
</dd>
<dt data-target-cell="annotated-cell-4" data-target-annotation="4">4</dt>
<dd>
<span data-code-cell="annotated-cell-4" data-code-lines="7,12" data-code-annotation="4">We define a sequential model, this reflects best our desired structure, the first layer that reduces down to two neurons and applies the function <span class="math inline">\(\tanh\)</span>, and a second for <code>softmax</code>.</span>
</dd>
<dt data-target-cell="annotated-cell-4" data-target-annotation="5">5</dt>
<dd>
<span data-code-cell="annotated-cell-4" data-code-lines="14,15,16" data-code-annotation="5">In <code>forward</code> we define how data moves through the network.</span>
</dd>
</dl>
</div>
</div>
<p>Of course it is important to check if the code corresponds to the model we have in mind. For this <a href="https://github.com/TylerYep/torchinfo"><code>torchinfo</code></a> is quite a useful tool. It provides a tabular overview.</p>
<div id="243c0788" class="cell styled-output" data-execution_count="5">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchinfo</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> MyFirstNN(X_train.shape[<span class="dv">1</span>])</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>info <span class="op">=</span> torchinfo.summary(model, (batch_size, X_train.shape[<span class="dv">1</span>]), col_width<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Nicer formatting for the notes</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>info.layer_name_width<span class="op">=</span><span class="dv">15</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(info)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>================================================================
Layer (type:depth-idx)                   Output Shape Param #
================================================================
MyFirstNN                                [8, 2]       --
├─Sequential: 1-1                        [8, 2]       --
│    └─Linear: 2-1                       [8, 2]       2,050
│    └─Tanh: 2-2                         [8, 2]       --
│    └─Linear: 2-3                       [8, 2]       6
================================================================
Total params: 2,056
Trainable params: 2,056
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 0.02
================================================================
Input size (MB): 0.03
Forward/backward pass size (MB): 0.00
Params size (MB): 0.01
Estimated Total Size (MB): 0.04
================================================================</code></pre>
</div>
</div>
<div class="callout callout-style-simple callout-caution no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exr-nn-nn-params" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 7.2 (Explain the output of <code>.summary()</code>)</strong></span> For the (extended) output of <code>.summary()</code> in the following listing answer the questions below.</p>
<div id="dbcf7368" class="cell styled-output" data-execution_count="6">
<details class="code-fold">
<summary>Show the code for the slightly extended summary.</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchinfo</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> MyFirstNN(X_train.shape[<span class="dv">1</span>])</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>info <span class="op">=</span> torchinfo.summary(model, (batch_size, X_train.shape[<span class="dv">1</span>]),</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>                  col_names<span class="op">=</span>[<span class="st">"input_size"</span>, <span class="st">"output_size"</span>, <span class="st">"num_params"</span>],</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>                  col_width<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>info.layer_name_width<span class="op">=</span><span class="dv">15</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(info)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n\n</span><span class="ss">The estimated total size in KB </span><span class="sc">{</span>info<span class="sc">.</span>total_param_bytes <span class="op">/</span> <span class="dv">1024</span><span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>============================================================================
Layer (type:depth-idx)                   Input Shape  Output Shape Param #
============================================================================
MyFirstNN                                [8, 1024]    [8, 2]       --
├─Sequential: 1-1                        [8, 1024]    [8, 2]       --
│    └─Linear: 2-1                       [8, 1024]    [8, 2]       2,050
│    └─Tanh: 2-2                         [8, 2]       [8, 2]       --
│    └─Linear: 2-3                       [8, 2]       [8, 2]       6
============================================================================
Total params: 2,056
Trainable params: 2,056
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 0.02
============================================================================
Input size (MB): 0.03
Forward/backward pass size (MB): 0.00
Params size (MB): 0.01
Estimated Total Size (MB): 0.04
============================================================================


The estimated total size in KB 8.03125</code></pre>
</div>
</div>
<ol type="1">
<li>Explain how the <code>Param #</code> column is computed and retrace the details.</li>
<li>If we expand the <code>Params size</code> to (KB) we get 8.03, what does this imply on the data type of the parameters?</li>
</ol>
</div>
</div>
</div>
</div>
<p>It is often also quite useful to export the model as an image. Here the <a href="https://github.com/szagoruyko/pytorchviz"><code>torchviz</code></a> package comes in handy. In our case we can work again with a <code>dot</code> file, that is rendered as <a href="#fig-nn-nn-model-visual" class="quarto-xref">Figure&nbsp;<span>7.4</span></a>.</p>
<div id="7cda0fd5" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchviz</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>x_viz <span class="op">=</span> X_train_tensor[<span class="dv">0</span>, :].reshape([<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>y_viz <span class="op">=</span> model(x_viz)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>dot <span class="op">=</span> torchviz.make_dot(y_viz, params<span class="op">=</span><span class="bu">dict</span>(model.named_parameters()))</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>dot.save(<span class="st">"model.dot"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-file="model.dot" data-layout-align="default">
<div class="cell-output-display">
<div id="fig-nn-nn-model-visual" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-nn-nn-model-visual-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div>
<svg width="672" height="480" viewbox="0.00 0.00 299.30 424.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 420)">
<polygon fill="white" stroke="transparent" points="-4,4 -4,-420 295.3,-420 295.3,4 -4,4"></polygon>
<!-- 140325389018256 -->
<g id="node1" class="node">
<title>140325389018256</title>
<polygon fill="#caff70" stroke="black" points="170.15,-32 116.15,-32 116.15,0 170.15,0 170.15,-32"></polygon>
<text text-anchor="middle" x="143.15" y="-7" font-family="monospace" font-size="10.00"> (1, 2)</text>
</g>
<!-- 140325349162624 -->
<g id="node2" class="node">
<title>140325349162624</title>
<polygon fill="lightgrey" stroke="black" points="190.47,-88 95.83,-88 95.83,-68 190.47,-68 190.47,-88"></polygon>
<text text-anchor="middle" x="143.15" y="-75" font-family="monospace" font-size="10.00">AddmmBackward0</text>
</g>
<!-- 140325349162624&#45;&gt;140325389018256 -->
<g id="edge13" class="edge">
<title>140325349162624-&gt;140325389018256</title>
<path fill="none" stroke="black" d="M143.15,-67.89C143.15,-61.1 143.15,-51.48 143.15,-42.44"></path>
<polygon fill="black" stroke="black" points="146.65,-42.28 143.15,-32.28 139.65,-42.28 146.65,-42.28"></polygon>
</g>
<!-- 140322143315296 -->
<g id="node3" class="node">
<title>140322143315296</title>
<polygon fill="lightgrey" stroke="black" points="84.45,-144 -0.15,-144 -0.15,-124 84.45,-124 84.45,-144"></polygon>
<text text-anchor="middle" x="42.15" y="-131" font-family="monospace" font-size="10.00">AccumulateGrad</text>
</g>
<!-- 140322143315296&#45;&gt;140325349162624 -->
<g id="edge1" class="edge">
<title>140322143315296-&gt;140325349162624</title>
<path fill="none" stroke="black" d="M59.28,-123.84C75.2,-115.33 99.11,-102.55 117.33,-92.8"></path>
<polygon fill="black" stroke="black" points="119.1,-95.83 126.27,-88.03 115.8,-89.65 119.1,-95.83"></polygon>
</g>
<!-- 140322144013440 -->
<g id="node4" class="node">
<title>140322144013440</title>
<polygon fill="lightblue" stroke="black" points="75.75,-212 8.55,-212 8.55,-180 75.75,-180 75.75,-212"></polygon>
<text text-anchor="middle" x="42.15" y="-199" font-family="monospace" font-size="10.00">model.2.bias</text>
<text text-anchor="middle" x="42.15" y="-187" font-family="monospace" font-size="10.00"> (2)</text>
</g>
<!-- 140322144013440&#45;&gt;140322143315296 -->
<g id="edge2" class="edge">
<title>140322144013440-&gt;140322143315296</title>
<path fill="none" stroke="black" d="M42.15,-179.86C42.15,-172.13 42.15,-162.63 42.15,-154.37"></path>
<polygon fill="black" stroke="black" points="45.65,-154.15 42.15,-144.15 38.65,-154.15 45.65,-154.15"></polygon>
</g>
<!-- 140325349162672 -->
<g id="node5" class="node">
<title>140325349162672</title>
<polygon fill="lightgrey" stroke="black" points="184.23,-144 102.07,-144 102.07,-124 184.23,-124 184.23,-144"></polygon>
<text text-anchor="middle" x="143.15" y="-131" font-family="monospace" font-size="10.00">TanhBackward0</text>
</g>
<!-- 140325349162672&#45;&gt;140325349162624 -->
<g id="edge3" class="edge">
<title>140325349162672-&gt;140325349162624</title>
<path fill="none" stroke="black" d="M143.15,-123.59C143.15,-116.7 143.15,-107.1 143.15,-98.57"></path>
<polygon fill="black" stroke="black" points="146.65,-98.3 143.15,-88.3 139.65,-98.3 146.65,-98.3"></polygon>
</g>
<!-- 140322125262816 -->
<g id="node6" class="node">
<title>140322125262816</title>
<polygon fill="lightgrey" stroke="black" points="189.47,-206 94.83,-206 94.83,-186 189.47,-186 189.47,-206"></polygon>
<text text-anchor="middle" x="142.15" y="-193" font-family="monospace" font-size="10.00">AddmmBackward0</text>
</g>
<!-- 140322125262816&#45;&gt;140325349162672 -->
<g id="edge4" class="edge">
<title>140322125262816-&gt;140325349162672</title>
<path fill="none" stroke="black" d="M142.3,-185.89C142.44,-177.52 142.65,-164.84 142.83,-154.23"></path>
<polygon fill="black" stroke="black" points="146.33,-154.26 143,-144.2 139.33,-154.14 146.33,-154.26"></polygon>
</g>
<!-- 140322123598000 -->
<g id="node7" class="node">
<title>140322123598000</title>
<polygon fill="lightgrey" stroke="black" points="98.45,-274 13.85,-274 13.85,-254 98.45,-254 98.45,-274"></polygon>
<text text-anchor="middle" x="56.15" y="-261" font-family="monospace" font-size="10.00">AccumulateGrad</text>
</g>
<!-- 140322123598000&#45;&gt;140322125262816 -->
<g id="edge5" class="edge">
<title>140322123598000-&gt;140322125262816</title>
<path fill="none" stroke="black" d="M68.11,-253.82C82.1,-243.09 105.48,-225.14 122.23,-212.29"></path>
<polygon fill="black" stroke="black" points="124.49,-214.96 130.29,-206.1 120.23,-209.41 124.49,-214.96"></polygon>
</g>
<!-- 140322144026480 -->
<g id="node8" class="node">
<title>140322144026480</title>
<polygon fill="lightblue" stroke="black" points="89.75,-348 22.55,-348 22.55,-316 89.75,-316 89.75,-348"></polygon>
<text text-anchor="middle" x="56.15" y="-335" font-family="monospace" font-size="10.00">model.0.bias</text>
<text text-anchor="middle" x="56.15" y="-323" font-family="monospace" font-size="10.00"> (2)</text>
</g>
<!-- 140322144026480&#45;&gt;140322123598000 -->
<g id="edge6" class="edge">
<title>140322144026480-&gt;140322123598000</title>
<path fill="none" stroke="black" d="M56.15,-315.69C56.15,-306.4 56.15,-294.44 56.15,-284.47"></path>
<polygon fill="black" stroke="black" points="59.65,-284.32 56.15,-274.32 52.65,-284.32 59.65,-284.32"></polygon>
</g>
<!-- 140322123596944 -->
<g id="node9" class="node">
<title>140322123596944</title>
<polygon fill="lightgrey" stroke="black" points="183.8,-274 116.5,-274 116.5,-254 183.8,-254 183.8,-274"></polygon>
<text text-anchor="middle" x="150.15" y="-261" font-family="monospace" font-size="10.00">TBackward0</text>
</g>
<!-- 140322123596944&#45;&gt;140322125262816 -->
<g id="edge7" class="edge">
<title>140322123596944-&gt;140322125262816</title>
<path fill="none" stroke="black" d="M149.04,-253.82C147.87,-244.17 145.99,-228.69 144.49,-216.32"></path>
<polygon fill="black" stroke="black" points="147.93,-215.61 143.25,-206.1 140.98,-216.45 147.93,-215.61"></polygon>
</g>
<!-- 140322123597760 -->
<g id="node10" class="node">
<title>140322123597760</title>
<polygon fill="lightgrey" stroke="black" points="192.45,-342 107.85,-342 107.85,-322 192.45,-322 192.45,-342"></polygon>
<text text-anchor="middle" x="150.15" y="-329" font-family="monospace" font-size="10.00">AccumulateGrad</text>
</g>
<!-- 140322123597760&#45;&gt;140322123596944 -->
<g id="edge8" class="edge">
<title>140322123597760-&gt;140322123596944</title>
<path fill="none" stroke="black" d="M150.15,-321.82C150.15,-312.17 150.15,-296.69 150.15,-284.32"></path>
<polygon fill="black" stroke="black" points="153.65,-284.1 150.15,-274.1 146.65,-284.1 153.65,-284.1"></polygon>
</g>
<!-- 140322144013040 -->
<g id="node11" class="node">
<title>140322144013040</title>
<polygon fill="lightblue" stroke="black" points="189.36,-416 110.94,-416 110.94,-384 189.36,-384 189.36,-416"></polygon>
<text text-anchor="middle" x="150.15" y="-403" font-family="monospace" font-size="10.00">model.0.weight</text>
<text text-anchor="middle" x="150.15" y="-391" font-family="monospace" font-size="10.00"> (2, 1024)</text>
</g>
<!-- 140322144013040&#45;&gt;140322123597760 -->
<g id="edge9" class="edge">
<title>140322144013040-&gt;140322123597760</title>
<path fill="none" stroke="black" d="M150.15,-383.69C150.15,-374.4 150.15,-362.44 150.15,-352.47"></path>
<polygon fill="black" stroke="black" points="153.65,-352.32 150.15,-342.32 146.65,-352.32 153.65,-352.32"></polygon>
</g>
<!-- 140322124505024 -->
<g id="node12" class="node">
<title>140322124505024</title>
<polygon fill="lightgrey" stroke="black" points="275.8,-144 208.5,-144 208.5,-124 275.8,-124 275.8,-144"></polygon>
<text text-anchor="middle" x="242.15" y="-131" font-family="monospace" font-size="10.00">TBackward0</text>
</g>
<!-- 140322124505024&#45;&gt;140325349162624 -->
<g id="edge10" class="edge">
<title>140322124505024-&gt;140325349162624</title>
<path fill="none" stroke="black" d="M225.36,-123.84C209.9,-115.41 186.75,-102.78 168.95,-93.07"></path>
<polygon fill="black" stroke="black" points="170.15,-89.74 159.7,-88.03 166.8,-95.89 170.15,-89.74"></polygon>
</g>
<!-- 140322124557248 -->
<g id="node13" class="node">
<title>140322124557248</title>
<polygon fill="lightgrey" stroke="black" points="291.45,-206 206.85,-206 206.85,-186 291.45,-186 291.45,-206"></polygon>
<text text-anchor="middle" x="249.15" y="-193" font-family="monospace" font-size="10.00">AccumulateGrad</text>
</g>
<!-- 140322124557248&#45;&gt;140322124505024 -->
<g id="edge11" class="edge">
<title>140322124557248-&gt;140322124505024</title>
<path fill="none" stroke="black" d="M248.09,-185.89C247.11,-177.52 245.63,-164.84 244.39,-154.23"></path>
<polygon fill="black" stroke="black" points="247.86,-153.73 243.22,-144.2 240.91,-154.54 247.86,-153.73"></polygon>
</g>
<!-- 140322144016320 -->
<g id="node14" class="node">
<title>140322144016320</title>
<polygon fill="lightblue" stroke="black" points="288.36,-280 209.94,-280 209.94,-248 288.36,-248 288.36,-280"></polygon>
<text text-anchor="middle" x="249.15" y="-267" font-family="monospace" font-size="10.00">model.2.weight</text>
<text text-anchor="middle" x="249.15" y="-255" font-family="monospace" font-size="10.00"> (2, 2)</text>
</g>
<!-- 140322144016320&#45;&gt;140322124557248 -->
<g id="edge12" class="edge">
<title>140322144016320-&gt;140322124557248</title>
<path fill="none" stroke="black" d="M249.15,-247.69C249.15,-238.4 249.15,-226.44 249.15,-216.47"></path>
<polygon fill="black" stroke="black" points="252.65,-216.32 249.15,-206.32 245.65,-216.32 252.65,-216.32"></polygon>
</g>
</g>
</svg>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-nn-nn-model-visual-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.4: Model with all its parameters visualized.
</figcaption>
</figure>
</div>
</div>
</div>
<p>In <code>pytorch</code> we are responsible for our training function. This allows for a lot of flexibility. The structure is always quite similar.</p>
<div id="8d03e599" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="annotated-cell-7"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-7-1"><a href="#annotated-cell-7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_model(model, dataset, loss_fn, optimizer,</span>
<span id="annotated-cell-7-2"><a href="#annotated-cell-7-2" aria-hidden="true" tabindex="-1"></a>                epochs<span class="op">=</span><span class="dv">250</span>, validation_split<span class="op">=</span><span class="fl">0.1</span>, </span>
<span id="annotated-cell-7-3"><a href="#annotated-cell-7-3" aria-hidden="true" tabindex="-1"></a>                batch_size<span class="op">=</span><span class="dv">8</span>):</span>
<span id="annotated-cell-7-4"><a href="#annotated-cell-7-4" aria-hidden="true" tabindex="-1"></a></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-7" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-7-5" class="code-annotation-target"><a href="#annotated-cell-7-5" aria-hidden="true" tabindex="-1"></a>    met <span class="op">=</span> {</span>
<span id="annotated-cell-7-6"><a href="#annotated-cell-7-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">"train_loss"</span>: [],</span>
<span id="annotated-cell-7-7"><a href="#annotated-cell-7-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">"val_loss"</span>: [],</span>
<span id="annotated-cell-7-8"><a href="#annotated-cell-7-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">"train_acc"</span>: [],</span>
<span id="annotated-cell-7-9"><a href="#annotated-cell-7-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">"val_acc"</span>: []}</span>
<span id="annotated-cell-7-10"><a href="#annotated-cell-7-10" aria-hidden="true" tabindex="-1"></a></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-7" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-7-11" class="code-annotation-target"><a href="#annotated-cell-7-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-7" data-target-annotation="3" onclick="event.preventDefault();">3</a><span id="annotated-cell-7-12" class="code-annotation-target"><a href="#annotated-cell-7-12" aria-hidden="true" tabindex="-1"></a>        model.train()</span>
<span id="annotated-cell-7-13"><a href="#annotated-cell-7-13" aria-hidden="true" tabindex="-1"></a>        train_loss, train_corr <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="annotated-cell-7-14"><a href="#annotated-cell-7-14" aria-hidden="true" tabindex="-1"></a>        train_dl, val_dl <span class="op">=</span> get_dataset(dataset, validation_split, batch_size)</span>
<span id="annotated-cell-7-15"><a href="#annotated-cell-7-15" aria-hidden="true" tabindex="-1"></a></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-7" data-target-annotation="4" onclick="event.preventDefault();">4</a><span id="annotated-cell-7-16" class="code-annotation-target"><a href="#annotated-cell-7-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> X_batch, y_batch <span class="kw">in</span> train_dl:</span>
<span id="annotated-cell-7-17"><a href="#annotated-cell-7-17" aria-hidden="true" tabindex="-1"></a>            y_pred <span class="op">=</span> model(X_batch)            <span class="co"># Forward pass through the model</span></span>
<span id="annotated-cell-7-18"><a href="#annotated-cell-7-18" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_fn(y_pred, y_batch)    <span class="co"># Compute the loss</span></span>
<span id="annotated-cell-7-19"><a href="#annotated-cell-7-19" aria-hidden="true" tabindex="-1"></a>            loss.backward()                    <span class="co"># Backpropagation</span></span>
<span id="annotated-cell-7-20"><a href="#annotated-cell-7-20" aria-hidden="true" tabindex="-1"></a>            optimizer.step()                   <span class="co"># Update the model parameters</span></span>
<span id="annotated-cell-7-21"><a href="#annotated-cell-7-21" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()              <span class="co"># Reset the gradients</span></span>
<span id="annotated-cell-7-22"><a href="#annotated-cell-7-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-7-23"><a href="#annotated-cell-7-23" aria-hidden="true" tabindex="-1"></a>            train_loss <span class="op">+=</span> loss.item()</span>
<span id="annotated-cell-7-24"><a href="#annotated-cell-7-24" aria-hidden="true" tabindex="-1"></a>            train_corr <span class="op">+=</span> (y_pred.argmax(<span class="dv">1</span>) <span class="op">==</span> y_batch).<span class="bu">sum</span>().item()</span>
<span id="annotated-cell-7-25"><a href="#annotated-cell-7-25" aria-hidden="true" tabindex="-1"></a></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-7" data-target-annotation="5" onclick="event.preventDefault();">5</a><span id="annotated-cell-7-26" class="code-annotation-target"><a href="#annotated-cell-7-26" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()</span>
<span id="annotated-cell-7-27"><a href="#annotated-cell-7-27" aria-hidden="true" tabindex="-1"></a>        val_loss, val_corr <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span>                                       </span>
<span id="annotated-cell-7-28"><a href="#annotated-cell-7-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():                   <span class="co"># No gradient calculation</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-7" data-target-annotation="6" onclick="event.preventDefault();">6</a><span id="annotated-cell-7-29" class="code-annotation-target"><a href="#annotated-cell-7-29" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> X_val, y_val <span class="kw">in</span> val_dl:</span>
<span id="annotated-cell-7-30"><a href="#annotated-cell-7-30" aria-hidden="true" tabindex="-1"></a>                y_val_pred <span class="op">=</span> model(X_val)</span>
<span id="annotated-cell-7-31"><a href="#annotated-cell-7-31" aria-hidden="true" tabindex="-1"></a>                val_loss <span class="op">+=</span> loss_fn(y_val_pred, y_val).item()</span>
<span id="annotated-cell-7-32"><a href="#annotated-cell-7-32" aria-hidden="true" tabindex="-1"></a>                val_corr <span class="op">+=</span> (y_val_pred.argmax(<span class="dv">1</span>) <span class="op">==</span> y_val).<span class="bu">sum</span>().item()</span>
<span id="annotated-cell-7-33"><a href="#annotated-cell-7-33" aria-hidden="true" tabindex="-1"></a></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-7" data-target-annotation="7" onclick="event.preventDefault();">7</a><span id="annotated-cell-7-34" class="code-annotation-target"><a href="#annotated-cell-7-34" aria-hidden="true" tabindex="-1"></a>        met[<span class="st">"train_loss"</span>].append(train_loss <span class="op">/</span> <span class="bu">len</span>(train_dl))</span>
<span id="annotated-cell-7-35"><a href="#annotated-cell-7-35" aria-hidden="true" tabindex="-1"></a>        met[<span class="st">"val_loss"</span>].append(val_loss <span class="op">/</span> <span class="bu">len</span>(val_dl))</span>
<span id="annotated-cell-7-36"><a href="#annotated-cell-7-36" aria-hidden="true" tabindex="-1"></a>        met[<span class="st">"train_acc"</span>].append(train_corr <span class="op">/</span> <span class="bu">len</span>(train_dl.dataset))</span>
<span id="annotated-cell-7-37"><a href="#annotated-cell-7-37" aria-hidden="true" tabindex="-1"></a>        met[<span class="st">"val_acc"</span>].append(val_corr <span class="op">/</span> <span class="bu">len</span>(val_dl.dataset))</span>
<span id="annotated-cell-7-38"><a href="#annotated-cell-7-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-7-39"><a href="#annotated-cell-7-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> met</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-7" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-7" data-code-lines="5,9" data-code-annotation="1">Create a dict for our metrics.</span>
</dd>
<dt data-target-cell="annotated-cell-7" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-7" data-code-lines="11,38" data-code-annotation="2">The training loop for each epoch.</span>
</dd>
<dt data-target-cell="annotated-cell-7" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-7" data-code-lines="12" data-code-annotation="3">The model needs to be in the <code>train</code> mode, otherwise the parameters can not be changed.</span>
</dd>
<dt data-target-cell="annotated-cell-7" data-target-annotation="4">4</dt>
<dd>
<span data-code-cell="annotated-cell-7" data-code-lines="16,24" data-code-annotation="4">The actual training, the data is processed in batches and the optimization is computed for each batch.</span>
</dd>
<dt data-target-cell="annotated-cell-7" data-target-annotation="5">5</dt>
<dd>
<span data-code-cell="annotated-cell-7" data-code-lines="26" data-code-annotation="5">To allow validation, the model needs to be in <code>eval</code> mode.</span>
</dd>
<dt data-target-cell="annotated-cell-7" data-target-annotation="6">6</dt>
<dd>
<span data-code-cell="annotated-cell-7" data-code-lines="29,32" data-code-annotation="6">Validation step, that computes the necessary metrics for our validation set.</span>
</dd>
<dt data-target-cell="annotated-cell-7" data-target-annotation="7">7</dt>
<dd>
<span data-code-cell="annotated-cell-7" data-code-lines="34,37" data-code-annotation="7">Keep track of the metrics of our training. We log the average loss and the accuracy.</span>
</dd>
</dl>
</div>
</div>
<p>Now all parts are available and we can finally train our model.</p>
<div id="f43cb3f1" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="annotated-cell-8"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><a class="code-annotation-anchor" data-target-cell="annotated-cell-8" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-8-1" class="code-annotation-target"><a href="#annotated-cell-8-1" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-8" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-8-2" class="code-annotation-target"><a href="#annotated-cell-8-2" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.SGD(model.parameters(), lr<span class="op">=</span><span class="fl">1e-2</span>)</span>
<span id="annotated-cell-8-3"><a href="#annotated-cell-8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-8-4"><a href="#annotated-cell-8-4" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">120</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-8" data-target-annotation="3" onclick="event.preventDefault();">3</a><span id="annotated-cell-8-5" class="code-annotation-target"><a href="#annotated-cell-8-5" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> train_model(model, dataset, loss_fn, optimizer,</span>
<span id="annotated-cell-8-6"><a href="#annotated-cell-8-6" aria-hidden="true" tabindex="-1"></a>                      epochs<span class="op">=</span>epochs,</span>
<span id="annotated-cell-8-7"><a href="#annotated-cell-8-7" aria-hidden="true" tabindex="-1"></a>                      validation_split<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="annotated-cell-8-8"><a href="#annotated-cell-8-8" aria-hidden="true" tabindex="-1"></a>                      batch_size<span class="op">=</span>batch_size)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-8" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-8" data-code-lines="1" data-code-annotation="1">Define the loss function.</span>
</dd>
<dt data-target-cell="annotated-cell-8" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-8" data-code-lines="2" data-code-annotation="2">Define the optimizer.</span>
</dd>
<dt data-target-cell="annotated-cell-8" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-8" data-code-lines="5,8" data-code-annotation="3">Call the training loop.</span>
</dd>
</dl>
</div>
</div>
<p>This looks like a lot, but actually it is boiler plate code if needed and allows for quite a lot of flexibility if required.</p>
<p>Now that training is complete we can have a look at the performance.</p>
<div id="0d388ba4" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="annotated-cell-9"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><a class="code-annotation-anchor" data-target-cell="annotated-cell-9" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-9-1" class="code-annotation-target"><a href="#annotated-cell-9-1" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="annotated-cell-9-2"><a href="#annotated-cell-9-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-9" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-9-3" class="code-annotation-target"><a href="#annotated-cell-9-3" aria-hidden="true" tabindex="-1"></a>    y_proba <span class="op">=</span> torch.nn.Softmax(dim<span class="op">=</span><span class="dv">1</span>)(model(X_test_tensor))</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-9" data-target-annotation="3" onclick="event.preventDefault();">3</a><span id="annotated-cell-9-4" class="code-annotation-target"><a href="#annotated-cell-9-4" aria-hidden="true" tabindex="-1"></a>y_predict <span class="op">=</span> y_proba.argmax(axis<span class="op">=-</span><span class="dv">1</span>)</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-9" data-target-annotation="4" onclick="event.preventDefault();">4</a><span id="annotated-cell-9-5" class="code-annotation-target"><a href="#annotated-cell-9-5" aria-hidden="true" tabindex="-1"></a>acc <span class="op">=</span> (y_predict <span class="op">==</span> y_test_tensor).<span class="bu">sum</span>().item() <span class="op">/</span> <span class="bu">len</span>(y_test)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-9" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-9" data-code-lines="1" data-code-annotation="1">Switch to evaluation model.</span>
</dd>
<dt data-target-cell="annotated-cell-9" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-9" data-code-lines="3" data-code-annotation="2">Apply <code>softmax</code> to the output of the model.</span>
</dd>
<dt data-target-cell="annotated-cell-9" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-9" data-code-lines="4" data-code-annotation="3">Convert the probability into a class.</span>
</dd>
<dt data-target-cell="annotated-cell-9" data-target-annotation="4">4</dt>
<dd>
<span data-code-cell="annotated-cell-9" data-code-lines="5" data-code-annotation="4">Compute the accuracy for the test images.</span>
</dd>
</dl>
</div>
</div>
<p>We can also visualize the findings for a better understanding.</p>
<div class="cell" data-execution_count="11">
<details class="code-fold">
<summary>Show the code for the figure</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> myplot(y):</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    plt.figure()</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> y.shape[<span class="dv">0</span>]</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    plt.bar(<span class="bu">range</span>(n), y)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    plt.plot([<span class="op">-</span><span class="fl">0.5</span>, n <span class="op">-</span> <span class="fl">0.5</span>], [<span class="dv">0</span>, <span class="dv">0</span>], <span class="st">"k"</span>, linewidth<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    plt.plot([n <span class="op">//</span> <span class="dv">2</span> <span class="op">-</span> <span class="fl">0.5</span>, y.shape[<span class="dv">0</span>] <span class="op">//</span> <span class="dv">2</span> <span class="op">-</span> <span class="fl">0.5</span>], [<span class="op">-</span><span class="fl">1.1</span>, <span class="fl">1.1</span>], <span class="st">"r-."</span>, linewidth<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    plt.yticks([<span class="op">-</span><span class="fl">0.5</span>, <span class="fl">0.5</span>], [<span class="st">"cats"</span>, <span class="st">"dogs"</span>], rotation<span class="op">=</span><span class="dv">90</span>, va<span class="op">=</span><span class="st">"center"</span>)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    plt.text(n <span class="op">//</span> <span class="dv">4</span>, <span class="fl">1.05</span>, <span class="st">"dogs"</span>)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    plt.text(n <span class="op">//</span> <span class="dv">4</span> <span class="op">*</span> <span class="dv">3</span>, <span class="fl">1.05</span>, <span class="st">"cats"</span>)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    plt.gca().set_aspect(n <span class="op">/</span> (<span class="dv">2</span> <span class="op">*</span> <span class="dv">3</span>))</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>myplot(y_predict <span class="op">*</span> (<span class="op">-</span><span class="dv">2</span>) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> y_proba.shape[<span class="dv">0</span>]</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>plt.figure()</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>plt.bar(<span class="bu">range</span>(n), y_proba[:, <span class="dv">0</span>], color<span class="op">=</span><span class="st">'y'</span>, label<span class="op">=</span><span class="vs">r"p(dog)"</span>)</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>plt.bar(<span class="bu">range</span>(n), y_proba[:, <span class="dv">1</span>], color<span class="op">=</span><span class="st">'b'</span>, label<span class="op">=</span><span class="vs">r"p(cat)"</span>, </span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>        bottom<span class="op">=</span>y_proba[:, <span class="dv">0</span>])</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="op">-</span><span class="fl">0.5</span>, n <span class="op">-</span> <span class="fl">0.5</span>], [<span class="fl">0.5</span>, <span class="fl">0.5</span>], <span class="st">"r"</span>, linewidth<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>plt.gca().set_aspect(n <span class="op">/</span> (<span class="dv">1</span> <span class="op">*</span> <span class="dv">3</span>))</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>plt.figure()</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>epochs_range <span class="op">=</span> <span class="bu">range</span>(<span class="bu">len</span>(history[<span class="st">"train_acc"</span>]))</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>plt_list <span class="op">=</span> [[<span class="st">"train_acc"</span>, <span class="st">"-"</span>], [<span class="st">"train_loss"</span>, <span class="st">":"</span>],</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>            [<span class="st">"val_acc"</span>, <span class="st">"--"</span>], [<span class="st">"val_loss"</span>, <span class="st">"-."</span>]]</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, style <span class="kw">in</span> plt_list:</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>    plt.plot(epochs_range, history[name], style, label<span class="op">=</span>name)</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">"lower right"</span>)</span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>plt.gca().set_aspect(epochs <span class="op">/</span> (<span class="dv">1</span> <span class="op">*</span> <span class="dv">3</span>))</span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="fig-nn-nn-dvc-non-linear" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="11">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-nn-nn-dvc-non-linear-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-display">
<div id="fig-nn-nn-dvc-non-linear-1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-nn-nn-dvc-non-linear-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="nn_files/figure-html/fig-nn-nn-dvc-non-linear-output-1.svg" class="lightbox" data-gallery="fig-nn-nn-dvc-non-linear" title="Figure&nbsp;7.5&nbsp;(a): Classification for our test set."><img src="nn_files/figure-html/fig-nn-nn-dvc-non-linear-output-1.svg" class="img-fluid figure-img" data-ref-parent="fig-nn-nn-dvc-non-linear"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-nn-nn-dvc-non-linear-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Classification for our test set.
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div id="fig-nn-nn-dvc-non-linear-2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-nn-nn-dvc-non-linear-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="nn_files/figure-html/fig-nn-nn-dvc-non-linear-output-2.svg" class="lightbox" data-gallery="fig-nn-nn-dvc-non-linear" title="Figure&nbsp;7.5&nbsp;(b): Probabilities of the two classes - our actual output of the model."><img src="nn_files/figure-html/fig-nn-nn-dvc-non-linear-output-2.svg" class="img-fluid figure-img" data-ref-parent="fig-nn-nn-dvc-non-linear"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-nn-nn-dvc-non-linear-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Probabilities of the two classes - our actual output of the model.
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div id="fig-nn-nn-dvc-non-linear-3" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-nn-nn-dvc-non-linear-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="nn_files/figure-html/fig-nn-nn-dvc-non-linear-output-3.svg" class="lightbox" data-gallery="fig-nn-nn-dvc-non-linear" title="Figure&nbsp;7.5&nbsp;(c): Summary of the key metrics of the model training."><img src="nn_files/figure-html/fig-nn-nn-dvc-non-linear-output-3.svg" class="img-fluid figure-img" data-ref-parent="fig-nn-nn-dvc-non-linear"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-nn-nn-dvc-non-linear-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(c) Summary of the key metrics of the model training.
</figcaption>
</figure>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-nn-nn-dvc-non-linear-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.5: Performance of our model.
</figcaption>
</figure>
</div>
</div>
<p>In <a href="#fig-nn-nn-dvc-non-linear-1" class="quarto-xref">Figure&nbsp;<span>7.5 (a)</span></a> we can see the final classification of our model with regards to the test set. For 11 dogs our model is convinced they are not <em>good dogs</em> but cats, and 3 cats are classified as dogs. If we look at the probabilities <a href="#fig-nn-nn-dvc-non-linear-2" class="quarto-xref">Figure&nbsp;<span>7.5 (b)</span></a>, we can see that we have a couple of close calls, but in general our model is quite sure about the classification. Regarding the history of our optimization, we can see three phases, first our accuracy stays constant, right about for the first 80 iterations. Than the network starts learning up to 120 and after that only the loss function declines, but accuracy stays high.</p>
<p>At the end, we have an accuracy of 82.5% for our test set, a bit better than with our linear models <a href="#fig-nn-singlelayer" class="quarto-xref">Figure&nbsp;<span>7.1</span></a>.</p>
<div class="callout callout-style-simple callout-caution no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exr-nn-nn-dvc-lr" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 7.3 (Learning rate and momentum)</strong></span> The used optimizer <a href="https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD"><code>SGD</code></a> has two options we want to investigate further. The learning rate <code>lr</code> and the <code>momentum</code>.</p>
<ol type="1">
<li>Change the learning rate and see how this influences performance, you might want to increase <code>epochs</code> as well. Try <span class="math inline">\(lr \in [10^{-1}, 10^{-4}]\)</span>.</li>
<li>Change the momentum between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>, can this <em>improve</em> the predictions for different learning rates and such that the NN is <em>more sure</em> of its decision (in <a href="#fig-nn-nn-dvc-non-linear-2" class="quarto-xref">Figure&nbsp;<span>7.5 (b)</span></a> the bars are not almost equal but lean to one side).</li>
</ol>
</div>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-caution no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exr-nn-nn-dvc-adam" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 7.4 (Change the optimizer)</strong></span> As we have seen so often before, the optimizer used for the problem can change how fast convergence is reached (if at all).</p>
<ol type="1">
<li><p>Have a look at the possibilites provided in the framework <a href="https://pytorch.org/docs/stable/optim.html#algorithms">Overview - Optimizers</a> - they are basically all improvements on Stochastic Gradient Decent.</p></li>
<li><p>Test different approaches, especially one of the Adam (<code>Adam</code>, <code>AdamW</code>, <code>Adamax</code>) and Ada (<code>Adadelta</code>, <code>Adafactor</code>, <code>Adagrad</code>, <code>SparseAdam</code>) implementations and record the performance (final accuracy).</p></li>
</ol>
</div>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-caution no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exr-nn-nn-dvc-val" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 7.5 (Train and validation split)</strong></span> In the above version of the train loop we split our dataset in each epoch. Change this such that the split is done once per call of the training.</p>
<ol type="1">
<li>What is the influence on the training?</li>
<li>How is the performance for different optimizers?</li>
</ol>
</div>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-caution no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exr-nn-nn-dvc-train-softmax" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 7.6 (Train with <code>softmax</code>)</strong></span> Include <code>softmax</code> into to model for training and see how the performance is influenced.</p>
</div>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-caution no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exr-nn-nn-dvc-lightning" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 7.7 (Optional: PyTorch Lightning)</strong></span> The module <a href="https://lightning.ai/docs/pytorch/stable/"><code>pytorch lightning</code></a><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> promises to streamline the process for the training and to reduce the code.</p>
<p>With the <em>Lightning in 15 minutes</em> (or any other tutorial) rewrite your code to use this framework.</p>
<p><strong>Note</strong>: This will make the <code>dvclive</code> integration required below slightly easier.</p>
</div>
</div>
</div>
</div>
</section>
<section id="how-to-save-a-pytorch-model" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="how-to-save-a-pytorch-model"><span class="header-section-number">7.3</span> How to save a <code>pytorch</code> model</h2>
<p>Of course we can save our <code>pytorch</code> model with the methods discussed in <a href="../data/model.html" class="quarto-xref"><span>Chapter 4</span></a> but it is more convenient to use the dedicated functions, see <a href="https://pytorch.org/tutorials/beginner/saving_loading_models.html">docs</a>.</p>
<p>In short, we only need to call <code>torch.save(model.state_dict(), file)</code> to save in the default format using <code>pickle</code>, be careful when using it, see <a href="../data/model.html#sec-data-model-pickle" class="quarto-xref"><span>Section 4.2</span></a>.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>torch.save(<span class="st">"model.pt"</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>loaded_model <span class="op">=</span> model <span class="op">=</span> MyFirstNN(X_train.shape[<span class="dv">1</span>])</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>loaded_model.load_state_dict(torch.load(<span class="st">"model.pt"</span>, weights_only<span class="op">=</span><span class="va">True</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>It is also possible to implement continuous checkpoints during training, see <a href="https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-a-general-checkpoint-for-inference-and-or-resuming-training">docs</a>. This allows us to resume training after an interrupt or simply store the model at the end of the training.</p>
<p>All of this can be done via the already discussed <code>dvclive</code> interface, the implementation is defined as an exercise (if your module uses <code>lightning</code> this is even easier - see <a href="#exr-nn-nn-dvc-lightning" class="quarto-xref">Exercise&nbsp;<span>7.7</span></a>).</p>
<div class="callout callout-style-simple callout-caution no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exr-nn-nn-dvc-dvc" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 7.8 (<code>dvclive</code> integration into the <code>pytorch</code> training)</strong></span> Implement the <a href="https://dvc.org/doc/dvclive/ml-frameworks/pytorch"><code>DVCLive</code></a> integration to track the metrics.</p>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Store the model as <code>ONNX</code>
</div>
</div>
<div class="callout-body-container callout-body">
<p>It is also possible to export the model in the ONNX format, see <a href="../data/model.html#sec-data-model-onnx" class="quarto-xref"><span>Section 4.1</span></a> and for specifics the <a href="https://pytorch.org/tutorials/beginner/onnx/export_simple_model_to_onnx_tutorial.html">docs</a>.</p>
</div>
</div>
</section>
<section id="backward-propagation-of-error---backpropagation" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="backward-propagation-of-error---backpropagation"><span class="header-section-number">7.4</span> Backward Propagation of Error - Backpropagation</h2>
<p>Our first NN is a success, but how did it learn the necessary parameters to perform its task?</p>
<p>The answer is a technique called <em>Backward Propagation of Error</em> or in short <em>Backpropagation</em>. This essential component of for machine learning helps us to work out how the loss we compute translates into changes of the weights and biases in our network. In our training loop <code>train_model</code> the lines</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> model(X_batch)            <span class="co"># Forward pass through the model</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> loss_fn(y_pred, y_batch)    <span class="co"># Compute the loss</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>loss.backward()                    <span class="co"># Backpropagation</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>optimizer.step()                   <span class="co"># Update the model parameters</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>optimizer.zero_grad()              <span class="co"># Reset the gradients</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>are what we are focusing on in this section.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>A very nice and structured introduction by IBM can be found <a href="https://www.ibm.com/think/topics/backpropagation#:~:text=Backpropagation%20ist%20die%20Abk%C3%BCrzung%20f%C3%BCr,die%20Genauigkeit%20von%20Modellvorhersagen%20auswirken.">here</a><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p>
<p>An introduction closer to the mathematics is shown in <span class="citation" data-cites="Brunton2022">(<a href="../references.html#ref-Brunton2022" role="doc-biblioref">Brunton and Kutz 2022, chap. 6.3</a>)</span>.</p>
</div>
</div>
<p>The introduction of the technique is contributed to the paper of <span class="citation" data-cites="Rumelhart1986">Rumelhart, Hinton, and Williams (<a href="../references.html#ref-Rumelhart1986" role="doc-biblioref">1986</a>)</span>. As usual, predecessors and independent similar proposals go back to the 1960s. As we have seen, our NN can mathematically be described by nested functions, that are called inside the loss function, <span class="math inline">\(\mathscr{L}(\Theta)\)</span>, for <span class="math inline">\(\Theta\)</span> being all trainable parameters.</p>
<p>During the training, we can compute the <em>change</em> between the NN output and the provided label and use it in a gradient decent method<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. The result is the following iteration <span class="math display">\[
\Theta^{(n+1)} = \Theta^{(n)} - \delta \nabla \mathscr{L}\left(\Theta^{(n)}\right),
\]</span> where <span class="math inline">\(\delta\)</span> is called the <em>learning rate</em> and it is prescribed.</p>
<p>To compute the derivative of <span class="math inline">\(\mathscr{L}(\Theta)\)</span>, we can use the chain rule as this <em>propagates the error backwards</em> through the network. For <span class="math inline">\(h(x) = g(f(x))\)</span> the derivative <span class="math inline">\(h'(x)\)</span> is computed as <span class="math display">\[
h'(x) = g'(f(x))f'(x) \quad \Leftrightarrow \quad
\frac{\partial\, h}{\partial\, x} (x) = \frac{\partial\, g}{\partial\, x}(f(x)) \cdot \frac{\partial\, f}{\partial\, x}(x),
\]</span> or in Leibniz notation for a variable <span class="math inline">\(z\)</span> that depends on <span class="math inline">\(y\)</span>, which itself depends on <span class="math inline">\(x\)</span> we get <span class="math display">\[
\frac{\mathrm{d}\, z}{\mathrm{d}\, x} = \frac{\mathrm{d}\, z}{\mathrm{d}\, y} \cdot \frac{\mathrm{d}\, y}{\mathrm{d}\, x}.
\]</span></p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exm-nn-nn-backpropagation" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.1 (A simple case)</strong></span> To illustrate the procedure we start with the simplest example, illustrated in <a href="#fig-nn-nn-backprop_simple" class="quarto-xref">Figure&nbsp;<span>7.6</span></a>.</p>
<div id="fig-nn-nn-backprop_simple" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-nn-nn-backprop_simple-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="../_assets/nn/backprop_simple.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-8" title="Figure&nbsp;7.6: One node, one layer model for illustration of the backpropagation algorithm."><img src="../_assets/nn/backprop_simple.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-nn-nn-backprop_simple-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.6: One node, one layer model for illustration of the backpropagation algorithm.
</figcaption>
</figure>
</div>
<p>To get the output <span class="math inline">\(y\)</span> from <span class="math inline">\(x\)</span> the following computation is required <span class="math display">\[
y = g(z, b) = g(f(x, a), b).
\]</span></p>
<p>If we now assume a means square error for the final loss, <span class="math display">\[
\mathscr{L} = \frac12 (y_0 - y)^2,
\]</span> we get an error, depending on the weights <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, and for <span class="math inline">\(y_0\)</span> being the ground truth or correct result. In order to minimize the error according to <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> we need to compute the partial derivatives with respect to these variables</p>
<p><span class="math display">\[
\begin{align}
\frac{\partial\, \mathscr{L}}{\partial\, a}
&amp;= \frac{\partial\, \mathscr{L}}{\partial\, y} \cdot \frac{\partial\, y}{\partial\, a} &amp;=&amp; \big[y = g(z, b)\big]\\
&amp;= \frac{\partial\, \mathscr{L}}{\partial\, y}\cdot \frac{\partial\, g}{\partial\, z} \cdot \frac{\partial\, z}{\partial\, a} &amp;=&amp; \big[z = f(x, a)\big]\\
&amp;= \frac{\partial\, \mathscr{L}}{\partial\, y}\cdot \frac{\partial\, g}{\partial\, z} \cdot \frac{\partial\, f}{\partial\, a}
\end{align}
\]</span></p>
<p><span class="math display">\[
\begin{align}
\frac{\partial\, \mathscr{L}}{\partial\, b}
&amp;= \frac{\partial\, \mathscr{L}}{\partial\, y} \cdot \frac{\partial\, y}{\partial\, b} &amp;=&amp; \big[y = g(z,b)\big] \\
&amp;= \frac{\partial\, \mathscr{L}}{\partial\, y}\cdot \frac{\partial\, g}{\partial\, b} \phantom{ \cdot \frac{\partial\, f}{\partial\, a}}
\end{align}
\]</span></p>
<p>For a particular <span class="math inline">\(\mathscr{L}\)</span>, <span class="math inline">\(g\)</span>, and <span class="math inline">\(f\)</span> we can compute it explicitly, e.g.&nbsp;<span class="math inline">\(\mathscr{L}=\tfrac12(y_0 - y)^2\)</span>, <span class="math inline">\(g(z,b) = b z\)</span>, and <span class="math inline">\(f(x,a) = \tanh(a x)\)</span></p>
<p><span class="math display">\[
\begin{align}
\frac{\partial\, \mathscr{L}}{\partial\, a} &amp;=  \frac{\partial\, \mathscr{L}}{\partial\, y} \frac{\partial\, g}{\partial\, z}\frac{\partial\, f}{\partial\, a} &amp;=&amp; - (y_0 - y) \cdot b \cdot (1 - \tanh^2(a x)) \cdot x,\\
\frac{\partial\, \mathscr{L}}{\partial\, b} &amp;=  \frac{\partial\, \mathscr{L}}{\partial\, y} \frac{\partial\, g}{\partial\, b} &amp;=&amp; - (y_0 - y) \cdot \tanh(a x).
\end{align}
\]</span></p>
<p>With this information we can define the gradient descent update <span class="math display">\[
\begin{align}
a^{(k+1)} &amp;= a^{(k)} - \delta \frac{\partial\, \mathscr{L}}{\partial\, a} = a^{(k)} - \delta \left(- (y_0 - y) \cdot b^{(k)} \cdot (1 - \tanh^2(a^{(k)} x)) \cdot x\right), \\
b^{(k+1)} &amp;= b^{(k)} - \delta \frac{\partial\, \mathscr{L}}{\partial\, b} = b^{(k)} - \delta \left( - (y_0 - y) \cdot \tanh(a^{(k)} x)\right).
\end{align}
\]</span></p>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<div id="def-nn-backdrop" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 7.1 (Backpropagation)</strong></span> Now that we have a better understanding we can define the backdrop procedure, see <span class="citation" data-cites="Brunton2022">Brunton and Kutz (<a href="../references.html#ref-Brunton2022" role="doc-biblioref">2022</a>)</span> as reference:</p>
<ol type="1">
<li>Specify the NN along with the labeled training data.</li>
<li>Initialize the weights and biases of the NN with random values. If they are initialized with zero the gradient method will update all of them in the same fashion which is not what we are looking for.</li>
<li>In a loop until convergence or a maximum of iterations is achieved:
<ol type="i">
<li>Run the training data through the NN to compute <span class="math inline">\(y\)</span>. Compute the according loss and its derivatives with respect to each weight and bias.</li>
<li>For a given learning rate <span class="math inline">\(\delta\)</span> update the NN parameters via the gradient method.</li>
</ol></li>
</ol>
</div>
</div>
</div>
<p>We can see this reflected in our code for the NN above.</p>
<div class="callout callout-style-simple callout-caution no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exr-nn-nn-dvc-backprop" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 7.9 (Dogs and cats)</strong></span> Let us translate this findings to our example visualized in <a href="#fig-nn-cvd-nl" class="quarto-xref">Figure&nbsp;<span>7.3</span></a>. In order to do so, we need to specify our variables in more detail. To simplify it a bit we set the biases to the zero vector.</p>
<p>First, we call our output <span class="math inline">\(p = [p_1, p_2]\)</span> and our labels are encoded in one-hot encoding <span class="math inline">\(y = [y_1, y_2]\)</span> where <span class="math inline">\(y_1=1\)</span> and <span class="math inline">\(y_2=0\)</span> if the image is a dog, and vice versa if the image is a cat.</p>
<p>As our loss function we use cross-entropy <span class="math display">\[
\begin{align}
\mathscr{L}(\Theta) &amp;= - \frac12 \sum_{i=1}^2 y_i \log(p_i) = - \frac{y_1 \log(p_1) + y_2 \log(p_2)}{2} \\
&amp;= -\frac{1}{2} \left( y_1 \log(p_1) + (1-y_1) \log(1-p_1) \right),
\end{align}
\]</span> for a single sample with the above notation. The last line is true to the fact that the sum of the entries of <span class="math inline">\(y\)</span> and <span class="math inline">\(p\)</span> is equal to <span class="math inline">\(1\)</span>.</p>
<p>In order to make the computation of the derivates easier we use the variables as described in <a href="#fig-nn-nn-cvd_comp" class="quarto-xref">Figure&nbsp;<span>7.7</span></a>.</p>
<div id="fig-nn-nn-cvd_comp" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-nn-nn-cvd_comp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="../_assets/nn/cats_vs_dogs_comp.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-9" title="Figure&nbsp;7.7: One node, one layer model for illustration of the backpropagation algorithm."><img src="../_assets/nn/cats_vs_dogs_comp.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-nn-nn-cvd_comp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.7: One node, one layer model for illustration of the backpropagation algorithm.
</figcaption>
</figure>
</div>
<p>Therefore, we get <span class="math inline">\(p = g(z)=\sigma(B v)\)</span> (softmax), and <span class="math inline">\(v = f(u)= \tanh(A x)\)</span>. Overall we want to compute the change in <span class="math inline">\(B_{i, j}\)</span> (for some fixed indices <span class="math inline">\(i\)</span>, and <span class="math inline">\(j\)</span>). <span class="math display">\[
\frac{\partial\, \mathscr{L}}{\partial \, B_{i, j}} = \frac{\partial\, \mathscr{L}}{\partial \, p} \cdot \frac{\partial\, p}{\partial \, z} \cdot \frac{\partial\, z}{\partial \, B_{i, j}}
\]</span></p>
<p>Perform this task in the following steps:</p>
<ol type="1">
<li>Compute <span class="math inline">\(\partial_{p_i} \mathscr{L}\)</span>.</li>
<li>The computation of the Jacobian of <span class="math inline">\(\sigma(z)\)</span> is tricky but together with the cross-entropy loss it is straight forward, therefore compute <span class="math inline">\(\partial_{z_i} \mathscr{L}(\sigma(z))\)</span>.</li>
<li>Compute <span class="math inline">\(\partial_{B_{i, j}} z\)</span>.</li>
<li>Write down the components showing up for the chain rule for <span class="math inline">\(\frac{\partial\, \mathscr{L}}{\partial \, A_{i, j}}\)</span> (similar as above).</li>
</ol>
</div>
</div>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-Brunton2022" class="csl-entry" role="listitem">
Brunton, Steven L., and J. Nathan Kutz. 2022. <em>Data-Driven Science and Engineering - Machine Learning, Dynamical Systems, and Control</em>. 2nd ed. Cambridge: Cambridge University Press.
</div>
<div id="ref-Kandolf_GDM" class="csl-entry" role="listitem">
Kandolf, Peter. 2025. <span>“MECH-m-DUAL-1-DBM - Grundlagen Datenbasierter Methoden.”</span> <em>Management Center Innsbruck, Course Material</em>. <a href="https://doi.org/10.5281/zenodo.14671708">https://doi.org/10.5281/zenodo.14671708</a>.
</div>
<div id="ref-Rumelhart1986" class="csl-entry" role="listitem">
Rumelhart, David E., Geoffrey E. Hinton, and Ronald J. Williams. 1986. <span>“Learning Representations by Back-Propagating Errors.”</span> <em>Nature</em> 323 (6088): 533–36. <a href="https://doi.org/10.1038/323533a0">https://doi.org/10.1038/323533a0</a>.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Install it via <code>pdm add lightning</code>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Access on 4th April 2025.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>see <span class="citation" data-cites="Kandolf_GDM">Kandolf (<a href="../references.html#ref-Kandolf_GDM" role="doc-biblioref">2025</a>)</span>, Section 6.1 or follow the direct <a href="https://kandolfp.github.io/MECH-M-DUAL-1-DBM/regression/nonlinear.html#sec-regression-nonlinear-gd">link</a>.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/kandolfp\.github\.io\/MECH-M-DUAL-2-MLB\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../nn/index.html" class="pagination-link" aria-label="Neural Networks and Deep Learning">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Neural Networks and Deep Learning</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../nn/cnn.html" class="pagination-link" aria-label="Convolutional Neural Networks">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Convolutional Neural Networks</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Machine Learning in Industrial Image Processing SS 2025 (MECH-M-DUAL-2-MLB)</p>
</div>   
    <div class="nav-footer-center">
<p><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> Peter Kandolf</p>
<div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/kandolfp/MECH-M-DUAL-2-MLB/edit/main/nn/nn.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/kandolfp/MECH-M-DUAL-2-MLB/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This book was built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>