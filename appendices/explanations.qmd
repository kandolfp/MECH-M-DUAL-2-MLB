# More detailed explanations

In this section we collect more detailed explanations to help clear up some things that are only lightly touched in the main notes.

## Wavelet decomposition for cats and dogs {#sec-appendix-dvc}

In @sec-clustering-cvd we discuss how to use the wavelet transformation[^wave] to transform the image into a different basis.
Here are the details of how this is performed, with cat _zero_ as example.

[^wave]: see @Kandolf_GDM, Section 10 or follow the direct [link](https://kandolfp.github.io/MECH-M-DUAL-1-DBM/signal/wavelet.html)

```{python}
#| label: fig-appendix-clustering-cat-2-wavelet
#| fig-cap:
#|   - "The original image of cat zero."
#| code-fold: true
#| code-summary: "Show the code for the figure"
import numpy as np
import scipy
import requests
import io
import matplotlib.pyplot as plt
%config InlineBackend.figure_formats = ["svg"]

response = requests.get(
    "https://github.com/dynamicslab/databook_python/"
    "raw/refs/heads/master/DATA/catData.mat")
cats = scipy.io.loadmat(io.BytesIO(response.content))["cat"]

plt.figure()
plt.imshow(np.reshape(cats[:, 0], (64, 64)).T, cmap=plt.get_cmap("gray"))
plt.axis("off")
```
We use the Haar-Wavelet and we only need to do one level of transformation.
As per usual we get four images, each half the resolution, that represent the decomposition.
The images are, a downsampled version of the original image, one highlighting the vertical features, one highlighting the horizontal features, and one highlighting the diagonal features.

```{python}
#| label: fig-appendix-clustering-cat-2-wavelet2
#| fig-cap:
#|   - "The downsampled version of the image"
#|   - "The vertical highlights of the image."
#|   - "The horizontal highlights of the image."
#|   - "The diagonal highlights of the image"
#| layout-ncol: 2
#| code-fold: true
#| code-summary: "Show the code for the figure"
import pywt

[A_1, (cH1, cV1, cD1)] = pywt.wavedec2(np.reshape(cats[:, 0], (64, 64)).T,
                                       wavelet="haar", level=1)
plt.figure()
plt.imshow(A_1, cmap=plt.get_cmap("gray"))
plt.axis("off")
plt.figure()
plt.imshow(cH1, cmap=plt.get_cmap("gray"))
plt.axis("off")
plt.figure()
plt.imshow(cV1, cmap=plt.get_cmap("gray"))
plt.axis("off")
plt.figure()
plt.imshow(cD1, cmap=plt.get_cmap("gray"))
plt.axis("off")
```

For our purposes, only the vertical and horizontal feature are of interest, and we combine these two images.
In order to make sure the features are highlighted optimal, we need to rescale the images before combining them.
For this we use a similar function like the MATLAB [`wcodemat`](https://de.mathworks.com/help/wavelet/ref/wcodemat.html) function.

```{python}
def rescale(data, nb):
    x = np.abs(data)
    x = x - np.min(x)
    x = nb * x / np.max(x)
    x = 1 + np.fix(x)
    x[x>nb] = nb
    return x
```

```{python}
#| label: fig-appendix-clustering-cat-2-wavelet3
#| fig-cap:
#|   - "Combination of vertical and horizontal features unaltered."
#|   - "Combination of vertical and horizontal features rescaled."
#| layout-ncol: 2
#| code-fold: true
#| code-summary: "Show the code for the figure"
import pywt

plt.figure()
plt.imshow(cH1 + cV1, cmap=plt.get_cmap("gray"))
plt.axis("off")
plt.figure()
plt.imshow(rescale(cH1, 256) + rescale(cV1, 256), cmap=plt.get_cmap("gray"))
plt.axis("off")
```

In total this leads to the following function to transform a list of images (given as row vectors).

```{python}
import pywt
import math

def img2wave(images):
    l, w = data.shape
    data_w = np.zeros((l // 4, w))
    for i in range(w):
        A = np.reshape(data[:, i], (math.isqrt(l), math.isqrt(l)))
        [A_1, (cH1, cV1, cD1)] = pywt.wavedec2(A, wavelet="haar", level=1)
        data_w[:, i] = np.matrix.flatten(rescale(cH1, 256) + rescale(cV1, 256))
    return data_w
```

Note, the resulting image has only one forth of the pixels as the original image.
We can also visualize the transformation steps as follows in @fig-appendices-dvc-workflow.

![Workflow to get from the original image to the wavelet transformed version.](../_assets/appendices/catvdogs_workflow){#fig-appendices-dvc-workflow}

## Precision/Recall trade-off {#sec-appendix-pvsr}

In @sec-clustering-sl-performance we discuss the performance topics and we come across the si called _precision/recall trade-off_.

Lets remind ourself of the definitions:

Recall or true positive rate (TPR) is the rate of relevant instances that are retrieved, or _true positive_ over _all occurrences_
$$
\operatorname{recall} = \frac{TP}{P} = \frac{TP}{TP + FN}.
$$  

Precision on the other hand is the rate of relevant instances over all retrieved instances, or _true positive_ over the sum of _true positive_ and _false positive_.
$$
\operatorname{precision} = \frac{TP}{TP + FP}.
$$

In order to understand why precision and recall influence each other we need to understand how our classifier works.

Internally each observation given to the classifier is fed into a decision function that returns a score. 

The score is on some scale and in the default setting, everything above zero is counted as a match, if the threshold is set differently this can change.
See @fig-appendices-sl-pvsr-threshold.
In the presented example we can have a precision from $71\%$ to $100\%$ and at the same time a recall from $100\%$ to $60\%$.

![Some representatives and their score and three different thresholds and the corresponding results for precision and recall.](../_assets/appendices/threshold){#fig-appendices-sl-pvsr-threshold}

```{python}
#| code-fold: true
#| code-summary: "Code that provides the basis for the above figure."
#| output: false
import numpy as np
import pandas as pd
import sklearn
from sklearn.datasets import fetch_openml
from sklearn.linear_model import SGDClassifier
np.random.seed(6020)

mnist = fetch_openml('mnist_784', as_frame=False)

X_train, X_test = mnist.data[:60000], mnist.data[60000:]
y_train, y_test = mnist.target[:60000], mnist.target[60000:]

y_train_5 = (y_train == "5")
y_test_5 = (y_test == "5")

SGD = SGDClassifier(random_state=6020)
SGD.fit(X_train, y_train_5)

indices = [22698, 2, 73, 132, 244, 50, 48, 11, 0, 26873]
SGD.decision_function(X_train[indices])

im = np.zeros((1 * 28, 10 * 28), int)
for i, j in enumerate(indices):
    im[:28, 28*i: 28*(i+1)] = X_train[j].reshape(28,28)

plt.imshow(im, cmap="binary")
plt.axis("off")
```

We can also plot the entire precision/recall curves

```{python}
#| label: fig-appendix-clustering-sl-thresholds
#| fig-cap: 
#|   - "Precision and recall vs. the score of the decision function."
#|   - "Precision vs. recall."
#| code-fold: true
#| code-summary: "Show the code for the figure"
from sklearn.metrics import precision_recall_curve
from sklearn.model_selection import cross_val_predict
import matplotlib.pyplot as plt
%config InlineBackend.figure_formats = ["svg"]

y_scores = cross_val_predict(SGD, X_train, y_train_5, cv=5,
                             method="decision_function")
precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)

plt.figure()
plt.plot(thresholds, precisions[:-1], label="Precision")
plt.plot(thresholds, recalls[:-1], "--", label="Recall")
plt.xlim([-95000, 22000])
plt.xlabel("score")
plt.grid()
plt.legend()
plt.gca().set_aspect( 117000 / 3)

plt.figure()
plt.plot(recalls, precisions)
plt.xlabel("recall")
plt.ylabel("precision")
plt.grid()
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.show()
```

With the help of the precision vs. recall curve we can select a threshold appropriate for our classification, i.e. level between precision and recall as we see fit and our classification allows.