# Supervised learning {#sec-clustering-sl}

If we recall @Fischer from the Iris data set, we can also find one of the first supervised learning methods in this paper.
The introduced _linear discriminant analysis_ (LDA) has survived over time and is still one of the standard techniques for classification, even though we use a more generalized and improved method nowadays.

## Linear Discriminant Analysis (LDA)
::: {.callout-important}
The following introduction and illustrational data set, as well as the basic structure of the code is from [@Brunton2022, Code 5.9].
Also see [GitHub](https://github.com/dynamicslab/databook_python).
:::

The idea if LDA is to find a linear combination of features that optimally separates two or more classes.
The crucial part in the algorithm is that it is guided by labelled data.
At its core, the algorithm aims to solve an optimization problem: find an optimal low-dimensional embedding of the data that shows a clear separation between their point distribution, or maximize the distance between the inter-class data and minimize the intra-class data distance.

::: {.callout-tip}
For supervised learning, it is always good practice to split up your data set into a _training_ and _testing_ section.
**It is important to have a test set that the algorithm has never seen!**
In general a $80:20$ split is common but other rations might be advisable, depending on the data set. 

It is also common practice to use $k$-folds cross-validation for the training set. 
:::

::: {.callout appearance="simple"}
:::: {#def-crossvalidation}

## $k$-folds cross-validation

The $k$-folds cross-validation technique is a method to allow better _hyperparameter tuning_, especially for smaller data sets where training and validation data is small.
The main idea is that you split your iterate over different validation sets by splitting up your training set.
Lets say we use $5$-fold cross-validation we split the training set into 5 parts.
Train with 4 parts and validate against the 5th.
We than rotate and select a different validation fold.
At the end we average over the 5 iterations to get our final parameters.

This looks something like this:

![Common split with the folds 1 to 4 for training and 5 for validation in the first iteration and folds 2 to 5 for training and 1 for validation in the last. The test set is not touched.](../_assets/clustering/kfoldcrossvalidation){#fig-clustering-sl-5foldcrossvalidation}

It is important that the test set is not included in the folds to make sure you test against observations that the algorithm has never seen!
::::
:::

The main idea of LDA is to use projection.
For a two-class LDA this becomes
$$
w = \operatorname{arg\, max}_w \frac{w^\mathrm{T}S_B w}{w^\mathrm{T}S_W w},
$$ {#eq-grayleigh}
(the generalized Rayleigh quotient) where $w$ is our thought after projection and the two scatter matrices
$$
S_B = (\mu_2 - \mu_1)(\mu_2 - \mu_1)^\mathrm{T}
$$
for between-class relation as well as
$$
S_W = \sum_{j=1}^2 \sum_{x\in\mathcal{D}_j} (x - \mu_j)(x - \mu_j)^\mathrm{T}
$$
for within-class data.
The set $\mathcal{D}_j$ denotes the subdomain of the data associated with cluster $j$.
The two matrices measure the variance of the data set as well as the means.
To solve @eq-grayleigh we need to solve the generalized eigenvalue problem[^GEV]
$$
S_B w = \lambda S_w w
$$
where the maximal eigenvalue and the corresponding eigenvector are our solution.

We try this with the cats and dogs data set in both basis.

```{python}
#| label: fig-clustering-sl-lda
#| fig-cap: "Evaluation of the LDA for the second and fourth principal component on the test set of 40 animals. A bar on the in the top half corresponds to dogs and in the bottom half to cats. The first 20 individuals should be dogs, the second 20 cats. The red dotted line shows the split. True positive can be found in the top-left as well as the bottom-right."
#| fig-subcap: 
#|   - "Trained and evaluated against the raw data."
#|   - "Trained and evaluated against the data in wavelet basis."
#| code-fold: true
#| code-summary: "Show the code for the figure"
import numpy as np
import scipy
import requests
import io
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
import matplotlib.pyplot as plt
%config InlineBackend.figure_formats = ["svg"]

def analyse(CD):
    U, S, VT = np.linalg.svd(CD - np.mean(CD), full_matrices=0)
    v = VT.T
    xtrain = np.concatenate((v[:60, [1, 3]], v[80:140, [1, 3]]))
    label = np.repeat(np.array([1, -1]), 60)
    test = np.concatenate((v[60:80, [1, 3]], v[140:160, [1, 3]]))
    lda = LinearDiscriminantAnalysis()
    lda.fit(xtrain, label)
    test_class = lda.predict(test)
    truth = np.repeat(np.array([1, -1]), 20)
    E = 100 * (1 - np.sum(np.abs(test_class - truth) / 2) / 40)
    plt.figure()
    plt.bar(range(40), test_class)
    plt.plot([-0.5, 39.5], [0, 0], "k", linewidth=1.0)
    plt.plot([19.5, 19.5], [-1.1, 1.1], "r-.", linewidth=3)
    plt.yticks([-0.5, 0.5], ["cats", "dogs"], rotation=90, va="center")
    plt.text(10, 1.05, "dogs")
    plt.text(30, 1.05, "cats")
    plt.gca().set_aspect(40 / (2 * 3))
    return (test_class, E, v)


response = requests.get(
    "https://github.com/dynamicslab/databook_python/"
    "raw/refs/heads/master/DATA/catData.mat")
cats = scipy.io.loadmat(io.BytesIO(response.content))["cat"]

response = requests.get(
    "https://github.com/dynamicslab/databook_python/"
    "raw/refs/heads/master/DATA/dogData.mat")
dogs = scipy.io.loadmat(io.BytesIO(response.content))["dog"]

test_class, E, v = analyse(np.concatenate((dogs, cats), axis=1))

response = requests.get(
    "https://github.com/dynamicslab/databook_python/"
    "raw/refs/heads/master/DATA/catData_w.mat")
cats_w = scipy.io.loadmat(io.BytesIO(response.content))["cat_wave"]

response = requests.get(
    "https://github.com/dynamicslab/databook_python/"
    "raw/refs/heads/master/DATA/dogData_w.mat")
dogs_w = scipy.io.loadmat(io.BytesIO(response.content))["dog_wave"]

test_class, E_w, v_w = analyse(np.concatenate((dogs_w, cats_w), axis=1))
plt.show()
```

If we use our raw data set for the classification we get an overall accuracy of `{python} float(np.round(E, 2))`% with $\tfrac{4}{20}$ wrongly labelled dogs and $\tfrac{9}{20}$ wrongly labelled cats.
We can increase this to an accuracy of `{python} float(np.round(E_w, 2))`% with $\tfrac{5}{20}$ wrongly labelled dogs and $\tfrac{2}{20}$ wrongly labelled cats.

This could be expected, see @fig-clustering-dvc-wavelet-pca_results_overview for the separation of the principal values for the two basis. 

Of course we have very limited data with only 80 images for each of the classes.
In this case we should do a cross-validation and we have not shuffled the data.

Let us see how selecting different test and training sets influence the behaviour.

```{python}
#| label: fig-clustering-sl-lda2
#| fig-cap: "Cross validation for the data set in wavelet basis, use 100 run with different training and test sets. We always use 120 images for training and 40 for testing."
#| code-fold: true
#| code-summary: "Show the code for the figure"
import numpy as np
import scipy
import requests
import io
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
import matplotlib.pyplot as plt
%config InlineBackend.figure_formats = ["svg"]
np.random.seed(6020)

E = np.zeros(100)
for j in range(100):
    r1 = np.random.permutation(80)
    r2 = np.random.permutation(80) + 60
    ind1 = r1[:60]
    ind2 = r2[:60]
    ind1t = r1[60:80]
    ind2t = r2[60:80]
    
    xtrain = np.concatenate((v_w[ind1, :][:, [1, 3]], v_w[ind2, :][:, [1, 3]]))
    test = np.concatenate((v_w[ind1t, :][:, [1, 3]], v_w[ind2t, :][:, [1, 3]]))
    label = np.repeat(np.array([1, -1]), 60)

    lda = LinearDiscriminantAnalysis()
    test_class = lda.fit(xtrain, label).predict(test)

    truth = np.repeat(np.array([1, -1]),20)
    E[j] = 100 * (1 - np.sum(np.abs(test_class - truth) / 2) / 40)

plt.figure()
plt.bar(range(100), E)
plt.plot([0, 100], [E.mean(), E.mean()], "r-.", label="mean")
plt.plot([0, 100], [50, 50], "y-.", label='"coin toss"')
plt.xlim((-1, 100))
plt.ylim((45, 90))
plt.gca().set_aspect(100 / (45 * 3))
plt.ylabel("accuracy")
plt.xlabel("trial number")
plt.legend(loc="lower right")
plt.show()
```

With a maximal accuracy of `{python} float(E.max())`% and a minimal accuracy of `{python} float(E.min())`% our initial result with `{python} float(E_w)`% was quite good and above average (`{python} float(E.mean())`%).
We can also see that training the model is always better than just a simple _coin toss_ or random guessing for cat or dog.

Instead of a linear discriminants, we can also use quadratic discriminants.
To show the difference let us look at the classification line of the two methods for our data in wavelet basis

```{python}
#| label: fig-clustering-sl-lda3
#| fig-cap: 
#|    - "Classification line for the LDA together with actual instances."
#|    - "Classification line for the QDA together with actual instances."
#| code-fold: true
#| code-summary: "Show the code for the figure"
import numpy as np
import scipy
import requests
import io
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.inspection import DecisionBoundaryDisplay
import matplotlib.pyplot as plt
%config InlineBackend.figure_formats = ["svg"]
np.random.seed(6020)

xtrain = np.concatenate((v_w[:60, [1, 3]], v_w[80:140, [1, 3]]))
label = np.repeat(np.array([1, -1]), 60)
test = np.concatenate((v_w[60:80, [1, 3]], v_w[140:160, [1, 3]]))

plt.figure()
plt.scatter(v_w[:80, 1], v_w[:80, 3], label="dogs")
plt.scatter(v_w[80:, 1], v_w[80:, 3], label="cats")

lda = LinearDiscriminantAnalysis().fit(xtrain, label)
K = -lda.intercept_[0]
L = -lda.coef_[0]
x = np.arange(-0.12, 0.25, 0.005)
plt.plot(x, -(L[0] * x + K) / L[1], "k", label="classification line")
plt.ylim([-0.25, 0.2])
plt.xlim([-0.15, 0.25])
plt.xlabel(r"$PC_2$")
plt.ylabel(r"$PC_4$")
plt.legend()

plt.figure()
plt.scatter(v_w[:80, 1], v_w[:80, 3], label="dogs")
plt.scatter(v_w[80:, 1], v_w[80:, 3], label="cats")

qda = QuadraticDiscriminantAnalysis().fit(xtrain, label)
DecisionBoundaryDisplay.from_estimator(
        qda,
        xtrain,
        grid_resolution=2000,
        ax=plt.gca(),
        response_method="predict",
        plot_method="contour",
        alpha=1.0,
        levels=[0],
    )
plt.ylim([-0.25, 0.2])
plt.xlim([-0.15, 0.25])
plt.xlabel(r"$PC_2$")
plt.ylabel(r"$PC_4$")
plt.legend(["dogs", "cats", "classification line"])
plt.show()
```

As we can see in @fig-clustering-sl-lda3, having a quadratic discriminant classification line can be rather beneficial, like always depending on the observations.
The QDA arises from LDA when we do not assume that the covariance of each of the classes is the same. 

::: {.callout-note}
LDA and QDA assume a normal distribution as the basis for each of the clusters.
This allows us to write it also not in the here presented geometric interpretation as projection but as a update procedure with Bayes[^1] theorem,
:::

::: {.callout-tip}
Where for the LDA it is possible to get the correct function for the classification line this is tricky for the QDA.
Luckily the `scikit-learn` class/function [`DecisionBoundaryDisplay.from_estimator`](https://scikit-learn.org/1.6/modules/generated/sklearn.inspection.DecisionBoundaryDisplay.html#sklearn.inspection.DecisionBoundaryDisplay.from_estimator) can help in such cases.
:::

[^GEV]: see [@Kandolf_GDM, Definition 3.5] or the direct link [Link](https://kandolfp.github.io/MECH-M-DUAL-1-DBM/matrixdc/eigen.html#generalized-eigenvalue-problem)

[^1]: see [@Kandolf_GDM, Theorem 14.4] or the direct link [Link](https://kandolfp.github.io/MECH-M-DUAL-1-DBM/statistics/bayesian.html#def-statistics-bayesianth)

## Measuring Performance {#sec-clustering-sl-performance}

As in most applications the question how good an algorithm performs is not easy to establish.
In @fig-clustering-sl-lda2 we said we are doing better than a coin toss but we should be able to characterize this more precise.

::: {.callout-important}
The following approach and the basic structure of the code is from @Geron2022-xh, see [GitHub](https://github.com/ageron/handson-ml3/blob/main/03_classification.ipynb).
:::

In order to illustrate basic properties found in machine learning we use the MNIST data set together with a binary classifier based on Stochastic Gradient Descent. 

::: {.callout-note}
Stochastic Gradient Descent (SGD)[^SGD] is an optimization algorithm.
The key idea is to replace the actual gradient by a stochastic approximation in the optimization of the loss function.
This allows especially good performance for large-scale learning and sparse machine learning problems.

We can use this training method for classification to find the optimal parameters for our loss function an in turn, this can be used as a binary classifier.

As SGD methods are prone to a sensitivity in feature scaling and order we need to make sure to use normalized data and we should shuffle.

In `scikit-learn` we can use the class [`SGDClassifier`](https://scikit-learn.org/stable/modules/sgd.html).
:::

First we load the MNIST data set again and split it into a training and testing section, see @sec-clustering-ul-me.

```{python}
#| code-fold: true
#| code-summary: "Show the code for loading and splitting the dataset"
import numpy as np
import pandas as pd
import sklearn
from sklearn.datasets import fetch_openml
from sklearn.linear_model import SGDClassifier
np.random.seed(6020)

mnist = fetch_openml('mnist_784', as_frame=False)

X_train, X_test = mnist.data[:60000], mnist.data[60000:]
y_train, y_test = mnist.target[:60000], mnist.target[60000:]
```

Next, as we only want a binary classifier, we select one number, in our case `5` and relabel our data. 
With the new labels we can train our classifier.

```{python}
#| output: false
y_train_5 = (y_train == "5")
y_test_5 = (y_test == "5")

SGD = SGDClassifier(random_state=6020)
SGD.fit(X_train, y_train_5)
```

In order to cet a score for our method we use $k$-folds cross-validation @def-crossvalidation and the corresponding `scikit-learn` function `cross_val_score` to perform this task for our model.

```{python}
#| output: false
scores = sklearn.model_selection.cross_val_score(
    SGD, X_train, y_train_5, cv=5, scoring="accuracy")
```
```{python}
#| echo: false
pd.DataFrame({"accuracy [%]": np.round(scores * 100, 2)}).T
```

With results in the high $90\%$ range the results look promession if not great but are they really that good.
In order to get a better idea just always guess that we do not see a `5` that should be the most common class in our case.
To simulate this we use the `DummyClassifier` class.

```{python}
#| output: false
dummy = sklearn.dummy.DummyClassifier()
dummy.fit(X_train, y_train_5)
scores_dummy = sklearn.model_selection.cross_val_score(
    dummy, X_train, y_train_5, cv=5, scoring="accuracy")
```
```{python}
#| echo: false
pd.DataFrame({"accuracy [%]": np.round(scores_dummy * 100, 2)}).T
```

As this is pretty much $91\%$ (as expected there are only about $10\%$ of `5`s in the data set).
Just using accuracy is apparently not the gold standard to measure performance, what other possibilities are there?

::: {.callout appearance="simple"}
:::: {#def-confusionmatrix}

## Confusion Matrix
The confusion matrix, error matrix or for unsupervised learning sometimes called matching matrix allows an easy way of visualizing the performance of an algorithm.

The rows represent the true observations in each class, and the columns the predicted observations for each class.

In our $2\times 2$ case we get

![Names and abbreviations for a $2\times 2$ confusion matrix together with an example form our test case.](../_assets/clustering/confusion_matrix){#fig-clustering-sl-confusionmatrix}

but it can be extended for multi-class segmentation.

::::
:::

To compute the confusion matrix we first need predictions.
This can be achieved by `cross_val_predict` instead of `cross_val_score` and than we use [`sklearn.metrics.confusion_matrix`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html). 

Combined, for our example this reads as:
```{python}
#| output: false
y_train_pred = sklearn.model_selection.cross_val_predict(
                    SGD, X_train, y_train_5, cv=3)
cm = sklearn.metrics.confusion_matrix(y_train_5, y_train_pred)                   
```
```{python}
#| echo: false
df = pd.DataFrame(cm)
df.columns = ["PP", "PN"]
df["AC"] = ["P", "N"]
df.set_index("AC").rename_axis(None)
```

From the values in the confusion matrix a lot of metrics can be computed[^wikicm]:

1. **Accuracy**:
$$
ACC = \frac{TP + TN}{P + N}
$$

1. **True positive rate** (TPR) or **recall**:
$$
TPR = \frac{TP}{P}
$$

1. **False negative rate** (FNR):
$$
FNR = \frac{FN}{P}
$$

1. **False positive rate** (FPR):
$$
FPR = \frac{FP}{N}
$$

1. **True negative rate** (TNR):
$$
TNR = \frac{TN}{N}
$$

1. **Positive predictive value** (PPV) or **precission**:
$$
PPV = \frac{TP}{TP + FP}
$$

1. **False discovery rate** (FDR):
$$
FDR = \frac{FP}{TP + FP}
$$

1. **False omission rate** (FOR):
$$
FOR = \frac{FN}{TN + FN}
$$

1. **Negative predictive value** (NPV):
$$
NPV = \frac{TN}{TN + FN}
$$

1. **$F_1$ score**:
$$
F_1 = \frac{2 TP}{2 TP + FP + FN}
$$

In the [`sklearn.metrics`](https://scikit-learn.org/stable/api/sklearn.metrics.html) most of these values have a corresponding function. 
If we look at _precission_, _recall_, and the $F_1$ score, for our example we see that our performance is viewed under a different light:

```{python}
#| classes: styled-output
precision = sklearn.metrics.precision_score(y_train_5, y_train_pred)
recall = sklearn.metrics.recall_score(y_train_5, y_train_pred)
f1_score = sklearn.metrics.f1_score(y_train_5, y_train_pred)
```

This tells us that our classifier correctly classifies a `5` `{python} float(np.round(precision * 100, 2))`% of the time.
On the other hand it only _recalls_ or detects `{python} float(np.round(recall * 100, 2))`% of our `5`s.
The $F_1$-score is a combination of the two (the harmonic mean) and in our case `{python} float(np.round(f1_score * 100, 2))`%.

Depending on the application we might want to have high precision (e.g. medical diagnosis to have no unnecessary treatment) or high recall (e.g. fraud detection where a missed fraudulent transaction can be costly).
If we increase precision we reduce recall and the other way round so we can hardly have both.
This dilemma is called _precision/recall trade-off_, see @sec-appendix-pvsr for some more explanations.

An alternative way to look at accuracy for binary classifiers is to look at the _receiver operating characteristic_ (ROC).
It looks at recall (TPR) vs. the _false positive rate_ (FPR).
Other than that it works similar.

[^SGD]: see [@Kandolf_GDM, Section 6.2] or the direct link [Link](https://kandolfp.github.io/MECH-M-DUAL-1-DBM/regression/nonlinear.html#stochastic-gradient-descent)

[^wikicm]: see Wikipedia overview [Link](https://en.wikipedia.org/wiki/Confusion_matrix)

## Support Vector Machines (SVM) {#sec-clustering-sv-svm}

The basic idea of Support Vector Machines (SVM) is to split observations into distinct clusters via hyperplanes.
The have a long history in data science and come in different forms and fashions.
Over the years they became more flexible and are still one of the most used tools in industry and science. 

### Linear SVM
We start of with the linear SVM where we construct a hyperplane
$$
w \cdot x + b = 0
$$
with a vector $w$ and a constant $b$.
There is a natural degree of freedom in this selection of the hyperplane, see @fig-clustering-sl-svm for two different choices.

::: {#fig-clustering-sl-svm}

![Hyperplane with small margin.](../_assets/clustering/SVM_hyperplain1){#fig-clustering-sl-svm-1}

![Hyperplane with large margin.](../_assets/clustering/SVM_hyperplain2){#fig-clustering-sl-svm-2}

We see the hyperplane for the SVM classification scheme. The margin is much larger in the second choice.
:::

The optimization inside the SVM aims to find the line that separates the classes best (fewest wrong classifications) and also keeps the largest margin between the observations (the yellow region).
The vectors touching the edge of the yellow regions are called _support vectors_ giving the name to the algorithm.

With the hyperplane it is easy to classify an observation by simply computing the sign of the projection, i.e.
$$
y_j (w \cdot x_j + b) = \operatorname{sign}(w \cdot x_j + b) = \begin{cases} +1\\-1\end{cases},
$$
where $1$ corresponds to the versicolor (orange) and $-1$ setosa (blue) observations in @fig-clustering-sl-svm.
Therefore, the classifier depends on the position of the observation and is not invariant under scaling.

::: {.callout-caution appearance="simple" icon=false}
:::: {#exr-linear-SVM}

## Linear SVM

1. Compute the vector $w$ in the two cases of @fig-clustering-sl-svm.
The vector $w$ is normal to the line. 
For @fig-clustering-sl-svm-1 two points on the line are $v_1 = [1.25, 4.1]^\mathrm{T}$, $v_2 = [5, 7.4]^\mathrm{T}$. For @fig-clustering-sl-svm-2 two points on the line are $z_1 = [2.6, 4.25]^\mathrm{T}$, $z_2 = [2, 7]^\mathrm{T}$. 

1. Classify the two points 
$$
a = [1.4, 5.1]^\mathrm{T},
$$
$$
b = [4.7, 7.0]^\mathrm{T}.
$$
::::
:::

Stating the optimization function such that it is smooth for a linear SVM is a bit tricky.
This on the other hand is needed to allow for most optimization algorithm to work, as they require a gradient to some sort. 

Therefore, the following formulation is quite common.
$$
\underset{w, b}{\operatorname{argmin}} \sum_j H(y_j, \overline{y}_j) + \frac12\|w\|^2 \quad \text{subject to}\quad \min_j|x_j \cdot w| = 1,
$$
with $H(y_j, \overline{y}_j) = \max(0, 1-y_j \cdot \overline{y}_j)$, the so called _Hinge loss_ function for counting the number of errors. 
Furthermore, $\overline{y}_j = \operatorname{sign}(w\cdot x_j + b)$.

### Nonlinear SVM

In order to extend the SVM to more complex classification curves the feature space of the SVM can be extended.
In order to do so, SVM introduces nonlinear features and computes the hyperplane on these features via a mapping $x \to \Phi(x)$ and the hyperplane function becomes
$$
w \cdot \Phi(x) + b
$$
and accordingly we classify along
$$
\operatorname{sign}(w \cdot \Phi(x_j) + b).
$$

Essentially, we change the feature space such that a separation is (hopefully) easier.
To illustrate this we use a simple one dimensional example as illustrated in @fig-clustering-sl-svm-nl-1.
Clearly there is no _linear_ separation possible.
On the other hand, if we use 
$$
\Phi(x_j) = (x_j, x_j^2) 
$$
as our transformation function we move to 2D space and the problem can easily be solved by a line at $y=0.25$.

```{python}
#| label: fig-clustering-sl-svm-nl
#| fig-cap: "Nonlinear classification with SVM."
#| fig-subcap: 
#|   - "Observations that can not be separated linearly."
#|   - "Enriched feature set with Φ(x)=(x, x^2)."
#| code-fold: true
#| code-summary: "Show the code for the figure"
import numpy as np
from sklearn.svm import LinearSVC
import matplotlib.pyplot as plt
%config InlineBackend.figure_formats = ["svg"]
np.random.seed(6020)

x = np.linspace(-1, 1, 11, endpoint=True)
x2 = np.zeros_like(x)
y = np.zeros_like(x)
y[np.abs(x) < 0.5] = 1

plt.figure()
plt.scatter(x[y==0], x2[y==0], label="class 1")
plt.scatter(x[y==1], x2[y==1], label="class 2")
plt.ylim([-0.1, 1])
plt.xlim([-1, 1])
plt.gca().set_aspect(2/3.3)
plt.legend()

x2 = np.power(x, 2)

plt.figure()
data = np.stack([x.flatten(), x2.flatten()]).T
svm = LinearSVC(random_state=6020).fit(data, y.flatten())
plt.scatter(x[y==0], x2[y==0], label="class 1")
plt.scatter(x[y==1], x2[y==1], label="class 2")
plt.ylim([-0.1, 1])
plt.xlim([-1, 1])
w = svm.coef_[0]
d = svm.intercept_[0]
line = lambda x: -w[0] / w[1] * x - d / w[1]
plt.plot([-1, 1], [line(-1), line(1)], "k", label="classification line")
plt.plot([-1, 1], [0.25, 0.25], "k:", label="actual boundary line")
plt.gca().set_aspect(2/3.3)
plt.legend()

plt.show()
```

As can be seen in @fig-clustering-sl-svm-nl-2 the SVM does a great job in finding a split for the two classes, even though not select the _optimal_ line, which is not surprising for the given amount of observations. 

As mentioned before, SVMs are sensitive to scaling.
Let us use this example to illustrate the difference together with the concept of _pipelines_ often used in data science context.

::: {.callout-note}
## Pipeline
The main idea of a pipeline is to create a composite as a ordered chain of transformations and estimators, see [docs](https://scikit-learn.org/stable/modules/compose.html) for insights.
:::

We can use the pipeline to
- create the polynomial observations
- apply a scaler to our observations
- apply the Linear SVM

```{python}
composit_svm = sklearn.pipeline.make_pipeline(
    sklearn.preprocessing.PolynomialFeatures(2),
    sklearn.preprocessing.StandardScaler(),
    LinearSVC(random_state=6020)
)
```

```{python}
#| label: fig-clustering-sl-svm-nl-3
#| fig-cap: "Classification with autoscaler vs. no scaler."
#| fig-subcap: 
#|   - "Classification in the enriched Φ(x)=(x^0, x^1, x^2) and scaled space. Note the first dimension is ignored."
#|   - "Difference between the classification lines when transformed back into the original space."
#| code-fold: true
#| code-summary: "Show the code for the figure"
import numpy as np
from sklearn.svm import LinearSVC
import matplotlib.pyplot as plt
%config InlineBackend.figure_formats = ["svg"]
np.random.seed(6020)

x = np.linspace(-1, 1, 11, endpoint=True).reshape(-1, 1)
y = np.zeros_like(x).flatten()
y[np.abs(x.flatten()) < 0.5] = 1

composit_svm.fit(x, y)

xx = composit_svm[:2].fit_transform(x)

plt.figure()
plt.scatter(xx[y==0, 1], xx[y==0, 2], label="class 1")
plt.scatter(xx[y==1, 1], xx[y==1, 2], label="class 2")

w = composit_svm['linearsvc'].coef_[0][1:]
d = composit_svm['linearsvc'].intercept_[0]
plt.plot([-1.6, 1.6], [line(-1.5), line(1.5)],
         "k", label="scaled classification line")

plt.ylim([-1.25, 1.75])
plt.xlim([-1.6, 1.6])
plt.gca().set_aspect(3/9)
plt.legend()

xx = composit_svm[:1].fit_transform(x)
plt.figure()
plt.scatter(xx[y==0, 1], xx[y==0, 2], label="class 1")
plt.scatter(xx[y==1, 1], xx[y==1, 2], label="class 2")

w = composit_svm['linearsvc'].coef_[0][1:]
d = composit_svm['linearsvc'].intercept_[0]
a = composit_svm["standardscaler"].inverse_transform(
    [np.array([0, -1.6, line(-1.6)])])[0]
b = composit_svm["standardscaler"].inverse_transform(
    [np.array([0, 1.6, line(1.6)])])[0]
plt.plot([a[1], b[1]], [a[2], b[2]], 
         "k", label="scaled classification line")

w = svm.coef_[0]
d = svm.intercept_[0]
plt.plot([-1, 1], [line(-1), line(1)], 
            "k:", label="unscaled classification line")

plt.ylim([-0.1, 1])
plt.xlim([-1, 1])
plt.gca().set_aspect(2/3.3)
plt.legend()
plt.show()
```

::: {.callout-caution appearance="simple" icon=false}
:::: {#exr-nonlinear-SVM}

## Nonlinear SVM

1. Extend the above findings to an example in 2D with a circular classification line.
Create tests data of your classification by changing to `np.linspace(-1, 1, 12)`.
```{python}
#| label: fig-clustering-sl-svm-nl-exr
#| fig-cap: "Data set in 2D"
#| code-fold: true
#| code-summary: "Show the code for the figure"
import numpy as np
from sklearn.svm import LinearSVC
import sklearn
import matplotlib.pyplot as plt
%config InlineBackend.figure_formats = ["svg"]

np.random.seed(6020)
x = np.linspace(-1, 1, 11, endpoint=True)
x2 = np.linspace(-1, 1, 11, endpoint=True)
XX, XX2 = np.meshgrid(x, x2)
ZZ = np.pow(XX, 2) + np.pow(XX2, 2)
y = np.zeros_like(XX)

i = np.sqrt(ZZ) < 0.5
y[i] = 1
plt.scatter(XX[y == 0], XX2[y == 0], label="class 1")
plt.scatter(XX[y == 1], XX2[y == 1], label="class 2")

data = np.stack([XX.flatten(), XX2.flatten(), ZZ.flatten()]).T
label = y.flatten()
```

2. Recall the moons example from @sec-clustering-ul-dbscan and use a degree $3$ `PolynomialFeatures` for classification.

In both cases, plot the classification line in a projection onto the original 2D space.
::::
:::
