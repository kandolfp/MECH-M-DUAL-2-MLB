<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>2&nbsp; Supervised learning – Machine Learning in Industrial Image Processing</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../clustering/semisupervised.html" rel="next">
<link href="../clustering/unsupervised.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark-8ef56b68f8fa1e9d2ba328e99e439f80.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-396a8ca7a22f3fd420d3bfa4e06e1479.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark-ee05651f5575b4d404d9d8b9add92005.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../site_libs/bootstrap/bootstrap-396a8ca7a22f3fd420d3bfa4e06e1479.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script src="../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const queryPrefersDark = window.matchMedia('(prefers-color-scheme: dark)');
    const darkModeDefault = queryPrefersDark.matches;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    queryPrefersDark.addEventListener("change", e => {
      if(window.localStorage.getItem("quarto-color-scheme") !== null)
        return;
      const alternate = e.matches
      toggleColorMode(alternate);
      localAlternateSentinel = e.matches ? 'alternate' : 'default'; // this is used alongside local storage!
      toggleGiscusIfUsed(alternate, darkModeDefault);
    });
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../clustering/index.html">Clustering and Classification</a></li><li class="breadcrumb-item"><a href="../clustering/supervised.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Supervised learning</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Machine Learning in Industrial Image Processing</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/kandolfp/MECH-M-DUAL-2-MLB/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../clustering/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Clustering and Classification</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../clustering/unsupervised.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Unsupervised learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../clustering/supervised.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Supervised learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../clustering/semisupervised.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Semi-Supervised learning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../data/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Management and Data Engineering</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../data/model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Model persistence</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../data/code.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Code persistence</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../data/data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Data persistence</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../nn/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Neural Networks and Deep Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../nn/nn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../nn/cnn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Convolutional Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../nn/autoencoder.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Autoencoders</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../nn/transfer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Transfer learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../nn/data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Data Preparation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../nn/challenges.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Common Challenges</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Summary</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendices/explanations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">More detailed explanations</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendices/keras.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Our first Neural Network in <code>tensorflow.keras</code></span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-clustering-sl-lda" id="toc-sec-clustering-sl-lda" class="nav-link active" data-scroll-target="#sec-clustering-sl-lda"><span class="header-section-number">2.1</span> Linear Discriminant Analysis (LDA)</a></li>
  <li><a href="#sec-clustering-sl-performance" id="toc-sec-clustering-sl-performance" class="nav-link" data-scroll-target="#sec-clustering-sl-performance"><span class="header-section-number">2.2</span> Measuring Performance</a></li>
  <li><a href="#sec-clustering-sv-svm" id="toc-sec-clustering-sv-svm" class="nav-link" data-scroll-target="#sec-clustering-sv-svm"><span class="header-section-number">2.3</span> Support Vector Machine (SVM)</a>
  <ul class="collapse">
  <li><a href="#linear-svm" id="toc-linear-svm" class="nav-link" data-scroll-target="#linear-svm"><span class="header-section-number">2.3.1</span> Linear SVM</a></li>
  <li><a href="#nonlinear-svm" id="toc-nonlinear-svm" class="nav-link" data-scroll-target="#nonlinear-svm"><span class="header-section-number">2.3.2</span> Nonlinear SVM</a></li>
  <li><a href="#kernel-methods-for-svm" id="toc-kernel-methods-for-svm" class="nav-link" data-scroll-target="#kernel-methods-for-svm"><span class="header-section-number">2.3.3</span> Kernel Methods for SVM</a></li>
  </ul></li>
  <li><a href="#decision-trees" id="toc-decision-trees" class="nav-link" data-scroll-target="#decision-trees"><span class="header-section-number">2.4</span> Decision trees</a></li>
  <li><a href="#ensemble-learning-and-random-forests" id="toc-ensemble-learning-and-random-forests" class="nav-link" data-scroll-target="#ensemble-learning-and-random-forests"><span class="header-section-number">2.5</span> Ensemble learning and random forests</a></li>
  <li><a href="#multiclass-classification" id="toc-multiclass-classification" class="nav-link" data-scroll-target="#multiclass-classification"><span class="header-section-number">2.6</span> Multiclass Classification</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/kandolfp/MECH-M-DUAL-2-MLB/edit/main/clustering/supervised.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/kandolfp/MECH-M-DUAL-2-MLB/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../clustering/index.html">Clustering and Classification</a></li><li class="breadcrumb-item"><a href="../clustering/supervised.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Supervised learning</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-clustering-sl" class="quarto-section-identifier"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Supervised learning</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>If we recall <span class="citation" data-cites="Fischer">Fisher (<a href="../references.html#ref-Fischer" role="doc-biblioref">1936</a>)</span> from the Iris dataset, we can also find one of the first supervised learning methods in this paper. The introduced <em>linear discriminant analysis</em> (LDA) has survived over time and is still one of the standard techniques for classification, even though we use a more generalized and improved method nowadays.</p>
<section id="sec-clustering-sl-lda" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="sec-clustering-sl-lda"><span class="header-section-number">2.1</span> Linear Discriminant Analysis (LDA)</h2>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>The following introduction and illustrational dataset, as well as the basic structure of the code is from <span class="citation" data-cites="Brunton2022">(<a href="../references.html#ref-Brunton2022" role="doc-biblioref">Brunton and Kutz 2022</a>, Code 5.9)</span>. Also see <a href="https://github.com/dynamicslab/databook_python">GitHub</a>.</p>
</div>
</div>
<p>The idea of LDA is to find a linear combination of features that optimally separates two or more classes. The crucial part in the algorithm is that it is guided by labelled observations. At its core, the algorithm aims to solve an optimization problem: find an optimal low-dimensional embedding of the data that shows a clear separation between their point distribution, or maximize the distance between the inter-class data and minimize the intra-class data distance.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>For supervised learning, it is always good practice to split up our dataset into a <em>training</em> and <em>testing</em> section. <strong>It is important to have a test set that the algorithm has never seen!</strong> In general a <span class="math inline">\(80:20\)</span> split is common but other ratios might be advisable, depending on the dataset.</p>
<p>It is also common practice to use <span class="math inline">\(k\)</span>-folds cross-validation for the training set.</p>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-crossvalidation" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2.1 (<span class="math inline">\(k\)</span>-folds cross-validation)</strong></span> The <span class="math inline">\(k\)</span>-folds cross-validation technique is a method to allow better <em>hyperparameter tuning</em>, especially for smaller datasets where training and validation data is small. The main idea is that we split our iterate over different validation sets by splitting up our training set. Lets say we use <span class="math inline">\(5\)</span>-fold cross-validation we split the training set into 5 parts. Therefore, we train the model with four parts and validate against the fifth. We then rotate the folds and select a different one for validation. At the end, we average over the five iterations to get our final parameters.</p>
<p>This looks something like this:</p>
<div id="fig-clustering-sl-5foldcrossvalidation" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-clustering-sl-5foldcrossvalidation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="../_assets/clustering/kfoldcrossvalidation.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;2.1: Common split with the folds 1 to 4 for training and 5 for validation in the first iteration and folds 2 to 5 for training and 1 for validation in the last. The test set is not touched."><img src="../_assets/clustering/kfoldcrossvalidation.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-clustering-sl-5foldcrossvalidation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.1: Common split with the folds 1 to 4 for training and 5 for validation in the first iteration and folds 2 to 5 for training and 1 for validation in the last. The test set is not touched.
</figcaption>
</figure>
</div>
<p>It is important that the test set is not included in the folds to make sure we test against observations that the algorithm has never seen!</p>
</div>
</div>
</div>
</div>
<p>The main idea of LDA is to use projection. For a two-class LDA this becomes <span id="eq-grayleigh"><span class="math display">\[
w = \operatorname{arg\, max}_w \frac{w^\mathrm{T}S_B w}{w^\mathrm{T}S_W w},
\tag{2.1}\]</span></span> (the generalized Rayleigh quotient) where <span class="math inline">\(w\)</span> is our thought after projection. The two included scatter matrices are <span class="math display">\[
S_B = (\mu_2 - \mu_1)(\mu_2 - \mu_1)^\mathrm{T},
\]</span> for between-class relation as well as <span class="math display">\[
S_W = \sum_{j=1}^2 \sum_{x\in\mathcal{D}_j} (x - \mu_j)(x - \mu_j)^\mathrm{T},
\]</span> for within-class data. The set <span class="math inline">\(\mathcal{D}_j\)</span> denotes the subdomain of the data associated with cluster <span class="math inline">\(j\)</span>. The two matrices measure the variance of the dataset as well as the means. To solve <a href="#eq-grayleigh" class="quarto-xref">Equation&nbsp;<span>2.1</span></a> we need to solve the generalized eigenvalue problem<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> <span class="math display">\[
S_B w = \lambda S_w w
\]</span> where the maximal eigenvalue and the corresponding eigenvector are our solution.</p>
<p>We try this with the cats and dogs dataset in both basis.</p>
<div class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Show the code for the figure</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> io</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.discriminant_analysis <span class="im">import</span> LinearDiscriminantAnalysis</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.discriminant_analysis <span class="im">import</span> QuadraticDiscriminantAnalysis</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>config InlineBackend.figure_formats <span class="op">=</span> [<span class="st">"svg"</span>]</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> analyse(CD):</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    U, S, VT <span class="op">=</span> np.linalg.svd(CD <span class="op">-</span> np.mean(CD), full_matrices<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    v <span class="op">=</span> VT.T</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    xtrain <span class="op">=</span> np.concatenate((v[:<span class="dv">60</span>, [<span class="dv">1</span>, <span class="dv">3</span>]], v[<span class="dv">80</span>:<span class="dv">140</span>, [<span class="dv">1</span>, <span class="dv">3</span>]]))</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    label <span class="op">=</span> np.repeat(np.array([<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>]), <span class="dv">60</span>)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    test <span class="op">=</span> np.concatenate((v[<span class="dv">60</span>:<span class="dv">80</span>, [<span class="dv">1</span>, <span class="dv">3</span>]], v[<span class="dv">140</span>:<span class="dv">160</span>, [<span class="dv">1</span>, <span class="dv">3</span>]]))</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    lda <span class="op">=</span> LinearDiscriminantAnalysis()</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    lda.fit(xtrain, label)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    test_class <span class="op">=</span> lda.predict(test)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    truth <span class="op">=</span> np.repeat(np.array([<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>]), <span class="dv">20</span>)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    E <span class="op">=</span> <span class="dv">100</span> <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> np.<span class="bu">sum</span>(np.<span class="bu">abs</span>(test_class <span class="op">-</span> truth) <span class="op">/</span> <span class="dv">2</span>) <span class="op">/</span> <span class="dv">40</span>)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    plt.figure()</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>    plt.bar(<span class="bu">range</span>(<span class="dv">40</span>), test_class)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    plt.plot([<span class="op">-</span><span class="fl">0.5</span>, <span class="fl">39.5</span>], [<span class="dv">0</span>, <span class="dv">0</span>], <span class="st">"k"</span>, linewidth<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    plt.plot([<span class="fl">19.5</span>, <span class="fl">19.5</span>], [<span class="op">-</span><span class="fl">1.1</span>, <span class="fl">1.1</span>], <span class="st">"r-."</span>, linewidth<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    plt.yticks([<span class="op">-</span><span class="fl">0.5</span>, <span class="fl">0.5</span>], [<span class="st">"cats"</span>, <span class="st">"dogs"</span>], rotation<span class="op">=</span><span class="dv">90</span>, va<span class="op">=</span><span class="st">"center"</span>)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    plt.text(<span class="dv">10</span>, <span class="fl">1.05</span>, <span class="st">"dogs"</span>)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    plt.text(<span class="dv">30</span>, <span class="fl">1.05</span>, <span class="st">"cats"</span>)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    plt.gca().set_aspect(<span class="dv">40</span> <span class="op">/</span> (<span class="dv">2</span> <span class="op">*</span> <span class="dv">3</span>))</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (test_class, E, v)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> requests.get(</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>    <span class="st">"https://github.com/dynamicslab/databook_python/"</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>    <span class="st">"raw/refs/heads/master/DATA/catData.mat"</span>)</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>cats <span class="op">=</span> scipy.io.loadmat(io.BytesIO(response.content))[<span class="st">"cat"</span>]</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> requests.get(</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>    <span class="st">"https://github.com/dynamicslab/databook_python/"</span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>    <span class="st">"raw/refs/heads/master/DATA/dogData.mat"</span>)</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>dogs <span class="op">=</span> scipy.io.loadmat(io.BytesIO(response.content))[<span class="st">"dog"</span>]</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>test_class, E, v <span class="op">=</span> analyse(np.concatenate((dogs, cats), axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> requests.get(</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>    <span class="st">"https://github.com/dynamicslab/databook_python/"</span></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>    <span class="st">"raw/refs/heads/master/DATA/catData_w.mat"</span>)</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>cats_w <span class="op">=</span> scipy.io.loadmat(io.BytesIO(response.content))[<span class="st">"cat_wave"</span>]</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> requests.get(</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>    <span class="st">"https://github.com/dynamicslab/databook_python/"</span></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>    <span class="st">"raw/refs/heads/master/DATA/dogData_w.mat"</span>)</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>dogs_w <span class="op">=</span> scipy.io.loadmat(io.BytesIO(response.content))[<span class="st">"dog_wave"</span>]</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>test_class, E_w, v_w <span class="op">=</span> analyse(np.concatenate((dogs_w, cats_w), axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="fig-clustering-sl-lda" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="1">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-clustering-sl-lda-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-display">
<div id="fig-clustering-sl-lda-1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-clustering-sl-lda-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="supervised_files/figure-html/fig-clustering-sl-lda-output-1.svg" class="lightbox" data-gallery="fig-clustering-sl-lda" title="Figure&nbsp;2.2&nbsp;(a): Trained and evaluated against the raw data."><img src="supervised_files/figure-html/fig-clustering-sl-lda-output-1.svg" class="img-fluid figure-img" data-ref-parent="fig-clustering-sl-lda"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-clustering-sl-lda-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Trained and evaluated against the raw data.
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div id="fig-clustering-sl-lda-2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-clustering-sl-lda-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="supervised_files/figure-html/fig-clustering-sl-lda-output-2.svg" class="lightbox" data-gallery="fig-clustering-sl-lda" title="Figure&nbsp;2.2&nbsp;(b): Trained and evaluated against the data in wavelet basis."><img src="supervised_files/figure-html/fig-clustering-sl-lda-output-2.svg" class="img-fluid figure-img" data-ref-parent="fig-clustering-sl-lda"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-clustering-sl-lda-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Trained and evaluated against the data in wavelet basis.
</figcaption>
</figure>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-clustering-sl-lda-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.2: Evaluation of the LDA for the second and fourth principal component on the test set of 40 animals. A bar going up corresponds to dogs and one going down to cats. The first 20 individuals should be dogs, the second 20 cats. The red dotted line shows the split. True positive can be found in the top-left as well as the bottom-right.
</figcaption>
</figure>
</div>
</div>
<p>If we use our raw dataset for the classification we get an overall accuracy of 67.5% with <span class="math inline">\(\tfrac{4}{20}\)</span> wrongly labelled dogs and <span class="math inline">\(\tfrac{9}{20}\)</span> wrongly labelled cats. We can increase this to an accuracy of 82.5% with <span class="math inline">\(\tfrac{5}{20}\)</span> wrongly labelled dogs and <span class="math inline">\(\tfrac{2}{20}\)</span> wrongly labelled cats.</p>
<p>This could be expected, see <a href="index.html#fig-clustering-dvc-wavelet-pca_results_overview" class="quarto-xref">Figure&nbsp;<span>10</span></a> for the separation of the principal values for the two basis.</p>
<p>Of course we have very limited data with only 80 images for each of the classes. In this case we should do a cross-validation and we have not shuffled the data.</p>
<p>Let us see how selecting different test and training sets influence the behaviour.</p>
<div id="cell-fig-clustering-sl-lda2" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Show the code for the figure</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> io</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.discriminant_analysis <span class="im">import</span> LinearDiscriminantAnalysis</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.discriminant_analysis <span class="im">import</span> QuadraticDiscriminantAnalysis</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>config InlineBackend.figure_formats <span class="op">=</span> [<span class="st">"svg"</span>]</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">6020</span>)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>E <span class="op">=</span> np.zeros(<span class="dv">100</span>)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    r1 <span class="op">=</span> np.random.permutation(<span class="dv">80</span>)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    r2 <span class="op">=</span> np.random.permutation(<span class="dv">80</span>) <span class="op">+</span> <span class="dv">60</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    ind1 <span class="op">=</span> r1[:<span class="dv">60</span>]</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    ind2 <span class="op">=</span> r2[:<span class="dv">60</span>]</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    ind1t <span class="op">=</span> r1[<span class="dv">60</span>:<span class="dv">80</span>]</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    ind2t <span class="op">=</span> r2[<span class="dv">60</span>:<span class="dv">80</span>]</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    xtrain <span class="op">=</span> np.concatenate((v_w[ind1, :][:, [<span class="dv">1</span>, <span class="dv">3</span>]], v_w[ind2, :][:, [<span class="dv">1</span>, <span class="dv">3</span>]]))</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    test <span class="op">=</span> np.concatenate((v_w[ind1t, :][:, [<span class="dv">1</span>, <span class="dv">3</span>]], v_w[ind2t, :][:, [<span class="dv">1</span>, <span class="dv">3</span>]]))</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>    label <span class="op">=</span> np.repeat(np.array([<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>]), <span class="dv">60</span>)</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    lda <span class="op">=</span> LinearDiscriminantAnalysis()</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>    test_class <span class="op">=</span> lda.fit(xtrain, label).predict(test)</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>    truth <span class="op">=</span> np.repeat(np.array([<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>]),<span class="dv">20</span>)</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>    E[j] <span class="op">=</span> <span class="dv">100</span> <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> np.<span class="bu">sum</span>(np.<span class="bu">abs</span>(test_class <span class="op">-</span> truth) <span class="op">/</span> <span class="dv">2</span>) <span class="op">/</span> <span class="dv">40</span>)</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>plt.figure()</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>plt.bar(<span class="bu">range</span>(<span class="dv">100</span>), E)</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">100</span>], [E.mean(), E.mean()], <span class="st">"r-."</span>, label<span class="op">=</span><span class="st">"mean"</span>)</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">100</span>], [<span class="dv">50</span>, <span class="dv">50</span>], <span class="st">"y-."</span>, label<span class="op">=</span><span class="st">'"coin toss"'</span>)</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>plt.xlim((<span class="op">-</span><span class="dv">1</span>, <span class="dv">100</span>))</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>plt.ylim((<span class="dv">45</span>, <span class="dv">90</span>))</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>plt.gca().set_aspect(<span class="dv">100</span> <span class="op">/</span> (<span class="dv">45</span> <span class="op">*</span> <span class="dv">3</span>))</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"accuracy"</span>)</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"trial number"</span>)</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">"lower right"</span>)</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-clustering-sl-lda2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-clustering-sl-lda2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="supervised_files/figure-html/fig-clustering-sl-lda2-output-1.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Figure&nbsp;2.3: Cross validation for the dataset in wavelet basis, use 100 run with different training and test sets. We always use 120 images for training and 40 for testing."><img src="supervised_files/figure-html/fig-clustering-sl-lda2-output-1.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-clustering-sl-lda2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.3: Cross validation for the dataset in wavelet basis, use 100 run with different training and test sets. We always use 120 images for training and 40 for testing.
</figcaption>
</figure>
</div>
</div>
</div>
<p>With a maximal accuracy of 90.0% and a minimal accuracy of 65.0% our initial result with 82.5% was quite good and above average (77.1%). We can also see that training the model is always better than just a simple <em>coin toss</em> or random guessing for cat or dog.</p>
<p>Instead of a linear discriminants, we can also use quadratic discriminants. To show the difference let us look at the classification line of the two methods for our data in wavelet basis</p>
<div id="cell-fig-clustering-sl-lda3" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Show the code for the figure</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> io</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.discriminant_analysis <span class="im">import</span> LinearDiscriminantAnalysis</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.discriminant_analysis <span class="im">import</span> QuadraticDiscriminantAnalysis</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.inspection <span class="im">import</span> DecisionBoundaryDisplay</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>config InlineBackend.figure_formats <span class="op">=</span> [<span class="st">"svg"</span>]</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">6020</span>)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>xtrain <span class="op">=</span> np.concatenate((v_w[:<span class="dv">60</span>, [<span class="dv">1</span>, <span class="dv">3</span>]], v_w[<span class="dv">80</span>:<span class="dv">140</span>, [<span class="dv">1</span>, <span class="dv">3</span>]]))</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>label <span class="op">=</span> np.repeat(np.array([<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>]), <span class="dv">60</span>)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>test <span class="op">=</span> np.concatenate((v_w[<span class="dv">60</span>:<span class="dv">80</span>, [<span class="dv">1</span>, <span class="dv">3</span>]], v_w[<span class="dv">140</span>:<span class="dv">160</span>, [<span class="dv">1</span>, <span class="dv">3</span>]]))</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>plt.figure()</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>plt.scatter(v_w[:<span class="dv">80</span>, <span class="dv">1</span>], v_w[:<span class="dv">80</span>, <span class="dv">3</span>], label<span class="op">=</span><span class="st">"dogs"</span>)</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>plt.scatter(v_w[<span class="dv">80</span>:, <span class="dv">1</span>], v_w[<span class="dv">80</span>:, <span class="dv">3</span>], label<span class="op">=</span><span class="st">"cats"</span>)</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>lda <span class="op">=</span> LinearDiscriminantAnalysis().fit(xtrain, label)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>K <span class="op">=</span> <span class="op">-</span>lda.intercept_[<span class="dv">0</span>]</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>L <span class="op">=</span> <span class="op">-</span>lda.coef_[<span class="dv">0</span>]</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.arange(<span class="op">-</span><span class="fl">0.12</span>, <span class="fl">0.25</span>, <span class="fl">0.005</span>)</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>plt.plot(x, <span class="op">-</span>(L[<span class="dv">0</span>] <span class="op">*</span> x <span class="op">+</span> K) <span class="op">/</span> L[<span class="dv">1</span>], <span class="st">"k"</span>, label<span class="op">=</span><span class="st">"classification line"</span>)</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>plt.ylim([<span class="op">-</span><span class="fl">0.25</span>, <span class="fl">0.2</span>])</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>plt.xlim([<span class="op">-</span><span class="fl">0.15</span>, <span class="fl">0.25</span>])</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="vs">r"</span><span class="dv">$</span><span class="vs">PC_2</span><span class="dv">$</span><span class="vs">"</span>)</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="vs">r"</span><span class="dv">$</span><span class="vs">PC_4</span><span class="dv">$</span><span class="vs">"</span>)</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>plt.figure()</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>plt.scatter(v_w[:<span class="dv">80</span>, <span class="dv">1</span>], v_w[:<span class="dv">80</span>, <span class="dv">3</span>], label<span class="op">=</span><span class="st">"dogs"</span>)</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>plt.scatter(v_w[<span class="dv">80</span>:, <span class="dv">1</span>], v_w[<span class="dv">80</span>:, <span class="dv">3</span>], label<span class="op">=</span><span class="st">"cats"</span>)</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>qda <span class="op">=</span> QuadraticDiscriminantAnalysis().fit(xtrain, label)</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>DecisionBoundaryDisplay.from_estimator(</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>        qda,</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>        xtrain,</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>        grid_resolution<span class="op">=</span><span class="dv">2000</span>,</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>        ax<span class="op">=</span>plt.gca(),</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>        response_method<span class="op">=</span><span class="st">"predict"</span>,</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>        plot_method<span class="op">=</span><span class="st">"contour"</span>,</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>        alpha<span class="op">=</span><span class="fl">1.0</span>,</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>        levels<span class="op">=</span>[<span class="dv">0</span>],</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>plt.ylim([<span class="op">-</span><span class="fl">0.25</span>, <span class="fl">0.2</span>])</span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>plt.xlim([<span class="op">-</span><span class="fl">0.15</span>, <span class="fl">0.25</span>])</span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="vs">r"</span><span class="dv">$</span><span class="vs">PC_2</span><span class="dv">$</span><span class="vs">"</span>)</span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="vs">r"</span><span class="dv">$</span><span class="vs">PC_4</span><span class="dv">$</span><span class="vs">"</span>)</span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a>plt.legend([<span class="st">"dogs"</span>, <span class="st">"cats"</span>, <span class="st">"classification line"</span>])</span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-clustering-sl-lda3" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-clustering-sl-lda3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="supervised_files/figure-html/fig-clustering-sl-lda3-output-1.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Figure&nbsp;2.4: Classification line for the LDA together with actual instances."><img src="supervised_files/figure-html/fig-clustering-sl-lda3-output-1.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-clustering-sl-lda3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.4: Classification line for the LDA together with actual instances.
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div id="fig-clustering-sl-lda3" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-clustering-sl-lda3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="supervised_files/figure-html/fig-clustering-sl-lda3-output-2.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="Figure&nbsp;2.5: Classification line for the QDA together with actual instances."><img src="supervised_files/figure-html/fig-clustering-sl-lda3-output-2.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-clustering-sl-lda3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.5: Classification line for the QDA together with actual instances.
</figcaption>
</figure>
</div>
</div>
</div>
<p>As we can see in <a href="#fig-clustering-sl-lda3" class="quarto-xref">Figure&nbsp;<span>2.5</span></a>, having a quadratic discriminant classification line can be rather beneficial, like always depending on the observations. The QDA arises from LDA when we do not assume that the covariance of each of the classes is the same.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>LDA and QDA assume a normal distribution as the basis for each of the clusters. This allows us to write it also as an update procedure with Bayes<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> theorem.</p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Where for the LDA it is possible to get the correct function for the classification line this is tricky for the QDA. Luckily the <code>scikit-learn</code> class/function <a href="https://scikit-learn.org/1.6/modules/generated/sklearn.inspection.DecisionBoundaryDisplay.html#sklearn.inspection.DecisionBoundaryDisplay.from_estimator"><code>DecisionBoundaryDisplay.from_estimator</code></a> can help in such cases.</p>
</div>
</div>
<div class="callout callout-style-simple callout-caution no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exr-lda" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 2.1 (Application of LDA)</strong></span> &nbsp;</p>
<ol type="1">
<li><p>Apply the LDA algorithm to the toy example (see <a href="unsupervised.html#fig-clustering-unsupervised_lloyd" class="quarto-xref">Figure&nbsp;<span>1.1</span></a>) to recover the two clusters as good as possible.</p></li>
<li><p>Additionally, for a higher dimensional problem, using LDA split the Fischer Iris dataset (see the introduction to part of the notes) into two clusters. Try for the harder split between <code>versicolor</code> and <code>virginica</code> types of flowers.</p></li>
</ol>
</div>
</div>
</div>
</div>
</section>
<section id="sec-clustering-sl-performance" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="sec-clustering-sl-performance"><span class="header-section-number">2.2</span> Measuring Performance</h2>
<p>As in most applications, the question how good an algorithm performs is not easy to establish. In <a href="#fig-clustering-sl-lda2" class="quarto-xref">Figure&nbsp;<span>2.3</span></a>, we implied we are doing better than a coin toss but we should be able to characterize this more precise.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>The following approach and the basic structure of the code is from <span class="citation" data-cites="Geron2022-xh">Geron (<a href="../references.html#ref-Geron2022-xh" role="doc-biblioref">2022</a>)</span>, see <a href="https://github.com/ageron/handson-ml3/blob/main/03_classification.ipynb">GitHub</a>.</p>
</div>
</div>
<p>In order to illustrate basic properties found in machine learning we use the MNIST dataset together with a binary classifier based on Stochastic Gradient Descent, see <a href="unsupervised.html#sec-clustering-ul-me" class="quarto-xref"><span>Section 1.5</span></a> for more on the MNIST dataset.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Stochastic Gradient Descent (SGD)<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> is an optimization algorithm. The key idea is to replace the actual gradient by a stochastic approximation in the optimization of the loss function. This allows especially good performance for large-scale learning and sparse machine learning problems.</p>
<p>We can use this training method for classification to find the optimal parameters for our loss function and in turn, this can be used as a binary classifier.</p>
<p>As SGD methods are prone to a sensitivity in feature scaling and order we need to make sure to use normalized data and we should shuffle.</p>
<p>In <code>scikit-learn</code> we can use the class <a href="https://scikit-learn.org/stable/modules/sgd.html"><code>SGDClassifier</code></a>.</p>
</div>
</div>
<p>First we load the MNIST dataset again and split it into a training and testing section, see <a href="unsupervised.html#sec-clustering-ul-me" class="quarto-xref"><span>Section 1.5</span></a>.</p>
<div id="0a2811d7" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Show the code for loading and splitting the dataset</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_openml</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> SGDClassifier</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">6020</span>)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>mnist <span class="op">=</span> fetch_openml(<span class="st">'mnist_784'</span>, as_frame<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>X_train, X_test <span class="op">=</span> mnist.data[:<span class="dv">60000</span>], mnist.data[<span class="dv">60000</span>:]</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>y_train, y_test <span class="op">=</span> mnist.target[:<span class="dv">60000</span>], mnist.target[<span class="dv">60000</span>:]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Next, as we only want a binary classifier, we select one number, in our case <code>5</code> and relabel our data. With the new labels we can train our classifier, compare <a href="#def-multiclass-ovr" class="quarto-xref">Definition&nbsp;<span>2.9</span></a>.</p>
<div id="0120ad32" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>y_train_5 <span class="op">=</span> (y_train <span class="op">==</span> <span class="st">"5"</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>y_test_5 <span class="op">=</span> (y_test <span class="op">==</span> <span class="st">"5"</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>SGD <span class="op">=</span> SGDClassifier(random_state<span class="op">=</span><span class="dv">6020</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>SGD.fit(X_train, y_train_5)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In order to get a score for our method, we use <span class="math inline">\(k\)</span>-folds cross-validation <a href="#def-crossvalidation" class="quarto-xref">Definition&nbsp;<span>2.1</span></a> and the corresponding <code>scikit-learn</code> function <a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html"><code>cross_val_score</code></a> to perform this task for our model.</p>
<div id="08020746" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> sklearn.model_selection.cross_val_score(</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    SGD, X_train, y_train_5, cv<span class="op">=</span><span class="dv">5</span>, scoring<span class="op">=</span><span class="st">"accuracy"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="298a88be" class="cell" data-execution_count="7">
<div class="cell-output cell-output-display" data-execution_count="7">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
<th data-quarto-table-cell-role="th">3</th>
<th data-quarto-table-cell-role="th">4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">accuracy [%]</td>
<td>97.07</td>
<td>96.23</td>
<td>95.46</td>
<td>96.62</td>
<td>96.37</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>With scores in the high <span class="math inline">\(90\%\)</span> range the results look promising, if not great, but are they really that good? In order to get a better idea just always guess that we do not see a <code>5</code> that should be the most common class in our case. To simulate this we use the <code>DummyClassifier</code> class.</p>
<div id="2fb79263" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>dummy <span class="op">=</span> sklearn.dummy.DummyClassifier()</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>dummy.fit(X_train, y_train_5)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>scores_dummy <span class="op">=</span> sklearn.model_selection.cross_val_score(</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    dummy, X_train, y_train_5, cv<span class="op">=</span><span class="dv">5</span>, scoring<span class="op">=</span><span class="st">"accuracy"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="f5e1adb3" class="cell" data-execution_count="9">
<div class="cell-output cell-output-display" data-execution_count="9">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
<th data-quarto-table-cell-role="th">3</th>
<th data-quarto-table-cell-role="th">4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">accuracy [%]</td>
<td>90.96</td>
<td>90.97</td>
<td>90.97</td>
<td>90.97</td>
<td>90.97</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>As this is pretty much <span class="math inline">\(91\%\)</span> (as expected there are only about <span class="math inline">\(10\%\)</span> of <code>5</code>s in the dataset). Just using accuracy is apparently not the gold standard to measure performance, what other possibilities are there?</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-confusionmatrix" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2.2 (Confusion Matrix)</strong></span> The confusion matrix, error matrix or for unsupervised learning sometimes called matching matrix allows an easy way of visualizing the performance of an algorithm.</p>
<p>The rows represent the true observations in each class, and the columns the predicted observations for each class.</p>
<p>In our <span class="math inline">\(2\times 2\)</span> case we get</p>
<div id="fig-clustering-sl-confusionmatrix" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-clustering-sl-confusionmatrix-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="../_assets/clustering/confusion_matrix.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-7" title="Figure&nbsp;2.6: Names and abbreviations for a 2\times 2 confusion matrix together with an example form our test case."><img src="../_assets/clustering/confusion_matrix.svg" class="img-fluid figure-img" style="width:2.88in"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-clustering-sl-confusionmatrix-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.6: Names and abbreviations for a <span class="math inline">\(2\times 2\)</span> confusion matrix together with an example form our test case.
</figcaption>
</figure>
</div>
<p>but it can be extended for multi-class segmentation.</p>
</div>
</div>
</div>
</div>
<p>To compute the confusion matrix we first need predictions. This can be achieved by <a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html"><code>cross_val_predict</code></a> instead of <code>cross_val_score</code> and than we use <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html"><code>confusion_matrix</code></a> from <code>sklearn.metrics</code>.</p>
<p>Combined, for our example, this reads as:</p>
<div id="270dcc51" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>y_train_pred <span class="op">=</span> sklearn.model_selection.cross_val_predict(</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>                    SGD, X_train, y_train_5, cv<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> sklearn.metrics.confusion_matrix(y_train_5, y_train_pred)                   </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="a04d20ee" class="cell" data-execution_count="11">
<div class="cell-output cell-output-display" data-execution_count="11">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">PP</th>
<th data-quarto-table-cell-role="th">PN</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">P</td>
<td>53617</td>
<td>962</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">N</td>
<td>1236</td>
<td>4185</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>From the values in the confusion matrix a lot of metrics can be computed<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>:</p>
<ol type="1">
<li><p><strong>Accuracy</strong>: <span class="math display">\[
ACC = \frac{TP + TN}{P + N}
\]</span></p></li>
<li><p><strong>True positive rate</strong> (TPR) or <strong>recall</strong>: <span class="math display">\[
TPR = \frac{TP}{P}
\]</span></p></li>
<li><p><strong>False negative rate</strong> (FNR): <span class="math display">\[
FNR = \frac{FN}{P}
\]</span></p></li>
<li><p><strong>False positive rate</strong> (FPR): <span class="math display">\[
FPR = \frac{FP}{N}
\]</span></p></li>
<li><p><strong>True negative rate</strong> (TNR): <span class="math display">\[
TNR = \frac{TN}{N}
\]</span></p></li>
<li><p><strong>Positive predictive value</strong> (PPV) or <strong>precission</strong>: <span class="math display">\[
PPV = \frac{TP}{TP + FP}
\]</span></p></li>
<li><p><strong>False discovery rate</strong> (FDR): <span class="math display">\[
FDR = \frac{FP}{TP + FP}
\]</span></p></li>
<li><p><strong>False omission rate</strong> (FOR): <span class="math display">\[
FOR = \frac{FN}{TN + FN}
\]</span></p></li>
<li><p><strong>Negative predictive value</strong> (NPV): <span class="math display">\[
NPV = \frac{TN}{TN + FN}
\]</span></p></li>
<li><p><strong><span class="math inline">\(F_1\)</span> score</strong>: <span class="math display">\[
F_1 = \frac{2 TP}{2 TP + FP + FN}
\]</span></p></li>
</ol>
<p>In the <a href="https://scikit-learn.org/stable/api/sklearn.metrics.html"><code>sklearn.metrics</code></a> most of these values have a corresponding function. If we look at <em>precission</em>, <em>recall</em>, and the <span class="math inline">\(F_1\)</span> score, for our example we see that our performance is viewed under a different light:</p>
<div id="15246795" class="cell styled-output" data-execution_count="12">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>precision <span class="op">=</span> sklearn.metrics.precision_score(y_train_5, y_train_pred)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>recall <span class="op">=</span> sklearn.metrics.recall_score(y_train_5, y_train_pred)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>f1_score <span class="op">=</span> sklearn.metrics.f1_score(y_train_5, y_train_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This tells us that our classifier correctly classifies a <code>5</code> 81.31% of the time. On the other hand it only <em>recalls</em> or detects 77.2% of our <code>5</code>s. The <span class="math inline">\(F_1\)</span>-score is a combination of the two (the harmonic mean) and in our case 79.2%.</p>
<p>Depending on the application we might want to have high precision (e.g.&nbsp;medical diagnosis to have no unnecessary treatment) or high recall (e.g.&nbsp;fraud detection where a missed fraudulent transaction can be costly). If we increase precision we reduce recall and the other way round so we can hardly have both. This dilemma is called <em>precision/recall trade-off</em>, see <a href="../appendices/explanations.html#sec-appendix-pvsr" class="quarto-xref"><span>Section A.2</span></a> for some more explanations.</p>
<p>An alternative way to look at accuracy for binary classifiers is to look at the <em>receiver operating characteristic</em> (ROC). It looks at recall (TPR) vs.&nbsp;the <em>false positive rate</em> (FPR). Other than that it works similar.</p>
</section>
<section id="sec-clustering-sv-svm" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="sec-clustering-sv-svm"><span class="header-section-number">2.3</span> Support Vector Machine (SVM)</h2>
<p>The basic idea of Support Vector Machines (SVMs) is to split observations into distinct clusters via hyperplanes. The have a long history in data science and come in different forms and fashions. Over the years they became more flexible and are still one of the most used tools in industry and science.</p>
<section id="linear-svm" class="level3" data-number="2.3.1">
<h3 data-number="2.3.1" class="anchored" data-anchor-id="linear-svm"><span class="header-section-number">2.3.1</span> Linear SVM</h3>
<p>We start of with the linear SVM where we construct a hyperplane <span class="math display">\[
\langle w, x\rangle + b = 0
\]</span> with a vector <span class="math inline">\(w\)</span> and a constant <span class="math inline">\(b\)</span>. There is a natural degree of freedom in this selection of the hyperplane, see <a href="#fig-clustering-sl-svm" class="quarto-xref">Figure&nbsp;<span>2.7</span></a> for two different choices.</p>
<div id="fig-clustering-sl-svm" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-clustering-sl-svm-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div id="fig-clustering-sl-svm-1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-clustering-sl-svm-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="../_assets/clustering/SVM_hyperplain1.svg" class="lightbox" data-gallery="fig-clustering-sl-svm" title="Figure&nbsp;2.7&nbsp;(a): Hyperplane with small margin."><img src="../_assets/clustering/SVM_hyperplain1.svg" class="img-fluid figure-img" style="width:4.7in" data-ref-parent="fig-clustering-sl-svm"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-clustering-sl-svm-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Hyperplane with small margin.
</figcaption>
</figure>
</div>
<div id="fig-clustering-sl-svm-2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-clustering-sl-svm-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="../_assets/clustering/SVM_hyperplain2.svg" class="lightbox" data-gallery="fig-clustering-sl-svm" title="Figure&nbsp;2.7&nbsp;(b): Hyperplane with large margin."><img src="../_assets/clustering/SVM_hyperplain2.svg" class="img-fluid figure-img" style="width:4.68in" data-ref-parent="fig-clustering-sl-svm"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-clustering-sl-svm-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Hyperplane with large margin.
</figcaption>
</figure>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-clustering-sl-svm-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.7: We see the hyperplane for the SVM classification scheme. The margin is much larger in the second choice.
</figcaption>
</figure>
</div>
<p>The optimization inside the SVM aims to find the line that separates the classes best (fewest wrong classifications) and also keeps the largest margin between the observations (the yellow region). The vectors touching the edge of the yellow regions are called <em>support vectors</em> giving the name to the algorithm.</p>
<p>With the hyperplane it is easy to classify an observation by simply computing the sign of the projection, i.e. <span class="math display">\[
y_j (\langle w, x_j \rangle + b) = \operatorname{sign}(\langle w, x_j \rangle + b) = \begin{cases} +1\\-1\end{cases},
\]</span> where <span class="math inline">\(1\)</span> corresponds to the versicolor (orange) and <span class="math inline">\(-1\)</span> setosa (blue) observations in <a href="#fig-clustering-sl-svm" class="quarto-xref">Figure&nbsp;<span>2.7</span></a>. Therefore, the classifier depends on the position of the observation and is not invariant under scaling.</p>
<div class="callout callout-style-simple callout-caution no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exr-linear-SVM" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 2.2 (Linear SVM)</strong></span> &nbsp;</p>
<ol type="1">
<li><p>Compute the vector <span class="math inline">\(w\)</span> in the two cases of <a href="#fig-clustering-sl-svm" class="quarto-xref">Figure&nbsp;<span>2.7</span></a>. The vector <span class="math inline">\(w\)</span> is normal to the line. For <a href="#fig-clustering-sl-svm-1" class="quarto-xref">Figure&nbsp;<span>2.7 (a)</span></a> two points on the line are <span class="math inline">\(v_1 = [1.25, 4.1]^\mathrm{T}\)</span>, <span class="math inline">\(v_2 = [5, 7.4]^\mathrm{T}\)</span>. For <a href="#fig-clustering-sl-svm-2" class="quarto-xref">Figure&nbsp;<span>2.7 (b)</span></a> two points on the line are <span class="math inline">\(z_1 = [2.6, 4.25]^\mathrm{T}\)</span>, <span class="math inline">\(z_2 = [2, 7]^\mathrm{T}\)</span>.</p></li>
<li><p>Classify the two points <span class="math display">\[
a = [1.4, 5.1]^\mathrm{T},
\]</span> <span class="math display">\[
b = [4.7, 7.0]^\mathrm{T}.
\]</span></p></li>
</ol>
</div>
</div>
</div>
</div>
<p>Stating the optimization function such that it is smooth for a linear SVM is a bit tricky. On the other hand, this is needed to allow for most optimization algorithm to work, as they require a gradient to some sort.</p>
<p>Therefore, the following formulation is quite common: <span class="math display">\[
\underset{w, b}{\operatorname{argmin}} \sum_j H(y_j, \overline{y}_j) + \frac12\|w\|^2 \quad \text{subject to}\quad \min_j|\langle x_j, w\rangle| = 1,
\]</span> with <span class="math inline">\(H(y_j, \overline{y}_j) = \max(0, 1 - \langle y_j, \overline{y}_j\rangle)\)</span>, the so called <em>Hinge loss</em> function for counting the number of errors. Furthermore, <span class="math inline">\(\overline{y}_j = \operatorname{sign}(\langle w, x_j\rangle + b)\)</span>.</p>
</section>
<section id="nonlinear-svm" class="level3" data-number="2.3.2">
<h3 data-number="2.3.2" class="anchored" data-anchor-id="nonlinear-svm"><span class="header-section-number">2.3.2</span> Nonlinear SVM</h3>
<p>In order to extend the SVM to more complex classification curves, the feature space can be extended. In order to do so, SVM introduces nonlinear features and computes the hyperplane on these features via a mapping <span class="math inline">\(x \to \Phi(x)\)</span> and the hyperplane function becomes <span class="math display">\[
f(x) = \langle w, \Phi(x)\rangle + b,
\]</span> and accordingly we classify along <span class="math display">\[
\operatorname{sign}(\langle w, \Phi(x_j)\rangle + b) = \operatorname{sign}(f(x_j)).
\]</span></p>
<p>Essentially, we change the feature space such that a separation is (hopefully) easier. To illustrate this we use a simple one dimensional example as shown in <a href="#fig-clustering-sl-svm-nl-1" class="quarto-xref">Figure&nbsp;<span>2.8 (a)</span></a>. Clearly there is no <em>linear</em> separation possible. On the other hand, if we use <span class="math display">\[
\Phi(x_j) = (x_j, x_j^2)
\]</span> as our transformation function we move to 2D space and the problem can easily be solved by a line at <span class="math inline">\(y=0.25\)</span>.</p>
<div class="cell" data-execution_count="13">
<details class="code-fold">
<summary>Show the code for the figure</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> LinearSVC</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>config InlineBackend.figure_formats <span class="op">=</span> [<span class="st">"svg"</span>]</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">6020</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">11</span>, endpoint<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>x2 <span class="op">=</span> np.zeros_like(x)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.zeros_like(x)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>y[np.<span class="bu">abs</span>(x) <span class="op">&lt;</span> <span class="fl">0.5</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>plt.figure()</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>plt.scatter(x[y<span class="op">==</span><span class="dv">0</span>], x2[y<span class="op">==</span><span class="dv">0</span>], label<span class="op">=</span><span class="st">"class 1"</span>)</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>plt.scatter(x[y<span class="op">==</span><span class="dv">1</span>], x2[y<span class="op">==</span><span class="dv">1</span>], label<span class="op">=</span><span class="st">"class 2"</span>)</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>plt.ylim([<span class="op">-</span><span class="fl">0.1</span>, <span class="dv">1</span>])</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>plt.xlim([<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>])</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>plt.gca().set_aspect(<span class="dv">2</span><span class="op">/</span><span class="fl">3.3</span>)</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>x2 <span class="op">=</span> np.power(x, <span class="dv">2</span>)</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>plt.figure()</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.stack([x.flatten(), x2.flatten()]).T</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>svm <span class="op">=</span> LinearSVC(random_state<span class="op">=</span><span class="dv">6020</span>).fit(data, y.flatten())</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>plt.scatter(x[y<span class="op">==</span><span class="dv">0</span>], x2[y<span class="op">==</span><span class="dv">0</span>], label<span class="op">=</span><span class="st">"class 1"</span>)</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>plt.scatter(x[y<span class="op">==</span><span class="dv">1</span>], x2[y<span class="op">==</span><span class="dv">1</span>], label<span class="op">=</span><span class="st">"class 2"</span>)</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>plt.ylim([<span class="op">-</span><span class="fl">0.1</span>, <span class="dv">1</span>])</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>plt.xlim([<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>])</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> svm.coef_[<span class="dv">0</span>]</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> svm.intercept_[<span class="dv">0</span>]</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>line <span class="op">=</span> <span class="kw">lambda</span> x: <span class="op">-</span>w[<span class="dv">0</span>] <span class="op">/</span> w[<span class="dv">1</span>] <span class="op">*</span> x <span class="op">-</span> d <span class="op">/</span> w[<span class="dv">1</span>]</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>], [line(<span class="op">-</span><span class="dv">1</span>), line(<span class="dv">1</span>)], <span class="st">"k"</span>, label<span class="op">=</span><span class="st">"classification line"</span>)</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>], [<span class="fl">0.25</span>, <span class="fl">0.25</span>], <span class="st">"k:"</span>, label<span class="op">=</span><span class="st">"actual boundary line"</span>)</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>plt.gca().set_aspect(<span class="dv">2</span><span class="op">/</span><span class="fl">3.3</span>)</span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="fig-clustering-sl-svm-nl" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="13">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-clustering-sl-svm-nl-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-display">
<div id="fig-clustering-sl-svm-nl-1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-clustering-sl-svm-nl-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="supervised_files/figure-html/fig-clustering-sl-svm-nl-output-1.svg" class="lightbox" data-gallery="fig-clustering-sl-svm-nl" title="Figure&nbsp;2.8&nbsp;(a): Observations that can not be separated linearly."><img src="supervised_files/figure-html/fig-clustering-sl-svm-nl-output-1.svg" class="img-fluid figure-img" data-ref-parent="fig-clustering-sl-svm-nl"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-clustering-sl-svm-nl-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Observations that can not be separated linearly.
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div id="fig-clustering-sl-svm-nl-2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-clustering-sl-svm-nl-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="supervised_files/figure-html/fig-clustering-sl-svm-nl-output-2.svg" class="lightbox" data-gallery="fig-clustering-sl-svm-nl" title="Figure&nbsp;2.8&nbsp;(b): Enriched feature set with Φ(x)=(x, x^2)."><img src="supervised_files/figure-html/fig-clustering-sl-svm-nl-output-2.svg" class="img-fluid figure-img" data-ref-parent="fig-clustering-sl-svm-nl"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-clustering-sl-svm-nl-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Enriched feature set with Φ(x)=(x, x^2).
</figcaption>
</figure>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-clustering-sl-svm-nl-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.8: Nonlinear classification with SVM.
</figcaption>
</figure>
</div>
</div>
<p>As can be seen in <a href="#fig-clustering-sl-svm-nl-2" class="quarto-xref">Figure&nbsp;<span>2.8 (b)</span></a> the SVM does a great job in finding a split for the two classes, even though not selecting the <em>optimal</em> line, which is not surprising for the given amount of observations.</p>
<p>As mentioned before, SVMs are sensitive to scaling. Let us use this example to illustrate the difference together with the concept of <em>pipelines</em> often used in data science context.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Pipeline
</div>
</div>
<div class="callout-body-container callout-body">
<p>The main idea of a pipeline is to create a composite as a ordered chain of transformations and estimators, see <a href="https://scikit-learn.org/stable/modules/compose.html">docs</a> for some more insights.</p>
</div>
</div>
<p>We can use the pipeline to</p>
<ul>
<li>create the polynomial observations</li>
<li>apply a scaler to our observations</li>
<li>apply the Linear SVM</li>
</ul>
<div id="b9f12fdb" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>composit_svm <span class="op">=</span> sklearn.pipeline.make_pipeline(</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    sklearn.preprocessing.PolynomialFeatures(<span class="dv">2</span>),</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    sklearn.preprocessing.StandardScaler(),</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    LinearSVC(random_state<span class="op">=</span><span class="dv">6020</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="15">
<details class="code-fold">
<summary>Show the code for the figure</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> LinearSVC</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>config InlineBackend.figure_formats <span class="op">=</span> [<span class="st">"svg"</span>]</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">6020</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">11</span>, endpoint<span class="op">=</span><span class="va">True</span>).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.zeros_like(x).flatten()</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>y[np.<span class="bu">abs</span>(x.flatten()) <span class="op">&lt;</span> <span class="fl">0.5</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>composit_svm.fit(x, y)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>xx <span class="op">=</span> composit_svm[:<span class="dv">2</span>].fit_transform(x)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>plt.figure()</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>plt.scatter(xx[y<span class="op">==</span><span class="dv">0</span>, <span class="dv">1</span>], xx[y<span class="op">==</span><span class="dv">0</span>, <span class="dv">2</span>], label<span class="op">=</span><span class="st">"class 1"</span>)</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>plt.scatter(xx[y<span class="op">==</span><span class="dv">1</span>, <span class="dv">1</span>], xx[y<span class="op">==</span><span class="dv">1</span>, <span class="dv">2</span>], label<span class="op">=</span><span class="st">"class 2"</span>)</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> composit_svm[<span class="st">'linearsvc'</span>].coef_[<span class="dv">0</span>][<span class="dv">1</span>:]</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> composit_svm[<span class="st">'linearsvc'</span>].intercept_[<span class="dv">0</span>]</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="op">-</span><span class="fl">1.6</span>, <span class="fl">1.6</span>], [line(<span class="op">-</span><span class="fl">1.5</span>), line(<span class="fl">1.5</span>)],</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>         <span class="st">"k"</span>, label<span class="op">=</span><span class="st">"scaled classification line"</span>)</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>plt.ylim([<span class="op">-</span><span class="fl">1.25</span>, <span class="fl">1.75</span>])</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>plt.xlim([<span class="op">-</span><span class="fl">1.6</span>, <span class="fl">1.6</span>])</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>plt.gca().set_aspect(<span class="dv">3</span><span class="op">/</span><span class="dv">9</span>)</span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>xx <span class="op">=</span> composit_svm[:<span class="dv">1</span>].fit_transform(x)</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>plt.figure()</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>plt.scatter(xx[y<span class="op">==</span><span class="dv">0</span>, <span class="dv">1</span>], xx[y<span class="op">==</span><span class="dv">0</span>, <span class="dv">2</span>], label<span class="op">=</span><span class="st">"class 1"</span>)</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>plt.scatter(xx[y<span class="op">==</span><span class="dv">1</span>, <span class="dv">1</span>], xx[y<span class="op">==</span><span class="dv">1</span>, <span class="dv">2</span>], label<span class="op">=</span><span class="st">"class 2"</span>)</span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> composit_svm[<span class="st">'linearsvc'</span>].coef_[<span class="dv">0</span>][<span class="dv">1</span>:]</span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> composit_svm[<span class="st">'linearsvc'</span>].intercept_[<span class="dv">0</span>]</span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> composit_svm[<span class="st">"standardscaler"</span>].inverse_transform(</span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a>    [np.array([<span class="dv">0</span>, <span class="op">-</span><span class="fl">1.6</span>, line(<span class="op">-</span><span class="fl">1.6</span>)])])[<span class="dv">0</span>]</span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> composit_svm[<span class="st">"standardscaler"</span>].inverse_transform(</span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>    [np.array([<span class="dv">0</span>, <span class="fl">1.6</span>, line(<span class="fl">1.6</span>)])])[<span class="dv">0</span>]</span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a>plt.plot([a[<span class="dv">1</span>], b[<span class="dv">1</span>]], [a[<span class="dv">2</span>], b[<span class="dv">2</span>]], </span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a>         <span class="st">"k"</span>, label<span class="op">=</span><span class="st">"scaled classification line"</span>)</span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> svm.coef_[<span class="dv">0</span>]</span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> svm.intercept_[<span class="dv">0</span>]</span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>], [line(<span class="op">-</span><span class="dv">1</span>), line(<span class="dv">1</span>)], </span>
<span id="cb12-46"><a href="#cb12-46" aria-hidden="true" tabindex="-1"></a>            <span class="st">"k:"</span>, label<span class="op">=</span><span class="st">"unscaled classification line"</span>)</span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-48"><a href="#cb12-48" aria-hidden="true" tabindex="-1"></a>plt.ylim([<span class="op">-</span><span class="fl">0.1</span>, <span class="dv">1</span>])</span>
<span id="cb12-49"><a href="#cb12-49" aria-hidden="true" tabindex="-1"></a>plt.xlim([<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>])</span>
<span id="cb12-50"><a href="#cb12-50" aria-hidden="true" tabindex="-1"></a>plt.gca().set_aspect(<span class="dv">2</span><span class="op">/</span><span class="fl">3.3</span>)</span>
<span id="cb12-51"><a href="#cb12-51" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb12-52"><a href="#cb12-52" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="fig-clustering-sl-svm-nl-3" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="15">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-clustering-sl-svm-nl-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-display">
<div id="fig-clustering-sl-svm-nl-3-1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-clustering-sl-svm-nl-3-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="supervised_files/figure-html/fig-clustering-sl-svm-nl-3-output-1.svg" class="lightbox" data-gallery="fig-clustering-sl-svm-nl-3" title="Figure&nbsp;2.9&nbsp;(a): Classification in the enriched Φ(x)=(x^0, x^1, x^2) and scaled space. Note the first dimension is ignored."><img src="supervised_files/figure-html/fig-clustering-sl-svm-nl-3-output-1.svg" class="img-fluid figure-img" data-ref-parent="fig-clustering-sl-svm-nl-3"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-clustering-sl-svm-nl-3-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Classification in the enriched Φ(x)=(x^0, x^1, x^2) and scaled space. Note the first dimension is ignored.
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div id="fig-clustering-sl-svm-nl-3-2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-clustering-sl-svm-nl-3-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="supervised_files/figure-html/fig-clustering-sl-svm-nl-3-output-2.svg" class="lightbox" data-gallery="fig-clustering-sl-svm-nl-3" title="Figure&nbsp;2.9&nbsp;(b): Difference between the classification lines when transformed back into the original space."><img src="supervised_files/figure-html/fig-clustering-sl-svm-nl-3-output-2.svg" class="img-fluid figure-img" data-ref-parent="fig-clustering-sl-svm-nl-3"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-clustering-sl-svm-nl-3-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Difference between the classification lines when transformed back into the original space.
</figcaption>
</figure>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-clustering-sl-svm-nl-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.9: Classification with autoscaler vs.&nbsp;no scaler.
</figcaption>
</figure>
</div>
</div>
<div class="callout callout-style-simple callout-caution no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exr-nonlinear-SVM" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 2.3 (Nonlinear SVM)</strong></span> &nbsp;</p>
<ol type="1">
<li>Extend the above findings to an example in 2D with a circular classification line. Create tests data of your classification by changing to <code>np.linspace(-1, 1, 12)</code>.</li>
</ol>
<div id="cell-fig-clustering-sl-svm-nl-exr" class="cell" data-execution_count="16">
<details class="code-fold">
<summary>Show the code for the figure</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> LinearSVC</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>config InlineBackend.figure_formats <span class="op">=</span> [<span class="st">"svg"</span>]</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">6020</span>)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">11</span>, endpoint<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>x2 <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">11</span>, endpoint<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>XX, XX2 <span class="op">=</span> np.meshgrid(x, x2)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>ZZ <span class="op">=</span> np.<span class="bu">pow</span>(XX, <span class="dv">2</span>) <span class="op">+</span> np.<span class="bu">pow</span>(XX2, <span class="dv">2</span>)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.zeros_like(XX)</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>i <span class="op">=</span> np.sqrt(ZZ) <span class="op">&lt;</span> <span class="fl">0.5</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>y[i] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>plt.scatter(XX[y <span class="op">==</span> <span class="dv">0</span>], XX2[y <span class="op">==</span> <span class="dv">0</span>], label<span class="op">=</span><span class="st">"class 1"</span>)</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>plt.scatter(XX[y <span class="op">==</span> <span class="dv">1</span>], XX2[y <span class="op">==</span> <span class="dv">1</span>], label<span class="op">=</span><span class="st">"class 2"</span>)</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.stack([XX.flatten(), XX2.flatten(), ZZ.flatten()]).T</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>label <span class="op">=</span> y.flatten()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-clustering-sl-svm-nl-exr" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-clustering-sl-svm-nl-exr-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="supervised_files/figure-html/fig-clustering-sl-svm-nl-exr-output-1.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-14" title="Figure&nbsp;2.10: Dataset in 2D"><img src="supervised_files/figure-html/fig-clustering-sl-svm-nl-exr-output-1.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-clustering-sl-svm-nl-exr-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.10: Dataset in 2D
</figcaption>
</figure>
</div>
</div>
</div>
<ol start="2" type="1">
<li>Recall the moons example from <a href="unsupervised.html#sec-clustering-ul-dbscan" class="quarto-xref"><span>Section 1.3</span></a> and use a degree <span class="math inline">\(3\)</span> <code>PolynomialFeatures</code> for classification.</li>
</ol>
<p>In both cases, plot the classification line in a projection onto the original 2D space.</p>
</div>
</div>
</div>
</div>
</section>
<section id="kernel-methods-for-svm" class="level3" data-number="2.3.3">
<h3 data-number="2.3.3" class="anchored" data-anchor-id="kernel-methods-for-svm"><span class="header-section-number">2.3.3</span> Kernel Methods for SVM</h3>
<p>While enriching the feature space is, without doubt, extremal helpful the curse of dimensionality is quickly starting to influence the performance. The computation of <span class="math inline">\(w\)</span> is getting harder. The so called <em>kernel trick</em> is solving this problem. We express <span class="math inline">\(w\)</span> in a different basis and solve for the parameters of the basis, i.e. <span class="math display">\[
w = \sum_{j=1}^m \alpha_j \Phi(x_j)
\]</span> where <span class="math inline">\(\alpha_j\)</span> are called the weights of the different nonlinear observable functions <span class="math inline">\(\Phi(x_j)\)</span>. Our <span class="math inline">\(f\)</span> becomes <span class="math display">\[
f(x) = \sum_{j=1}^m \alpha_j \langle \Phi(x_j), \Phi(x) \rangle + b.
\]</span> The so called <em>kernel function</em> is defined as the inner product involved, i.e. <span class="math display">\[
K(x_j, x) = \langle \Phi(x_j), \Phi(x) \rangle.
\]</span> The optimization problem for <span class="math inline">\(w\)</span> now reads <span class="math display">\[
\underset{\alpha, b}{\operatorname{argmin}} \sum_j H(y_j, \overline{y}_j) + \frac12\left\|\sum_{j=1} \alpha_j \Phi(x_j)\right\|^2 \quad \text{subject to}\quad \min_j|\langle x_j, w\rangle| = 1,
\]</span> with <span class="math inline">\(\alpha\)</span> representing the vector of all the <span class="math inline">\(\alpha_j\)</span>. The important part here is that we now minimize of <span class="math inline">\(\alpha\)</span>, which is easier.</p>
<p>The kernel function allow almost arbitrary number of observables as it, for example, can represent a Taylor series expansion. Furthermore, it allows an implicit computation in higher dimensions by simply computing the inner product of differences between observations.</p>
<p>One of these functions are so called <em>radial basis functions</em> (RBF) with the simplest being a Gaussian kernel <span class="math display">\[
K(x_j, x) = \exp\left(-\gamma\|x_j - x\|^2\right).
\]</span></p>
<p>In <code>scikit-learn</code> this is supported via the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC"><code>SVC</code></a> class.</p>
<p>Let us test this implementation with the help of our dogs and cats example.</p>
<div id="cell-fig-clustering-sl-svm-rbf" class="cell" data-execution_count="17">
<details class="code-fold">
<summary>Show the code for the figure</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> io</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> svm</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>config InlineBackend.figure_formats <span class="op">=</span> [<span class="st">"svg"</span>]</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> requests.get(</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">"https://github.com/dynamicslab/databook_python/"</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">"raw/refs/heads/master/DATA/catData_w.mat"</span>)</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>cats_w <span class="op">=</span> scipy.io.loadmat(io.BytesIO(response.content))[<span class="st">"cat_wave"</span>]</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> requests.get(</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">"https://github.com/dynamicslab/databook_python/"</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">"raw/refs/heads/master/DATA/dogData_w.mat"</span>)</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>dogs_w <span class="op">=</span> scipy.io.loadmat(io.BytesIO(response.content))[<span class="st">"dog_wave"</span>]</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>CD <span class="op">=</span> np.concatenate((dogs_w, cats_w), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>U, S, VT <span class="op">=</span> np.linalg.svd(CD <span class="op">-</span> np.mean(CD), full_matrices<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>v <span class="op">=</span> VT.T</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> np.arange(<span class="dv">1</span>, <span class="dv">21</span>)</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>xtrain <span class="op">=</span> np.concatenate((v[:<span class="dv">60</span>, features], v[<span class="dv">80</span>:<span class="dv">140</span>, features]))</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>label <span class="op">=</span> np.repeat(np.array([<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>]), <span class="dv">60</span>)</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>xtest <span class="op">=</span> np.concatenate((v[<span class="dv">60</span>:<span class="dv">80</span>, features], v[<span class="dv">140</span>:<span class="dv">160</span>, features]))</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>truth <span class="op">=</span> np.repeat(np.array([<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>]), <span class="dv">20</span>)</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>svc <span class="op">=</span> svm.SVC(kernel<span class="op">=</span><span class="st">"rbf"</span>, gamma<span class="op">=</span><span class="st">"auto"</span>).fit(xtrain, label)</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>test_label <span class="op">=</span> svc.predict(xtest)</span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>train_label <span class="op">=</span> svc.predict(xtrain)</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> sklearn.metrics.confusion_matrix(test_label, truth)</span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>plt.figure()</span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>plt.scatter(xtrain[train_label <span class="op">==</span> <span class="dv">1</span>, <span class="dv">1</span>], xtrain[train_label <span class="op">==</span> <span class="dv">1</span>, <span class="dv">3</span>],</span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>            alpha<span class="op">=</span><span class="fl">0.5</span>, color<span class="op">=</span><span class="st">"C0"</span>, label<span class="op">=</span><span class="st">"train_dogs"</span>)</span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a>plt.scatter(xtrain[train_label <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>], xtrain[train_label <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>, <span class="dv">3</span>],</span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a>            alpha<span class="op">=</span><span class="fl">0.5</span>, color<span class="op">=</span><span class="st">"C1"</span>, label<span class="op">=</span><span class="st">"train_cats"</span>)</span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a>plt.scatter(xtest[test_label <span class="op">==</span> <span class="dv">1</span>, <span class="dv">1</span>], xtest[test_label <span class="op">==</span> <span class="dv">1</span>, <span class="dv">3</span>],</span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a>            color<span class="op">=</span><span class="st">"C0"</span>, label<span class="op">=</span><span class="st">"test_dogs"</span>)</span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a>plt.scatter(xtest[test_label <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>], xtest[test_label <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>, <span class="dv">3</span>],</span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a>            color<span class="op">=</span><span class="st">"C1"</span>, label<span class="op">=</span><span class="st">"test_cats"</span>)</span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a>error <span class="op">=</span> np.vstack((xtrain[label <span class="op">!=</span> train_label, :][:, [<span class="dv">1</span>,<span class="dv">3</span>]],</span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a>                   xtest[truth <span class="op">!=</span> test_label, :][:, [<span class="dv">1</span>, <span class="dv">3</span>]]))</span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a>plt.scatter(error[:, <span class="dv">0</span>], error[:, <span class="dv">1</span>],</span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a>            color<span class="op">=</span><span class="st">"k"</span>, marker<span class="op">=</span><span class="st">"x"</span>, label<span class="op">=</span><span class="st">"wrong classification"</span>)</span>
<span id="cb14-46"><a href="#cb14-46" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb14-47"><a href="#cb14-47" aria-hidden="true" tabindex="-1"></a>plt.ylim([<span class="op">-</span><span class="fl">0.25</span>, <span class="fl">0.2</span>])</span>
<span id="cb14-48"><a href="#cb14-48" aria-hidden="true" tabindex="-1"></a>plt.xlim([<span class="op">-</span><span class="fl">0.15</span>, <span class="fl">0.25</span>])</span>
<span id="cb14-49"><a href="#cb14-49" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="vs">r"</span><span class="dv">$</span><span class="vs">PC_2</span><span class="dv">$</span><span class="vs">"</span>)</span>
<span id="cb14-50"><a href="#cb14-50" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="vs">r"</span><span class="dv">$</span><span class="vs">PC_4</span><span class="dv">$</span><span class="vs">"</span>)</span>
<span id="cb14-51"><a href="#cb14-51" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-clustering-sl-svm-rbf" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-clustering-sl-svm-rbf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="supervised_files/figure-html/fig-clustering-sl-svm-rbf-output-1.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-15" title="Figure&nbsp;2.11: Training a SVM with an RBF kernel for the singular vectors 2 to 22. The picture shows the classification results projected for the principal components 2 and 4."><img src="supervised_files/figure-html/fig-clustering-sl-svm-rbf-output-1.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-clustering-sl-svm-rbf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.11: Training a SVM with an RBF kernel for the singular vectors 2 to 22. The picture shows the classification results projected for the principal components 2 and 4.
</figcaption>
</figure>
</div>
</div>
</div>
<p>We get a confusion matrix for our test set as</p>
<div id="8864d8ff" class="cell" data-execution_count="18">
<div class="cell-output cell-output-display" data-execution_count="18">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">PP</th>
<th data-quarto-table-cell-role="th">PN</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">P</td>
<td>18</td>
<td>3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">N</td>
<td>2</td>
<td>17</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>In <a href="#fig-clustering-sl-svm-rbf" class="quarto-xref">Figure&nbsp;<span>2.11</span></a> we can see the results of the classification for the entire set of observations, shaded for the training set, and crosses marking the wrongly classified data. With 8 wrongly classified images we have quite a good result, compared to LDA or QDA <a href="#fig-clustering-sl-lda3" class="quarto-xref">Figure&nbsp;<span>2.5</span></a>. Note, the classification is hard to recognise for the two classes in the simple projection. With the parameters <code>C</code> and <code>gamma</code> we can influence the classification.</p>
<div class="callout callout-style-simple callout-caution no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exr-nonlinear-SVM-rbf" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 2.4 (Nonlinear SVM with RBF)</strong></span> Recall the moons example from <a href="unsupervised.html#sec-clustering-ul-dbscan" class="quarto-xref"><span>Section 1.3</span></a> and use a <code>SVC</code> classification to distinguish the clusters. Look at four different results for <span class="math inline">\(\gamma \in \{0.1, 5\}\)</span> and <span class="math inline">\(C \in \{0.001, 1000\}\)</span>, compare <span class="citation" data-cites="Geron2022-xh">Geron (<a href="../references.html#ref-Geron2022-xh" role="doc-biblioref">2022</a>)</span>.</p>
<p>In all of the four images plot the classification line in a projection onto the original 2D space.</p>
</div>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-caution no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exr-nonlinear-SVM-regression" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 2.5 (Nonlinear SVM for regression)</strong></span> We can use SVM for regression. Have a look at <a href="https://scikit-learn.org/stable/auto_examples/svm/plot_svm_regression.html#sphx-glr-auto-examples-svm-plot-svm-regression-py">docs</a> and use the findings to fit the following observations with various degrees and kernel functions.</p>
<div id="f81c8284" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>config InlineBackend.figure_formats <span class="op">=</span> [<span class="st">"svg"</span>]</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">6020</span>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> <span class="dv">6</span> <span class="op">*</span> np.random.rand(m) <span class="op">-</span> <span class="dv">3</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span> <span class="op">*</span> x <span class="op">**</span> <span class="dv">2</span> <span class="op">+</span> x <span class="op">+</span> <span class="dv">2</span> <span class="op">+</span> np.random.randn(m)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure()</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>plt.scatter(x, y, label<span class="op">=</span><span class="st">"observations"</span>)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="supervised_files/figure-html/cell-20-output-1.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-16"><img src="supervised_files/figure-html/cell-20-output-1.svg" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>Compare <span class="citation" data-cites="Kandolf_GDM">(<a href="../references.html#ref-Kandolf_GDM" role="doc-biblioref">Kandolf 2025</a>, Example 5.2)</span> <a href="https://kandolfp.github.io/MECH-M-DUAL-1-DBM/regression/linear.html#exm-regression-linear-poly">Link</a>.</p>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="decision-trees" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="decision-trees"><span class="header-section-number">2.4</span> Decision trees</h2>
<p>Decision trees are a common tool in data science, for classification and regression. They are a powerful class of algorithms, that can fit not only numerical data. Furthermore, they form the basis of <em>random forests</em>, one of the most powerful machine learning algorithms available to date.</p>
<p>They where not invented for machine learning but have been a staple in business for centuries. Their basic idea is to establish an algorithmic flow chart for making decisions. The criteria that creates the splits in each branch is related to a desired outcome and are therefore <em>important</em>. Often experts are called upon creating such a decision tree.</p>
<p>The decision tree learning follows the same principals to create a predictive classification model based on the provided observations and labels. Similar to DBSCAN, they form a hierarchical structure that tries to split <em>in an optimal way</em>. In this regard, they are the counterpart to DBSCAN, as they move from top to bottom and of course use the labels to guide the process.</p>
<p>The following key feature make them wildly use:</p>
<ol type="1">
<li>The usually produce interpretable results (we can draw the graph).</li>
<li>The algorithm mimics human decision making, which helps for the interpretation.</li>
<li>The can handle numerical and categorical data.</li>
<li>They perform well with large sets of data.</li>
<li>The reliability of the classification can be assessed with statistical validation.</li>
</ol>
<p>While there are a lot of different optimizations the base algorithm follows these steps:</p>
<ol type="1">
<li>Look through all components (features) of an observation <span class="math inline">\(x_j\)</span> that gives the best labeling prediction <span class="math inline">\(y_j\)</span>.</li>
<li>Compare the prediction accuracy over all observations, the best result is used.</li>
<li>Proceed with the two new branches in the same fashion.</li>
</ol>
<p>Let us apply it to the Fischer Iris dataset to better understand what is happening.</p>
<div id="be75872d" class="cell" data-execution_count="20">
<details class="code-fold">
<summary>Show the code for the figure</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_iris</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> six <span class="im">import</span> StringIO</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>config InlineBackend.figure_formats <span class="op">=</span> [<span class="st">"svg"</span>]</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>iris <span class="op">=</span> load_iris(as_frame<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>X_iris <span class="op">=</span> iris.data.values</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>y_iris <span class="op">=</span> iris.target</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>decision_tree <span class="op">=</span> DecisionTreeClassifier(max_depth<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">6020</span>)</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>decision_tree.fit(X_iris, y_iris)</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>dot_data <span class="op">=</span> <span class="st">"fischer_tree.dot"</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>sklearn.tree.export_graphviz(decision_tree, out_file<span class="op">=</span>dot_data,  </span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>                filled<span class="op">=</span><span class="va">True</span>, rounded<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>                feature_names<span class="op">=</span>iris.feature_names,</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>                class_names<span class="op">=</span>iris.target_names,</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>                special_characters<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-file="fischer_tree.dot" data-layout-align="default">
<div class="cell-output-display">
<div id="fig-clustering-sl-tree-iris" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-clustering-sl-tree-iris-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div>
<svg width="672" height="480" viewbox="0.00 0.00 356.91 339.20" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 335.2)">
<title>Tree</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-335.2 352.91,-335.2 352.91,4 -4,4"></polygon>
<!-- 0 -->
<g id="node1" class="node">
<title>0</title>
<path fill="#ffffff" stroke="black" d="M210.42,-331.2C210.42,-331.2 67.49,-331.2 67.49,-331.2 61.49,-331.2 55.49,-325.2 55.49,-319.2 55.49,-319.2 55.49,-251.2 55.49,-251.2 55.49,-245.2 61.49,-239.2 67.49,-239.2 67.49,-239.2 210.42,-239.2 210.42,-239.2 216.42,-239.2 222.42,-245.2 222.42,-251.2 222.42,-251.2 222.42,-319.2 222.42,-319.2 222.42,-325.2 216.42,-331.2 210.42,-331.2"></path>
<text text-anchor="start" x="63.47" y="-314.6" font-family="Helvetica,sans-Serif" font-size="14.00">petal length (cm) ≤ 2.45</text>
<text text-anchor="start" x="102.56" y="-297.8" font-family="Helvetica,sans-Serif" font-size="14.00">gini = 0.667</text>
<text text-anchor="start" x="93.23" y="-281" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 150</text>
<text text-anchor="start" x="79.21" y="-264.2" font-family="Helvetica,sans-Serif" font-size="14.00">value = [50, 50, 50]</text>
<text text-anchor="start" x="94.4" y="-247.4" font-family="Helvetica,sans-Serif" font-size="14.00">class = setosa</text>
</g>
<!-- 1 -->
<g id="node2" class="node">
<title>1</title>
<path fill="#e58139" stroke="black" d="M107.86,-194.9C107.86,-194.9 12.05,-194.9 12.05,-194.9 6.05,-194.9 0.05,-188.9 0.05,-182.9 0.05,-182.9 0.05,-131.5 0.05,-131.5 0.05,-125.5 6.05,-119.5 12.05,-119.5 12.05,-119.5 107.86,-119.5 107.86,-119.5 113.86,-119.5 119.86,-125.5 119.86,-131.5 119.86,-131.5 119.86,-182.9 119.86,-182.9 119.86,-188.9 113.86,-194.9 107.86,-194.9"></path>
<text text-anchor="start" x="31.35" y="-178.2" font-family="Helvetica,sans-Serif" font-size="14.00">gini = 0.0</text>
<text text-anchor="start" x="18.12" y="-161.4" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 50</text>
<text text-anchor="start" x="8" y="-144.6" font-family="Helvetica,sans-Serif" font-size="14.00">value = [50, 0, 0]</text>
<text text-anchor="start" x="15.4" y="-127.8" font-family="Helvetica,sans-Serif" font-size="14.00">class = setosa</text>
</g>
<!-- 0&#45;&gt;1 -->
<g id="edge1" class="edge">
<title>0-&gt;1</title>
<path fill="none" stroke="black" d="M110.66,-239.07C103.46,-227.59 95.72,-215.25 88.51,-203.75"></path>
<polygon fill="black" stroke="black" points="91.39,-201.76 83.12,-195.14 85.46,-205.48 91.39,-201.76"></polygon>
<text text-anchor="middle" x="77.53" y="-215.31" font-family="Helvetica,sans-Serif" font-size="14.00">True</text>
</g>
<!-- 2 -->
<g id="node3" class="node">
<title>2</title>
<path fill="#ffffff" stroke="black" d="M287.46,-203.2C287.46,-203.2 150.45,-203.2 150.45,-203.2 144.45,-203.2 138.45,-197.2 138.45,-191.2 138.45,-191.2 138.45,-123.2 138.45,-123.2 138.45,-117.2 144.45,-111.2 150.45,-111.2 150.45,-111.2 287.46,-111.2 287.46,-111.2 293.46,-111.2 299.46,-117.2 299.46,-123.2 299.46,-123.2 299.46,-191.2 299.46,-191.2 299.46,-197.2 293.46,-203.2 287.46,-203.2"></path>
<text text-anchor="start" x="146.2" y="-186.6" font-family="Helvetica,sans-Serif" font-size="14.00">petal width (cm) ≤ 1.75</text>
<text text-anchor="start" x="190.35" y="-169.8" font-family="Helvetica,sans-Serif" font-size="14.00">gini = 0.5</text>
<text text-anchor="start" x="173.23" y="-153" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 100</text>
<text text-anchor="start" x="163.11" y="-136.2" font-family="Helvetica,sans-Serif" font-size="14.00">value = [0, 50, 50]</text>
<text text-anchor="start" x="165.08" y="-119.4" font-family="Helvetica,sans-Serif" font-size="14.00">class = versicolor</text>
</g>
<!-- 0&#45;&gt;2 -->
<g id="edge2" class="edge">
<title>0-&gt;2</title>
<path fill="none" stroke="black" d="M167.61,-239.07C173.18,-230.29 179.07,-221.01 184.8,-211.99"></path>
<polygon fill="black" stroke="black" points="187.82,-213.76 190.23,-203.44 181.91,-210.01 187.82,-213.76"></polygon>
<text text-anchor="middle" x="195.68" y="-223.64" font-family="Helvetica,sans-Serif" font-size="14.00">False</text>
</g>
<!-- 3 -->
<g id="node4" class="node">
<title>3</title>
<path fill="#4de88e" stroke="black" d="M198.71,-75.3C198.71,-75.3 99.2,-75.3 99.2,-75.3 93.2,-75.3 87.2,-69.3 87.2,-63.3 87.2,-63.3 87.2,-11.9 87.2,-11.9 87.2,-5.9 93.2,0.1 99.2,0.1 99.2,0.1 198.71,0.1 198.71,0.1 204.71,0.1 210.71,-5.9 210.71,-11.9 210.71,-11.9 210.71,-63.3 210.71,-63.3 210.71,-69.3 204.71,-75.3 198.71,-75.3"></path>
<text text-anchor="start" x="112.56" y="-58.6" font-family="Helvetica,sans-Serif" font-size="14.00">gini = 0.168</text>
<text text-anchor="start" x="107.12" y="-41.8" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 54</text>
<text text-anchor="start" x="97" y="-25" font-family="Helvetica,sans-Serif" font-size="14.00">value = [0, 49, 5]</text>
<text text-anchor="start" x="95.08" y="-8.2" font-family="Helvetica,sans-Serif" font-size="14.00">class = versicolor</text>
</g>
<!-- 2&#45;&gt;3 -->
<g id="edge3" class="edge">
<title>2-&gt;3</title>
<path fill="none" stroke="black" d="M192.09,-111.07C186.83,-102.23 181.3,-92.95 176.03,-84.1"></path>
<polygon fill="black" stroke="black" points="178.99,-82.22 170.87,-75.42 172.97,-85.8 178.99,-82.22"></polygon>
</g>
<!-- 4 -->
<g id="node5" class="node">
<title>4</title>
<path fill="#843de6" stroke="black" d="M336.86,-75.3C336.86,-75.3 241.05,-75.3 241.05,-75.3 235.05,-75.3 229.05,-69.3 229.05,-63.3 229.05,-63.3 229.05,-11.9 229.05,-11.9 229.05,-5.9 235.05,0.1 241.05,0.1 241.05,0.1 336.86,0.1 336.86,0.1 342.86,0.1 348.86,-5.9 348.86,-11.9 348.86,-11.9 348.86,-63.3 348.86,-63.3 348.86,-69.3 342.86,-75.3 336.86,-75.3"></path>
<text text-anchor="start" x="252.56" y="-58.6" font-family="Helvetica,sans-Serif" font-size="14.00">gini = 0.043</text>
<text text-anchor="start" x="247.12" y="-41.8" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 46</text>
<text text-anchor="start" x="237" y="-25" font-family="Helvetica,sans-Serif" font-size="14.00">value = [0, 1, 45]</text>
<text text-anchor="start" x="239.35" y="-8.2" font-family="Helvetica,sans-Serif" font-size="14.00">class = virginica</text>
</g>
<!-- 2&#45;&gt;4 -->
<g id="edge4" class="edge">
<title>2-&gt;4</title>
<path fill="none" stroke="black" d="M245.82,-111.07C251.08,-102.23 256.6,-92.95 261.87,-84.1"></path>
<polygon fill="black" stroke="black" points="264.93,-85.8 267.04,-75.42 258.92,-82.22 264.93,-85.8"></polygon>
</g>
</g>
</svg>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-clustering-sl-tree-iris-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.12: Decision tree for the Fischer iris dataset and depth 2.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Displaying <code>dot</code> files
</div>
</div>
<div class="callout-body-container callout-body">
<p>In the code for <a href="#fig-clustering-sl-tree-iris" class="quarto-xref">Figure&nbsp;<span>2.12</span></a> we generate a <code>dot</code> file, that is interpreted with quarto. This allows a better visual integration. In order to do the same offline you need to install <a href="https://www.graphviz.org/download/"><code>graphviz</code></a> for the installation of <code>dot</code> and also install the python package <code>pydotplus</code>.</p>
<p>Than you should be able to use:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pydotplus</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> six <span class="im">import</span> StringIO</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>dot_data <span class="op">=</span> StringIO()</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>graph <span class="op">=</span> pydotplus.graph_from_dot_data(dot_data.getvalue())  </span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>graph.create_png()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<p>As we can see, for our tree with depth <span class="math inline">\(2\)</span>, we only need to split along <code>petal length (cm)</code> and <code>petal width (cm)</code>, leaving the two other features untouched, compare <a href="index.html#fig-clustering-iris" class="quarto-xref">Figure&nbsp;<span>2</span></a>.</p>
<p>As we only have the splits happening in these two variables we can also visualize them easily.</p>
<div id="cell-fig-clustering-sl-tree-iris-split" class="cell" data-execution_count="21">
<details class="code-fold">
<summary>Show the code for the figure</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>config InlineBackend.figure_formats <span class="op">=</span> [<span class="st">"svg"</span>]</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>iris.frame[<span class="st">"target"</span>] <span class="op">=</span> iris.target_names[iris.target]</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> iris.frame</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>plt.figure()</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name <span class="kw">in</span> iris.target_names:</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    index <span class="op">=</span> df[<span class="st">"target"</span>] <span class="op">==</span> name</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>    plt.scatter(df.iloc[:, <span class="dv">2</span>][index], df.iloc[:, <span class="dv">3</span>][index], label<span class="op">=</span>name)</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>plt.xlim([<span class="fl">0.5</span>, <span class="fl">7.5</span>])</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>plt.ylim([<span class="dv">0</span>, <span class="fl">2.6</span>])</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>th <span class="op">=</span> decision_tree.tree_.threshold[[<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>]]</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>plt.plot([th[<span class="dv">0</span>], th[<span class="dv">0</span>]], plt.gca().get_ylim(), <span class="st">'C1-.'</span>,</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>          linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">"split 1"</span>)</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>plt.plot([th[<span class="dv">0</span>], plt.gca().get_xlim()[<span class="dv">1</span>]], [th[<span class="dv">1</span>], th[<span class="dv">1</span>]], <span class="st">'C2:'</span>,</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>          linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">"split 2"</span>)</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="fl">4.95</span>, <span class="fl">4.95</span>], [<span class="dv">0</span>, th[<span class="dv">1</span>]], <span class="st">'C3--'</span>,</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>          linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">"(split 3)"</span>)</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>plt.xlabel(iris.feature_names[<span class="dv">2</span>])</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>plt.ylabel(iris.feature_names[<span class="dv">3</span>])</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-clustering-sl-tree-iris-split" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-clustering-sl-tree-iris-split-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="supervised_files/figure-html/fig-clustering-sl-tree-iris-split-output-1.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-17" title="Figure&nbsp;2.13: Splits for the Fischer Iris dataset with the first two split form the above tree and the third split would be the next step for a larger tree."><img src="supervised_files/figure-html/fig-clustering-sl-tree-iris-split-output-1.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-clustering-sl-tree-iris-split-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.13: Splits for the Fischer Iris dataset with the first two split form the above tree and the third split would be the next step for a larger tree.
</figcaption>
</figure>
</div>
</div>
</div>
<p>In <a href="#fig-clustering-sl-tree-iris-split" class="quarto-xref">Figure&nbsp;<span>2.13</span></a> we can see the the first two splits and the next split if we would increase the tree. With the first split, we immediately separate <em>setosa</em> with <span class="math inline">\(100\%\)</span> accuracy. The two other classes are a bit tricky and we can not classify everything correct right away. In total <span class="math inline">\(6\)</span> out of <span class="math inline">\(150\)</span> observations are wrongly classified with this simple tree.</p>
<p>Let us also apply the tree classification to our cats and dogs example.</p>
<div id="47313cb3" class="cell" data-execution_count="22">
<details class="code-fold">
<summary>Show the code for the figure</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> io</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_val_score</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> six <span class="im">import</span> StringIO</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>config InlineBackend.figure_formats <span class="op">=</span> [<span class="st">"svg"</span>]</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> requests.get(</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">"https://github.com/dynamicslab/databook_python/"</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">"raw/refs/heads/master/DATA/catData_w.mat"</span>)</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>cats_w <span class="op">=</span> scipy.io.loadmat(io.BytesIO(response.content))[<span class="st">"cat_wave"</span>]</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> requests.get(</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">"https://github.com/dynamicslab/databook_python/"</span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">"raw/refs/heads/master/DATA/dogData_w.mat"</span>)</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>dogs_w <span class="op">=</span> scipy.io.loadmat(io.BytesIO(response.content))[<span class="st">"dog_wave"</span>]</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>CD <span class="op">=</span> np.concatenate((dogs_w, cats_w), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>U, S, VT <span class="op">=</span> np.linalg.svd(CD <span class="op">-</span> np.mean(CD), full_matrices<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>v <span class="op">=</span> VT.T</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> np.arange(<span class="dv">1</span>, <span class="dv">21</span>)</span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>xtrain <span class="op">=</span> np.concatenate((v[:<span class="dv">60</span>, features], v[<span class="dv">80</span>:<span class="dv">140</span>, features]))</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>label <span class="op">=</span> np.repeat(np.array([<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>]), <span class="dv">60</span>)</span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>xtest <span class="op">=</span> np.concatenate((v[<span class="dv">60</span>:<span class="dv">80</span>, features], v[<span class="dv">140</span>:<span class="dv">160</span>, features]))</span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>truth <span class="op">=</span> np.repeat(np.array([<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>]), <span class="dv">20</span>)</span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>decision_tree_cvd <span class="op">=</span> DecisionTreeClassifier(max_depth<span class="op">=</span><span class="dv">2</span>).fit(xtrain, label)</span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>test_label <span class="op">=</span> decision_tree_cvd.predict(xtest)</span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> sklearn.metrics.confusion_matrix(test_label, truth)</span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a>test_label <span class="op">=</span> svc.predict(xtest)</span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> sklearn.metrics.confusion_matrix(test_label, truth)</span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a>dot_data <span class="op">=</span> <span class="st">"cvsd_tree.dot"</span></span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a>sklearn.tree.export_graphviz(decision_tree_cvd,</span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a>                out_file<span class="op">=</span>dot_data,  </span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a>                filled<span class="op">=</span><span class="va">True</span>, rounded<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a>                class_names<span class="op">=</span>[<span class="st">"dog"</span>, <span class="st">"cat"</span>],</span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a>                special_characters<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> decision_tree_cvd.score(xtest, truth)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-file="cvsd_tree.dot" data-layout-align="default">
<div class="cell-output-display">
<div id="fig-clustering-sl-tree-cvsd" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-clustering-sl-tree-cvsd-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div>
<svg width="672" height="480" viewbox="0.00 0.00 472.45 311.20" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 307.2)">
<title>Tree</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-307.2 468.45,-307.2 468.45,4 -4,4"></polygon>
<!-- 0 -->
<g id="node1" class="node">
<title>0</title>
<path fill="#ffffff" stroke="black" d="M280.3,-303.2C280.3,-303.2 192.04,-303.2 192.04,-303.2 186.04,-303.2 180.04,-297.2 180.04,-291.2 180.04,-291.2 180.04,-237.2 180.04,-237.2 180.04,-231.2 186.04,-225.2 192.04,-225.2 192.04,-225.2 280.3,-225.2 280.3,-225.2 286.3,-225.2 292.3,-231.2 292.3,-237.2 292.3,-237.2 292.3,-291.2 292.3,-291.2 292.3,-297.2 286.3,-303.2 280.3,-303.2"></path>
<text text-anchor="start" x="201.54" y="-287.6" font-family="Helvetica,sans-Serif" font-size="14.00">x</text>
<text text-anchor="start" x="208.54" y="-287.6" font-family="Helvetica,sans-Serif" baseline-shift="sub" font-size="14.00">0</text>
<text text-anchor="start" x="216.32" y="-287.6" font-family="Helvetica,sans-Serif" font-size="14.00"> ≤ 0.049</text>
<text text-anchor="start" x="207.57" y="-273.6" font-family="Helvetica,sans-Serif" font-size="14.00">gini = 0.5</text>
<text text-anchor="start" x="190.45" y="-259.6" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 120</text>
<text text-anchor="start" x="188.11" y="-245.6" font-family="Helvetica,sans-Serif" font-size="14.00">value = [60, 60]</text>
<text text-anchor="start" x="200.57" y="-231.6" font-family="Helvetica,sans-Serif" font-size="14.00">class = dog</text>
</g>
<!-- 1 -->
<g id="node2" class="node">
<title>1</title>
<path fill="#72b9ec" stroke="black" d="M217.3,-189.2C217.3,-189.2 129.04,-189.2 129.04,-189.2 123.04,-189.2 117.04,-183.2 117.04,-177.2 117.04,-177.2 117.04,-123.2 117.04,-123.2 117.04,-117.2 123.04,-111.2 129.04,-111.2 129.04,-111.2 217.3,-111.2 217.3,-111.2 223.3,-111.2 229.3,-117.2 229.3,-123.2 229.3,-123.2 229.3,-177.2 229.3,-177.2 229.3,-183.2 223.3,-189.2 217.3,-189.2"></path>
<text text-anchor="start" x="138.54" y="-173.6" font-family="Helvetica,sans-Serif" font-size="14.00">x</text>
<text text-anchor="start" x="145.54" y="-173.6" font-family="Helvetica,sans-Serif" baseline-shift="sub" font-size="14.00">2</text>
<text text-anchor="start" x="153.32" y="-173.6" font-family="Helvetica,sans-Serif" font-size="14.00"> ≤ 0.019</text>
<text text-anchor="start" x="136.78" y="-159.6" font-family="Helvetica,sans-Serif" font-size="14.00">gini = 0.346</text>
<text text-anchor="start" x="131.34" y="-145.6" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 72</text>
<text text-anchor="start" x="125.11" y="-131.6" font-family="Helvetica,sans-Serif" font-size="14.00">value = [16, 56]</text>
<text text-anchor="start" x="139.91" y="-117.6" font-family="Helvetica,sans-Serif" font-size="14.00">class = cat</text>
</g>
<!-- 0&#45;&gt;1 -->
<g id="edge1" class="edge">
<title>0-&gt;1</title>
<path fill="none" stroke="black" d="M214.67,-224.97C209.8,-216.32 204.58,-207.04 199.54,-198.08"></path>
<polygon fill="black" stroke="black" points="202.53,-196.26 194.58,-189.26 196.43,-199.69 202.53,-196.26"></polygon>
<text text-anchor="middle" x="187.84" y="-209.13" font-family="Helvetica,sans-Serif" font-size="14.00">True</text>
</g>
<!-- 4 -->
<g id="node5" class="node">
<title>4</title>
<path fill="#e78c4b" stroke="black" d="M339.51,-189.2C339.51,-189.2 258.83,-189.2 258.83,-189.2 252.83,-189.2 246.83,-183.2 246.83,-177.2 246.83,-177.2 246.83,-123.2 246.83,-123.2 246.83,-117.2 252.83,-111.2 258.83,-111.2 258.83,-111.2 339.51,-111.2 339.51,-111.2 345.51,-111.2 351.51,-117.2 351.51,-123.2 351.51,-123.2 351.51,-177.2 351.51,-177.2 351.51,-183.2 345.51,-189.2 339.51,-189.2"></path>
<text text-anchor="start" x="264.54" y="-173.6" font-family="Helvetica,sans-Serif" font-size="14.00">x</text>
<text text-anchor="start" x="271.54" y="-173.6" font-family="Helvetica,sans-Serif" baseline-shift="sub" font-size="14.00">3</text>
<text text-anchor="start" x="279.32" y="-173.6" font-family="Helvetica,sans-Serif" font-size="14.00"> ≤ 0.133</text>
<text text-anchor="start" x="262.78" y="-159.6" font-family="Helvetica,sans-Serif" font-size="14.00">gini = 0.153</text>
<text text-anchor="start" x="257.34" y="-145.6" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 48</text>
<text text-anchor="start" x="255" y="-131.6" font-family="Helvetica,sans-Serif" font-size="14.00">value = [44, 4]</text>
<text text-anchor="start" x="263.57" y="-117.6" font-family="Helvetica,sans-Serif" font-size="14.00">class = dog</text>
</g>
<!-- 0&#45;&gt;4 -->
<g id="edge4" class="edge">
<title>0-&gt;4</title>
<path fill="none" stroke="black" d="M257.68,-224.97C262.54,-216.32 267.76,-207.04 272.8,-198.08"></path>
<polygon fill="black" stroke="black" points="275.91,-199.69 277.76,-189.26 269.81,-196.26 275.91,-199.69"></polygon>
<text text-anchor="middle" x="284.5" y="-209.13" font-family="Helvetica,sans-Serif" font-size="14.00">False</text>
</g>
<!-- 2 -->
<g id="node3" class="node">
<title>2</title>
<path fill="#399de5" stroke="black" d="M92.51,-75.3C92.51,-75.3 11.83,-75.3 11.83,-75.3 5.83,-75.3 -0.17,-69.3 -0.17,-63.3 -0.17,-63.3 -0.17,-11.9 -0.17,-11.9 -0.17,-5.9 5.83,0.1 11.83,0.1 11.83,0.1 92.51,0.1 92.51,0.1 98.51,0.1 104.51,-5.9 104.51,-11.9 104.51,-11.9 104.51,-63.3 104.51,-63.3 104.51,-69.3 98.51,-75.3 92.51,-75.3"></path>
<text text-anchor="start" x="23.57" y="-58.6" font-family="Helvetica,sans-Serif" font-size="14.00">gini = 0.0</text>
<text text-anchor="start" x="10.34" y="-41.8" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 47</text>
<text text-anchor="start" x="8" y="-25" font-family="Helvetica,sans-Serif" font-size="14.00">value = [0, 47]</text>
<text text-anchor="start" x="18.91" y="-8.2" font-family="Helvetica,sans-Serif" font-size="14.00">class = cat</text>
</g>
<!-- 1&#45;&gt;2 -->
<g id="edge2" class="edge">
<title>1-&gt;2</title>
<path fill="none" stroke="black" d="M131.53,-111.14C121.3,-101.79 110.27,-91.7 99.78,-82.11"></path>
<polygon fill="black" stroke="black" points="102,-79.4 92.25,-75.24 97.27,-84.57 102,-79.4"></polygon>
</g>
<!-- 3 -->
<g id="node4" class="node">
<title>3</title>
<path fill="#f4c8a8" stroke="black" d="M214.51,-75.3C214.51,-75.3 133.83,-75.3 133.83,-75.3 127.83,-75.3 121.83,-69.3 121.83,-63.3 121.83,-63.3 121.83,-11.9 121.83,-11.9 121.83,-5.9 127.83,0.1 133.83,0.1 133.83,0.1 214.51,0.1 214.51,0.1 220.51,0.1 226.51,-5.9 226.51,-11.9 226.51,-11.9 226.51,-63.3 226.51,-63.3 226.51,-69.3 220.51,-75.3 214.51,-75.3"></path>
<text text-anchor="start" x="137.78" y="-58.6" font-family="Helvetica,sans-Serif" font-size="14.00">gini = 0.461</text>
<text text-anchor="start" x="132.34" y="-41.8" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 25</text>
<text text-anchor="start" x="130" y="-25" font-family="Helvetica,sans-Serif" font-size="14.00">value = [16, 9]</text>
<text text-anchor="start" x="138.57" y="-8.2" font-family="Helvetica,sans-Serif" font-size="14.00">class = dog</text>
</g>
<!-- 1&#45;&gt;3 -->
<g id="edge3" class="edge">
<title>1-&gt;3</title>
<path fill="none" stroke="black" d="M173.51,-111.14C173.59,-102.88 173.67,-94.04 173.75,-85.48"></path>
<polygon fill="black" stroke="black" points="177.25,-85.27 173.84,-75.24 170.25,-85.21 177.25,-85.27"></polygon>
</g>
<!-- 5 -->
<g id="node6" class="node">
<title>5</title>
<path fill="#e6843d" stroke="black" d="M338.51,-75.3C338.51,-75.3 257.83,-75.3 257.83,-75.3 251.83,-75.3 245.83,-69.3 245.83,-63.3 245.83,-63.3 245.83,-11.9 245.83,-11.9 245.83,-5.9 251.83,0.1 257.83,0.1 257.83,0.1 338.51,0.1 338.51,0.1 344.51,0.1 350.51,-5.9 350.51,-11.9 350.51,-11.9 350.51,-63.3 350.51,-63.3 350.51,-69.3 344.51,-75.3 338.51,-75.3"></path>
<text text-anchor="start" x="261.78" y="-58.6" font-family="Helvetica,sans-Serif" font-size="14.00">gini = 0.043</text>
<text text-anchor="start" x="256.34" y="-41.8" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 45</text>
<text text-anchor="start" x="254" y="-25" font-family="Helvetica,sans-Serif" font-size="14.00">value = [44, 1]</text>
<text text-anchor="start" x="262.57" y="-8.2" font-family="Helvetica,sans-Serif" font-size="14.00">class = dog</text>
</g>
<!-- 4&#45;&gt;5 -->
<g id="edge5" class="edge">
<title>4-&gt;5</title>
<path fill="none" stroke="black" d="M298.83,-111.14C298.75,-102.88 298.67,-94.04 298.59,-85.48"></path>
<polygon fill="black" stroke="black" points="302.09,-85.21 298.5,-75.24 295.09,-85.27 302.09,-85.21"></polygon>
</g>
<!-- 6 -->
<g id="node7" class="node">
<title>6</title>
<path fill="#399de5" stroke="black" d="M452.23,-75.3C452.23,-75.3 380.11,-75.3 380.11,-75.3 374.11,-75.3 368.11,-69.3 368.11,-63.3 368.11,-63.3 368.11,-11.9 368.11,-11.9 368.11,-5.9 374.11,0.1 380.11,0.1 380.11,0.1 452.23,0.1 452.23,0.1 458.23,0.1 464.23,-5.9 464.23,-11.9 464.23,-11.9 464.23,-63.3 464.23,-63.3 464.23,-69.3 458.23,-75.3 452.23,-75.3"></path>
<text text-anchor="start" x="387.57" y="-58.6" font-family="Helvetica,sans-Serif" font-size="14.00">gini = 0.0</text>
<text text-anchor="start" x="378.23" y="-41.8" font-family="Helvetica,sans-Serif" font-size="14.00">samples = 3</text>
<text text-anchor="start" x="375.89" y="-25" font-family="Helvetica,sans-Serif" font-size="14.00">value = [0, 3]</text>
<text text-anchor="start" x="382.91" y="-8.2" font-family="Helvetica,sans-Serif" font-size="14.00">class = cat</text>
</g>
<!-- 4&#45;&gt;6 -->
<g id="edge6" class="edge">
<title>4-&gt;6</title>
<path fill="none" stroke="black" d="M339.44,-111.14C349.33,-101.79 360,-91.7 370.14,-82.11"></path>
<polygon fill="black" stroke="black" points="372.55,-84.65 377.41,-75.24 367.74,-79.56 372.55,-84.65"></polygon>
</g>
</g>
</svg>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-clustering-sl-tree-cvsd-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.14: Decision tree for the Fischer iris dataset and depth 2.
</figcaption>
</figure>
</div>
</div>
</div>
<div id="823b8d3e" class="cell" data-execution_count="23">
<div class="cell-output cell-output-display" data-execution_count="23">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">PP</th>
<th data-quarto-table-cell-role="th">PN</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">P</td>
<td>18</td>
<td>3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">N</td>
<td>2</td>
<td>17</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>If we compare our confusion matrix for the test cases to the one of SVM we get comparable results. In general, we can see that the first split is along <span class="math inline">\(PC_2\)</span> (note that we do not use the <span class="math inline">\(PC_1\)</span> in the code and therefore <span class="math inline">\(x_0=PC_2\)</span>) and our second split is along <span class="math inline">\(PC_4\)</span>. We used the same components before. The third split is along <span class="math inline">\(PC_5\)</span>, which we did not consider before hand. Overall the mean accuracy for out test set is 77.5%.</p>
<div class="callout callout-style-simple callout-caution no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exr-nonlinear-tree-moons" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 2.6 (A tree on the moon)</strong></span> Recall the moons example from <a href="unsupervised.html#sec-clustering-ul-dbscan" class="quarto-xref"><span>Section 1.3</span></a> and use a <code>DecisionTreeClassifier</code> classification to distinguish the clusters and plot the decision splits.</p>
<p>Play around with the parameters, e.g.&nbsp;<code>min_samples_leaf = 5</code> and see how this influences the score for a test set.</p>
</div>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-caution no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exr-nonlinear-tree-regression" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 2.7 (Tree regression)</strong></span> We can use a decision tree for regression. Have a look at <a href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html">docs</a> and use the findings to fit the observations of <a href="#exr-nonlinear-SVM-regression" class="quarto-xref">Exercise&nbsp;<span>2.5</span></a> with various <code>max_depth</code> values and no value here but limiting <code>min_samples_leaf=10</code>.</p>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Sensitivity to rotation and initial state
</div>
</div>
<div class="callout-body-container callout-body">
<p>Due to the nature of decision trees and the way they split observations by lines, they become sensitive to rotation. Furthermore, the tree construction is based on a random process as the feature for the split is chosen at random.</p>
<p>To illustrate this we use a slight adaptation of the <span class="citation" data-cites="Geron2022-xh">(<a href="../references.html#ref-Geron2022-xh" role="doc-biblioref">Geron 2022, figs. 6–7</a>)</span>.</p>
<details class="code-fold">
<summary>Show the code for the figure</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.inspection <span class="im">import</span> DecisionBoundaryDisplay</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> make_pipeline</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>config InlineBackend.figure_formats <span class="op">=</span> [<span class="st">"svg"</span>]</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">6020</span>)</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_tree_bound(tree, X, y):</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>    plt.figure()</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>    plt.scatter(X[y<span class="op">==</span><span class="dv">0</span>, <span class="dv">0</span>], X[y<span class="op">==</span><span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>    plt.scatter(X[y<span class="op">==</span><span class="dv">1</span>, <span class="dv">0</span>], X[y<span class="op">==</span><span class="dv">1</span>, <span class="dv">1</span>])</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>    DecisionBoundaryDisplay.from_estimator(</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>            tree,</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>            X,</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>            grid_resolution<span class="op">=</span><span class="dv">2000</span>,</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>            ax<span class="op">=</span>plt.gca(),</span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>            response_method<span class="op">=</span><span class="st">"predict"</span>,</span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>            plot_method<span class="op">=</span><span class="st">"contour"</span>,</span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>            alpha<span class="op">=</span><span class="fl">1.0</span>,</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>            levels<span class="op">=</span>[<span class="dv">0</span>],</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a>    l <span class="op">=</span> np.<span class="bu">round</span>(np.<span class="bu">abs</span>(X).<span class="bu">max</span>() <span class="op">+</span> <span class="fl">0.1</span>, <span class="dv">2</span>)</span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a>    plt.xlim([<span class="op">-</span>l, l])</span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a>    plt.ylim([<span class="op">-</span>l, l])</span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.random.rand(<span class="dv">100</span>, <span class="dv">2</span>) <span class="op">-</span> <span class="fl">0.5</span></span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> (X[:, <span class="dv">0</span>] <span class="op">&gt;</span> <span class="dv">0</span>).astype(np.int32)</span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a>angle <span class="op">=</span> np.pi <span class="op">/</span> <span class="dv">4</span></span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a>rotation_matrix <span class="op">=</span> np.array([[np.cos(angle), <span class="op">-</span>np.sin(angle)],</span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a>                            [np.sin(angle), np.cos(angle)]])</span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a>X_rot <span class="op">=</span> X <span class="op">@</span> rotation_matrix</span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a>tree_square <span class="op">=</span> DecisionTreeClassifier(random_state<span class="op">=</span><span class="dv">42</span>).fit(X, y)</span>
<span id="cb20-39"><a href="#cb20-39" aria-hidden="true" tabindex="-1"></a>tree_square_rot <span class="op">=</span> DecisionTreeClassifier(random_state<span class="op">=</span><span class="dv">42</span>).fit(X_rot, y)</span>
<span id="cb20-40"><a href="#cb20-40" aria-hidden="true" tabindex="-1"></a>tree_square_rot2 <span class="op">=</span> DecisionTreeClassifier(random_state<span class="op">=</span><span class="dv">6020</span>).fit(X_rot, y)</span>
<span id="cb20-41"><a href="#cb20-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-42"><a href="#cb20-42" aria-hidden="true" tabindex="-1"></a>pipeline <span class="op">=</span> make_pipeline(StandardScaler(), PCA())</span>
<span id="cb20-43"><a href="#cb20-43" aria-hidden="true" tabindex="-1"></a>X_pca <span class="op">=</span> pipeline.fit_transform(X_rot)</span>
<span id="cb20-44"><a href="#cb20-44" aria-hidden="true" tabindex="-1"></a>tree_square_pca <span class="op">=</span> DecisionTreeClassifier(random_state<span class="op">=</span><span class="dv">6020</span>).fit(X_pca, y)</span>
<span id="cb20-45"><a href="#cb20-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-46"><a href="#cb20-46" aria-hidden="true" tabindex="-1"></a>plot_tree_bound(tree_square, X, y)</span>
<span id="cb20-47"><a href="#cb20-47" aria-hidden="true" tabindex="-1"></a>plot_tree_bound(tree_square_rot, X_rot, y)</span>
<span id="cb20-48"><a href="#cb20-48" aria-hidden="true" tabindex="-1"></a>plot_tree_bound(tree_square_rot2, X_rot, y)</span>
<span id="cb20-49"><a href="#cb20-49" aria-hidden="true" tabindex="-1"></a>plot_tree_bound(tree_square_pca, X_pca, y)</span>
<span id="cb20-50"><a href="#cb20-50" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="fig-clustering-sl-tree-rot" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-clustering-sl-tree-rot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-clustering-sl-tree-rot" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-clustering-sl-tree-rot-1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-clustering-sl-tree-rot-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="supervised_files/figure-html/fig-clustering-sl-tree-rot-output-1.svg" class="lightbox" data-gallery="fig-clustering-sl-tree-rot" title="Figure&nbsp;2.15&nbsp;(a): Clear split along the middle for a vertical split."><img src="supervised_files/figure-html/fig-clustering-sl-tree-rot-output-1.svg" class="img-fluid figure-img" data-ref-parent="fig-clustering-sl-tree-rot"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-clustering-sl-tree-rot-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Clear split along the middle for a vertical split.
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-clustering-sl-tree-rot" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-clustering-sl-tree-rot-2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-clustering-sl-tree-rot-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="supervised_files/figure-html/fig-clustering-sl-tree-rot-output-2.svg" class="lightbox" data-gallery="fig-clustering-sl-tree-rot" title="Figure&nbsp;2.15&nbsp;(b): More complicated structure for the rotated observation."><img src="supervised_files/figure-html/fig-clustering-sl-tree-rot-output-2.svg" class="img-fluid figure-img" data-ref-parent="fig-clustering-sl-tree-rot"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-clustering-sl-tree-rot-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) More complicated structure for the rotated observation.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-clustering-sl-tree-rot" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-clustering-sl-tree-rot-3" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-clustering-sl-tree-rot-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="supervised_files/figure-html/fig-clustering-sl-tree-rot-output-3.svg" class="lightbox" data-gallery="fig-clustering-sl-tree-rot" title="Figure&nbsp;2.15&nbsp;(c): Different initial random state for the rotated observations."><img src="supervised_files/figure-html/fig-clustering-sl-tree-rot-output-3.svg" class="img-fluid figure-img" data-ref-parent="fig-clustering-sl-tree-rot"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-clustering-sl-tree-rot-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(c) Different initial random state for the rotated observations.
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-clustering-sl-tree-rot" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-clustering-sl-tree-rot-4" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-clustering-sl-tree-rot-4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="supervised_files/figure-html/fig-clustering-sl-tree-rot-output-4.svg" class="lightbox" data-gallery="fig-clustering-sl-tree-rot" title="Figure&nbsp;2.15&nbsp;(d): Correction of the rotated observations via PCA and scaling, resulting in an easy split."><img src="supervised_files/figure-html/fig-clustering-sl-tree-rot-output-4.svg" class="img-fluid figure-img" data-ref-parent="fig-clustering-sl-tree-rot"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-clustering-sl-tree-rot-4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(d) Correction of the rotated observations via PCA and scaling, resulting in an easy split.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-clustering-sl-tree-rot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.15: Illustration of the sensitivity to rotation of decision trees. Note both trees split perfectly.
</figcaption>
</figure>
</div>
<p>In <a href="#fig-clustering-sl-tree-rot-1" class="quarto-xref">Figure&nbsp;<span>2.15 (a)</span></a> we see the split for the original dataset - random numbers in <span class="math inline">\([-0.5, 0.5]^2\)</span> and the classes separation for <span class="math inline">\(x_1 &gt; 0\)</span>. A simple line, i.e.&nbsp;one split is enough to make the separation. If we rotate the dataset by by 45° we can see a way more complicated separation line in <a href="#fig-clustering-sl-tree-rot-2" class="quarto-xref">Figure&nbsp;<span>2.15 (b)</span></a>. Furthermore, <a href="#fig-clustering-sl-tree-rot-3" class="quarto-xref">Figure&nbsp;<span>2.15 (c)</span></a> shows that the <code>random_state</code> has an influence as well. Finally, if we apply scaling and PCA to the data we more or less end up at our original sample again <a href="#fig-clustering-sl-tree-rot-4" class="quarto-xref">Figure&nbsp;<span>2.15 (d)</span></a>, showcasing the power of these feature extraction techniques once more.</p>
<p>We note, all the trees make a perfect classification, just the structure is not as easy to recognize as it <em>could</em> be.</p>
</div>
</div>
<p>As we could see, trees are very sensitive to the observations and the state. In order to counteract this phenomenon we can compute multiple trees and average the results. This combinations of trees is called <em>ensemble</em> and leads to the next topic.</p>
</section>
<section id="ensemble-learning-and-random-forests" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="ensemble-learning-and-random-forests"><span class="header-section-number">2.5</span> Ensemble learning and random forests</h2>
<p>The notion of <em>wisdom of the crowd</em> suggests, that the decision of multiple people averaged, results in a <em>better</em> decision/judgment than the decisions of a single person. Of course there is a lot of statistics going in, if we want to compute exactly how the result is influenced, or if we should use the same weights for each classification, or e.g.&nbsp;the notion of <em>experts</em>, and much more.</p>
<p>Nevertheless, we can use this concept in our context to create so called <em>ensemble methods</em>, the process itself is called <em>ensemble learning</em>. With this concept we can combine already good classification methods and get a better result than the best classification method included.</p>
<p>If we train a multitude of decision trees on various (random) subsets of our observations, we can combine the predictions of the individual trees to an ensemble prediction. The resulting method is called a <em>random forest</em>. This very simple process allows us to generate very powerful classification methods.</p>
<p>There are some different approaches for the combination of such methods, we only discuss them briefly, see <span class="citation" data-cites="Geron2022-xh">(<a href="../references.html#ref-Geron2022-xh" role="doc-biblioref">Geron 2022, chap. 7</a>)</span> for a more detailed discussion.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>All of the below discussed methods and approaches can be found in the <a href="https://scikit-learn.org/stable/api/sklearn.ensemble.html"><code>sklearn.ensemble</code></a> module.</p>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-ensemble-voting" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2.3 (Voting classifiers)</strong></span> If we have a set of classifiers <span class="math inline">\(C=\{c_1, \ldots, c_n\}\)</span> of various kinds (even another ensemble classifier like a random forest is welcome), we can simple make a prediction with each resulting in <span class="math inline">\(r_1, \ldots, r_n\)</span>. Now we select the class which occurs most often, i.e.&nbsp;the <em>mode</em> of the predictions, we get a new classifier. This is called <em>hard voting</em>.</p>
<p>If all our classifiers can not only produce a prediction but a probability for our prediction, we can also create a <em>soft voting</em> classifier. All we need to do, average the probability of the predictions <span class="math inline">\(p_1, \ldots, p_n\)</span>, and this will give us new probabilities for our ensemble classifier.</p>
<div id="fig-clustering-el-voting" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-clustering-el-voting-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="../_assets/clustering/ensemble_voting.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-22" title="Figure&nbsp;2.16: Illustration of the difference between hard and soft voting for a ensemble method. For the three shown classifiers the class 0 is the most common. When moving to probabilities, the mean also predicts 0, where more convinced classifiers get a higher weight."><img src="../_assets/clustering/ensemble_voting.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-clustering-el-voting-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.16: Illustration of the difference between hard and soft voting for a ensemble method. For the three shown classifiers the class 0 is the most common. When moving to probabilities, the mean also predicts 0, where <em>more convinced</em> classifiers get a higher weight.
</figcaption>
</figure>
</div>
<p>In <code>scikit-learn</code> this is can be found in the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier"><code>sklearn.ensemble.VotingClassifier</code></a> class.</p>
</div>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-ensemble-baggingpasting" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2.4 (Bagging and Pasting)</strong></span> For <em>bagging</em> and <em>pasting</em> the idea is different. Instead of influencing the output, theses approaches influence how to manipulate the training of a set of (potentially equal) classifiers, to achieve overall better results.</p>
<p><em>Bagging</em> (bootstrap aggregating) uses sampling with replacement, i.e.&nbsp;the same observation can end up multiple times in the training set of the same classifier. <em>Pasting</em> uses sampling without replacement and therefore an observation can be in multiple classifiers but not more than once per classifier.</p>
<p>To predict, we can use hard or soft voting from above.</p>
<div id="fig-clustering-el-sampling" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-clustering-el-sampling-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="../_assets/clustering/ensemble_sampling.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-23" title="Figure&nbsp;2.17: Illustration of the random sampling for bagging and pasting in ensemble classifiers."><img src="../_assets/clustering/ensemble_sampling.svg" class="img-fluid figure-img" style="width:3.36in"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-clustering-el-sampling-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.17: Illustration of the random sampling for bagging and pasting in ensemble classifiers.
</figcaption>
</figure>
</div>
<p>With these sampling methods it is possible to use the <em>out-of-bag</em> observations (everything that is not used for a particular training) for evaluation of the trained classifier. This is called <em>out-of-bag evaluation</em>.</p>
<p>In <code>scikit-learn</code> this is can be found in the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html#sklearn.ensemble.BaggingClassifier"><code>sklearn.ensemble.BaggingClassifier</code></a> class.</p>
</div>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-ensemble-randompatches" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2.5 (Random Patches and Random Subspaces)</strong></span> For bagging and pasting it is also possible to sample features and not only observations, i.e.&nbsp;what to look at. This results in a random subset of input features for training for each classifier. This is especially useful, for high dimensional data inputs such as images, as it can speed up the learning process.</p>
<p>We call such methods <em>random patches</em> method if we sample both, training observations and training features.</p>
<p>On the other hand, if we keep the training observations fix and only sample the training features the resulting method is called a <em>random subspace</em> method.</p>
<p>In <code>scikit-learn</code> this is can be achieved by manipulating the arguments <code>max_features</code>, <code>bootstrap_features</code>, and <code>max_samples</code> in the <code>BagginClassifier</code> class.</p>
</div>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-ensemble-randomforest" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2.6 (Random Forest)</strong></span> An ensemble of decision tress, (usually) trained via bagging is called a <em>random forest</em>.</p>
<p>With a random forest it is quite easy to find out what features are important for the overall result. In <code>scikit-learn</code> this is automatically computed for the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier"><code>sklearn.ensemble.RandomForestClassifier</code></a> class.</p>
</div>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-ensemble-boosting" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2.7 (Boosting)</strong></span> <em>Boosting</em> or sometimes <em>hypothesis boosting</em> is the process of using ensemble methods to use slow learners to create a fast learner.</p>
<p>The general idea is to train a sequence where the output of one is the input of the next classifier. This <em>corrects</em> the previous result and therefore helps to achieve overall better results.</p>
<p>The most common methods are called <em>AdaBoost</em> (adaptive boosting) and <em>gradient boosting</em>.</p>
<p>In <code>scikit-learn</code> we can find this functionality in the classes <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier"><code>sklearn.ensemble.AdaBoostClassifier</code></a> and <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier"><code>sklearn.ensemble.GradientBoostingClassifier</code></a>.</p>
</div>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-ensemble-stacking" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2.8 (Stacking)</strong></span> The general idea of <em>stacking</em> is, to use a <em>blender</em> for combining the results of our ensemble methods. The blender is not just a linear combination like for soft/hard voting but another classifier/model to perform a hopefully better combination. Of course we can stack this approach and produce multiple layers before we combine them into a single result.</p>
<div id="fig-clustering-el-stacking" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-clustering-el-stacking-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="../_assets/clustering/ensemble_stacking.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-24" title="Figure&nbsp;2.18: Illustration of an m layer stacking with various classifiers in each layer."><img src="../_assets/clustering/ensemble_stacking.svg" class="img-fluid figure-img" style="width:4.58in"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-clustering-el-stacking-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.18: Illustration of an <span class="math inline">\(m\)</span> layer stacking with various classifiers in each layer.
</figcaption>
</figure>
</div>
<p>In <code>scikit-learn</code> this is can be found in the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html#sklearn.ensemble.StackingClassifier"><code>sklearn.ensemble.StackingClassifier</code></a> class.</p>
</div>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-caution no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exr-nonlinear-ensemble" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 2.8 (Ensemble methods)</strong></span> We follow the example of <span class="citation" data-cites="Geron2022-xh">(<a href="../references.html#ref-Geron2022-xh" role="doc-biblioref">Geron 2022, chap. 7</a>)</span> to explore the various possibilities for ensemble methods.</p>
<p>For our dataset we use the moons example:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_moons</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_moons(n_samples<span class="op">=</span><span class="dv">500</span>, noise<span class="op">=</span><span class="fl">0.30</span>, random_state<span class="op">=</span><span class="dv">6020</span>)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, random_state<span class="op">=</span><span class="dv">6020</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ol type="1">
<li><p>Use the <code>VotingClassifier</code> class with an <em>LDA</em>, a <em>SVM</em>, and a <em>tree</em> for classification. Make sure to set <code>random_state</code> for each, to have reproducible results. Get the overall score for the test set, as well as the individual scores for the included classifiers.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, clf <span class="kw">in</span> voting.named_estimators_.items():</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">, =, </span><span class="sc">{</span>clf<span class="sc">.</span>score(X_test, y_test)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p>Switch to <em>soft voting</em> for your ensemble classifier and see how this influences the results.</p></li>
<li><p>Create a <code>BaggingClassifier</code> with 500 trees and and an appropriate <code>max_samples</code> value. Report the score for this new classifier, also report the out-of-bag score via <code>.oob_score_</code>.</p></li>
<li><p>Create directly a <code>RandomForestClassifier</code> with 500 trees and appropriate value for <code>max_leaf_nodes</code>.</p></li>
<li><p>Create a <code>StackingClassifier</code> with an <em>LDA</em>, a <em>SVM</em>, and a <em>tree</em> for classification and a <em>random forest</em> as the final blending step and report the score of this method.</p></li>
<li><p>Train a random forest for the Fischer Iris dataset and check <code>.feature_importances_</code> to get an insight on the importance of each feature.</p></li>
<li><p>Train a random forest for our dogs and cats dataset in raw and wavelet form and check <code>.feature_importances_</code> to get an insight on the importance of each feature of the PCA.</p></li>
</ol>
</div>
</div>
</div>
</div>
</section>
<section id="multiclass-classification" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="multiclass-classification"><span class="header-section-number">2.6</span> Multiclass Classification</h2>
<p>We mainly focused on the classification of two classes in the last sections, but obviously not all problems only consist of two classes. Some of the methods discussed, like random forests, support multiclass classification out of the box. For others, there are several approaches to create a multiclass classifier out of a binary classifier.</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-multiclass-ovr" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2.9 (One vs.&nbsp;the Rest (OvR) or One vs.&nbsp;All (OvA))</strong></span> The <em>one versus the rest</em> (OvR) or <em>one versus all</em> (OvA) strategy is to train a binary classifier for each class and always interpret all other classes as the others or the <em>rest class</em>. To classify an observation you get the scores for each classifier and select the one with the highest score.</p>
<p>For the Fischer Iris dataset this would result in three classifiers (one for each iris), for the MNIST dataset in ten (one for each number).</p>
</div>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-multiclass-ovo" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2.10 (One vs.&nbsp;One (OvO))</strong></span> The <em>one versus one</em> (OvO) strategy is to train a binary classifier for always two classes and build up a set of classifiers, for <span class="math inline">\(n\)</span> classes we get <span class="math inline">\(\tfrac{n (n-1)}{2}\)</span> classifiers. To classify an observation you get the result for each classifier and select the one class with the most duels won.</p>
<p>For the Fischer Iris dataset this would result in three classifiers, for the MNIST dataset 45.</p>
<p>The advantage of OvO over OvR is that each classifier only needs to be trained on a subset and not with the entire dataset. This is especially useful for algorithms that do not scale well, like SVMs.</p>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>In <code>scikit-learn</code> the framework automatically realizes that we train a binary classifier for multiple classes and it will select OvR or OvO automatically, depending on the algorithm.</p>
<p>Nevertheless, there exist dedicated classes for the task as well <a href="https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsOneClassifier.html"><code>sklearn.multiclass.OneVsOneClassifier</code></a> and <a href="https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html#sklearn.multiclass.OneVsRestClassifier"><code>sklearn.multiclass.OneVsRestClassifier</code></a>.</p>
</div>
</div>
<div class="callout callout-style-simple callout-caution no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="exr-nonlinear-multi" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 2.9 (Multiclass classification)</strong></span> &nbsp;</p>
<ol type="1">
<li>Use SVM for the Fischer Iris dataset and test it.</li>
<li>Compare with a random forest.</li>
<li>Create a confusion matrix for more than two classes with your results and interpret the results.</li>
</ol>
</div>
</div>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-Brunton2022" class="csl-entry" role="listitem">
Brunton, Steven L., and J. Nathan Kutz. 2022. <em>Data-Driven Science and Engineering - Machine Learning, Dynamical Systems, and Control</em>. 2nd ed. Cambridge: Cambridge University Press.
</div>
<div id="ref-Fischer" class="csl-entry" role="listitem">
Fisher, R. A. 1936. <span>“The Use of Multiple Measurements in Taxonomic Problems.”</span> <em>Annals of Eugenics</em> 7 (2): 179–88. <a href="https://doi.org/10.1111/j.1469-1809.1936.tb02137.x">https://doi.org/10.1111/j.1469-1809.1936.tb02137.x</a>.
</div>
<div id="ref-Geron2022-xh" class="csl-entry" role="listitem">
Geron, Aurelien. 2022. <em>Hands-on Machine Learning with Scikit-Learn, Keras, and <span>TensorFlow</span> 3e</em>. 3rd ed. Sebastopol, CA: O’Reilly Media.
</div>
<div id="ref-Kandolf_GDM" class="csl-entry" role="listitem">
Kandolf, Peter. 2025. <span>“MECH-m-DUAL-1-DBM - Grundlagen Datenbasierter Methoden.”</span> <em>Management Center Innsbruck, Course Material</em>. <a href="https://doi.org/10.5281/zenodo.14671708">https://doi.org/10.5281/zenodo.14671708</a>.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>see <span class="citation" data-cites="Kandolf_GDM">(<a href="../references.html#ref-Kandolf_GDM" role="doc-biblioref">Kandolf 2025</a>, Definition 3.5)</span> or the direct <a href="https://kandolfp.github.io/MECH-M-DUAL-1-DBM/matrixdc/eigen.html#generalized-eigenvalue-problem">Link</a><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>see <span class="citation" data-cites="Kandolf_GDM">(<a href="../references.html#ref-Kandolf_GDM" role="doc-biblioref">Kandolf 2025</a>, Theorem 14.4)</span> or the direct <a href="https://kandolfp.github.io/MECH-M-DUAL-1-DBM/statistics/bayesian.html#def-statistics-bayesianth">Link</a><a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>see <span class="citation" data-cites="Kandolf_GDM">(<a href="../references.html#ref-Kandolf_GDM" role="doc-biblioref">Kandolf 2025, sec. 6.2</a>)</span> or the direct <a href="https://kandolfp.github.io/MECH-M-DUAL-1-DBM/regression/nonlinear.html#stochastic-gradient-descent">Link</a><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>see Wikipedia overview <a href="https://en.wikipedia.org/wiki/Confusion_matrix">Link</a><a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/kandolfp\.github\.io\/MECH-M-DUAL-2-MLB\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../clustering/unsupervised.html" class="pagination-link" aria-label="Unsupervised learning">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Unsupervised learning</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../clustering/semisupervised.html" class="pagination-link" aria-label="Semi-Supervised learning">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Semi-Supervised learning</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Machine Learning in Industrial Image Processing SS 2025 (MECH-M-DUAL-2-MLB)</p>
</div>   
    <div class="nav-footer-center">
<p><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> Peter Kandolf</p>
<div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/kandolfp/MECH-M-DUAL-2-MLB/edit/main/clustering/supervised.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/kandolfp/MECH-M-DUAL-2-MLB/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This book was built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>